{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driveway Footprint Detection \n",
    "Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENCV_IO_ENABLE_JASPER']='True' # reading jp2000 images\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import rasterio as rio\n",
    "from rasterio.windows import Window\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import loss, util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import rasterio as rio\n",
    "import random\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city = 'kw'\n",
    "# crop_size = 512\n",
    "# EXPERIMENT_NAME = 'test2'\n",
    "# TOTAL_EPOCHS = 500\n",
    "# LR = 1e-4\n",
    "# WD = 5e-4\n",
    "# test_freq = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split\n",
    "Train 70%\n",
    "Validation 15%\n",
    "Test 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDrivewayDataset(Dataset):\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        self.config = config\n",
    "        self.df_train = pd.read_csv(os.path.join(self.config['data_dir'], 'train.csv'))\n",
    "        \n",
    "        self.crop_size = self.config['train']['crop_size']\n",
    "        self.reshape = self.config['train']['reshape']\n",
    "        self.reshape_size = self.config['train']['reshape_size']\n",
    "        self.crop_diff = self.config['train']['crop_diff']\n",
    "        \n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        self.color_jit = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.05)\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.df_train))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        # prepapre reading paths\n",
    "        path_img = self.df_train.iloc[index]['path_img']\n",
    "        path_building = self.df_train.iloc[index]['path_building_fp']\n",
    "        path_road = self.df_train.iloc[index]['path_road_mask']\n",
    "        path_driveway = self.df_train.iloc[index]['path_driveway_mask']\n",
    "        \n",
    "        # read src datasets\n",
    "        src_img = rio.open(path_img, mode = 'r')\n",
    "        src_building = rio.open(path_building, mode ='r')\n",
    "        src_road = rio.open(path_road, mode = 'r')\n",
    "        src_driveway = rio.open(path_driveway, mode = 'r')\n",
    "        \n",
    "        meta = src_img.meta\n",
    "        x_lim = meta['width'] - self.crop_size + np.random.randint(-(self.crop_diff), self.crop_diff)\n",
    "        y_lim = meta['height'] - self.crop_size + np.random.randint(-(self.crop_diff), self.crop_diff)\n",
    "\n",
    "        col_off = np.random.randint(0, x_lim)\n",
    "        row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "        window = Window(col_off=col_off,\n",
    "            row_off=row_off,\n",
    "            width=self.crop_size,\n",
    "            height=self.crop_size)\n",
    "\n",
    "        _mask = src_driveway.read(window = window)\n",
    "        \n",
    "                \n",
    "        # read images, if you get nullpointer error in img read, there is a channel issue. Reformat the images.\n",
    "        _img = src_img.read((1,2,3), window = window)\n",
    "        _mask_building = src_building.read(1, window = window)\n",
    "        _mask_road = src_road.read(1, window = window)\n",
    "        _mask_driveway = src_driveway.read(1, window = window)\n",
    "        \n",
    "        _input_tensor, _mask = self.transform(_img, _mask_building, _mask_road, _mask_driveway)\n",
    "        \n",
    "        return _input_tensor, _mask\n",
    "        \n",
    "    def transform(self, img, mask_building, mask_road, mask_driveway):\n",
    "        \"\"\"\n",
    "        Input Tensor, Ouput Tensor\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # To Tensor\n",
    "        img = torch.tensor(img)\n",
    "        mask_building = torch.tensor(mask_building)\n",
    "        mask_road = torch.tensor(mask_road)\n",
    "        mask_driveway = torch.tensor(mask_driveway)\n",
    "        \n",
    "        # To PIL image\n",
    "        image = self.to_pil(img)\n",
    "        mask_building = self.to_pil(mask_building)\n",
    "        mask_road = self.to_pil(mask_road)\n",
    "        mask_driveway = self.to_pil(mask_driveway)\n",
    "        \n",
    "        # Resize\n",
    "        image = TF.resize(image, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_building = TF.resize(mask_building, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_road = TF.resize(mask_road, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_driveway = TF.resize(mask_driveway, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask_building= TF.hflip(mask_building)\n",
    "            mask_road= TF.hflip(mask_road)\n",
    "            mask_driveway= TF.hflip(mask_driveway)\n",
    "            \n",
    "        # Random Vertical flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask_building = TF.vflip(mask_building)\n",
    "            mask_road = TF.vflip(mask_road)\n",
    "            mask_driveway = TF.vflip(mask_driveway)\n",
    "        \n",
    "        # Color Jitter Image\n",
    "        image = self.color_jit(image)\n",
    "        \n",
    "        # Change to tensors\n",
    "        image = self.to_tensor(image)\n",
    "        mask_building = self.to_tensor(mask_building)\n",
    "        mask_road = self.to_tensor(mask_road)\n",
    "        mask_driveway = self.to_tensor(mask_driveway)\n",
    "        \n",
    "        # Merge input tensors to 5 channel, 3 image 1 building 1 road\n",
    "        _input_stacked = torch.cat((image, mask_building, mask_road))\n",
    "        \n",
    "        return _input_stacked, mask_driveway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDrivewayDataset(Dataset):\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(os.path.join(self.config['data_dir'], 'val.csv'))\n",
    "        \n",
    "        self.crop_size = self.config['val']['crop_size']\n",
    "        self.reshape = self.config['val']['reshape']\n",
    "        self.reshape_size = self.config['val']['reshape_size']\n",
    "        self.crop_diff = self.config['val']['crop_diff']\n",
    "        \n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.df))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        # prepapre reading paths\n",
    "        path_img = self.df.iloc[index]['path_img']\n",
    "        path_building = self.df.iloc[index]['path_building_fp']\n",
    "        path_road = self.df.iloc[index]['path_road_mask']\n",
    "        path_driveway = self.df.iloc[index]['path_driveway_mask']\n",
    "        \n",
    "        # read src datasets\n",
    "        src_img = rio.open(path_img, mode = 'r')\n",
    "        src_building = rio.open(path_building, mode ='r')\n",
    "        src_road = rio.open(path_road, mode = 'r')\n",
    "        src_driveway = rio.open(path_driveway, mode = 'r')\n",
    "        \n",
    "        meta = src_img.meta\n",
    "        x_lim = meta['width'] - self.crop_size\n",
    "        y_lim = meta['height'] - self.crop_size\n",
    "\n",
    "        col_off = np.random.randint(0, x_lim)\n",
    "        row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "        window = Window(col_off=col_off,\n",
    "            row_off=row_off,\n",
    "            width=self.crop_size,\n",
    "            height=self.crop_size)\n",
    "\n",
    "        _mask = src_driveway.read(window = window)\n",
    "        \n",
    "                \n",
    "        # read images, if you get nullpointer error in img read, there is a channel issue. Reformat the images.\n",
    "        _img = src_img.read((1,2,3), window = window)\n",
    "        _mask_building = src_building.read(1, window = window)\n",
    "        _mask_road = src_road.read(1, window = window)\n",
    "        _mask_driveway = src_driveway.read(1, window = window)\n",
    "        \n",
    "        _input_tensor, _mask = self.transform(_img, _mask_building, _mask_road, _mask_driveway)\n",
    "        \n",
    "        return _input_tensor, _mask\n",
    "        \n",
    "    def transform(self, img, mask_building, mask_road, mask_driveway):\n",
    "        \"\"\"\n",
    "        Input Tensor, Ouput Tensor\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # To Tensor\n",
    "        img = torch.tensor(img)\n",
    "        mask_building = torch.tensor(mask_building)\n",
    "        mask_road = torch.tensor(mask_road)\n",
    "        mask_driveway = torch.tensor(mask_driveway)\n",
    "        \n",
    "        # To PIL image\n",
    "        image = self.to_pil(img)\n",
    "        mask_building = self.to_pil(mask_building)\n",
    "        mask_road = self.to_pil(mask_road)\n",
    "        mask_driveway = self.to_pil(mask_driveway)\n",
    "        \n",
    "        # Resize\n",
    "        image = TF.resize(image, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_building = TF.resize(mask_building, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_road = TF.resize(mask_road, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_driveway = TF.resize(mask_driveway, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask_building= TF.hflip(mask_building)\n",
    "            mask_road= TF.hflip(mask_road)\n",
    "            mask_driveway= TF.hflip(mask_driveway)\n",
    "            \n",
    "        # Random Vertical flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask_building = TF.vflip(mask_building)\n",
    "            mask_road = TF.vflip(mask_road)\n",
    "            mask_driveway = TF.vflip(mask_driveway)\n",
    "        \n",
    "        # Change to tensors\n",
    "        image = self.to_tensor(image)\n",
    "        mask_building = self.to_tensor(mask_building)\n",
    "        mask_road = self.to_tensor(mask_road)\n",
    "        mask_driveway = self.to_tensor(mask_driveway)\n",
    "        \n",
    "        # Merge input tensors to 5 channel, 3 image 1 building 1 road\n",
    "        _input_stacked = torch.cat((image, mask_building, mask_road))\n",
    "        \n",
    "        return _input_stacked, mask_driveway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_dir\": \"./data/data_2\",\n",
    "    \"train\": {\n",
    "        \"crop_size\": 1250,\n",
    "        \"reshape\": True,\n",
    "        \"reshape_size\": 512,\n",
    "        \"crop_diff\": 100\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"crop_size\": 1250,\n",
    "        \"reshape\": True,\n",
    "        \"reshape_size\": 512,\n",
    "        \"crop_diff\": 0\n",
    "    },\n",
    "    \"train_batch_size\": 16,\n",
    "    \"val_batch_size\": 8,\n",
    "    \"epochs\": 1000,\n",
    "    \"test_freq\": 10,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_wd\": 1e-4,\n",
    "    \"exp_name\": \"exp_1\",\n",
    "    \"num_workers\": 24\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = f\"experiments/{config['exp_name']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DeepLabV3 segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, num_classes=1, aux_loss=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.conv1 = nn.Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(config['data_dir'], 'train.csv'))\n",
    "\n",
    "train_sample_weights = df_train.probability.tolist()\n",
    "train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weights, len(train_sample_weights))\n",
    "\n",
    "train_dataset = TrainDrivewayDataset(config)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"train_batch_size\"], \n",
    "                          num_workers=config['num_workers'], sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(os.path.join(config['data_dir'], 'val.csv'))\n",
    "\n",
    "val_sample_weights = df_val.probability.tolist()\n",
    "val_sampler = torch.utils.data.sampler.WeightedRandomSampler(val_sample_weights, len(val_sample_weights))\n",
    "\n",
    "val_dataset = ValDrivewayDataset(config = config)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"val_batch_size\"], \n",
    "                        num_workers=config['num_workers'], sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = TrainDrivewayDataset(config)\n",
    "# train_loader = DataLoader(train_ds, batch_size = config['train_batch_size'], shuffle = True, num_workers = config['num_workers'])\n",
    "\n",
    "# val_ds = ValTestDrivewayDataset(config)\n",
    "# val_loader = DataLoader(val_ds, batch_size = config['val_batch_size'], shuffle = True, num_workers = config['num_workers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import loss, util\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth = 1e-6):\n",
    "    pred = y_pred.contiguous()\n",
    "    target = y_true.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "def calc_loss(pred, target, weight_bce):\n",
    "    pred = pred\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(y_true = target, y_pred = pred)\n",
    "\n",
    "    loss = bce * weight_bce + dice * (1-weight_bce)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def compute_miou(y_pred, y_true):\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    \n",
    "    current = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    intersection = np.diag(current)\n",
    "    ground_truth_set = current.sum(axis=1)\n",
    "    predicted_set = current.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "    IoU = intersection / union.astype(np.float32)\n",
    "    \n",
    "    return np.mean(IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(experiment_dir):\n",
    "    os.makedirs(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logging Files\n",
    "train_file = \"{}/{}_train_loss.txt\".format(experiment_dir, config['exp_name'])\n",
    "test_file = \"{}/{}_test_loss.txt\".format(experiment_dir, config['exp_name'])\n",
    "\n",
    "train_loss_file = open(train_file, \"w\")\n",
    "val_loss_file = open(test_file, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with multiple GPUs (4)\n"
     ]
    }
   ],
   "source": [
    "if num_gpus > 1:\n",
    "    print(\"Training with multiple GPUs ({})\".format(num_gpus))\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif num_gpus == 1:\n",
    "    print(\"Single Cuda Node is avaiable\")\n",
    "    model.cuda()\n",
    "else:\n",
    "    print(\"Training on CPU, GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO CHECK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_miou = 0\n",
    "best_loss = 1e10\n",
    "epochs = 1\n",
    "total_epochs = config['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr = config['lr'],\n",
    "    weight_decay = config['lr_wd']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):    \n",
    "    model.train()\n",
    "    \n",
    "    for i, sample in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _input, gt = sample\n",
    "        _output = model(_input.cuda())\n",
    "        \n",
    "        loss = calc_loss(_output['out'].cpu(), gt, weight_bce=0.5)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = (torch.sigmoid(_output['out'].cpu()) > 0.5).numpy().astype(int)\n",
    "        \n",
    "        gt = gt.cpu().numpy().astype(int)\n",
    "        running_mIOU = compute_miou(y_pred=pred, y_true=gt)\n",
    "        \n",
    "        print('Train Epoch:{} --- Running Loss:{} --- Running mIOU:{}'.format(epochs, loss.item(), running_mIOU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(loss, model, optimizer, experiment_dir):\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        arch = type(model.module).__name__\n",
    "    else:\n",
    "        arch = type(model).__name__\n",
    "    state = {\n",
    "        \"arch\": arch,\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "    filename = os.path.join(\n",
    "        experiment_dir, \"checkpoint-loss-{:.4f}.pth.tar\".format(loss)\n",
    "    )\n",
    "    torch.save(state, filename)\n",
    "    os.rename(filename, os.path.join(experiment_dir, \"model_best.pth.tar\"))\n",
    "    print(\"Saving current best: {} ...\".format(\"model_best.pth.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val():\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        for i, sample in enumerate(val_loader):\n",
    "            _input, gt = sample\n",
    "            _output = model(_input.cuda())\n",
    "\n",
    "            loss = calc_loss(_output['out'].cpu(), gt, weight_bce=0.5)\n",
    "\n",
    "            pred = (torch.sigmoid(_output['out'].cpu()) > 0.5).numpy().astype(int)\n",
    "            \n",
    "            gt = gt.cpu().numpy().astype(int)\n",
    "            running_mIOU = compute_miou(y_pred=pred, y_true=gt)\n",
    "\n",
    "            print('Running Loss:{} --- Running mIOU:{}'.format(loss.item(), running_mIOU))\n",
    "            \n",
    "            val_loss = val_loss + loss\n",
    "        \n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1 --- Running Loss:0.7261912226676941 --- Running mIOU:0.49573213639735325\n",
      "Train Epoch:1 --- Running Loss:0.7074239253997803 --- Running mIOU:0.5153619074690174\n",
      "Train Epoch:1 --- Running Loss:0.6809643507003784 --- Running mIOU:0.531050895711434\n",
      "Train Epoch:1 --- Running Loss:0.6911866664886475 --- Running mIOU:0.5256030367646344\n",
      "Train Epoch:1 --- Running Loss:0.6865183115005493 --- Running mIOU:0.5315358428599826\n",
      "Train Epoch:1 --- Running Loss:0.6917109489440918 --- Running mIOU:0.5226575465420009\n",
      "Train Epoch:1 --- Running Loss:0.6836482286453247 --- Running mIOU:0.5239766779450157\n",
      "Train Epoch:1 --- Running Loss:0.6660503149032593 --- Running mIOU:0.5484286753767497\n",
      "Train Epoch:1 --- Running Loss:0.671397864818573 --- Running mIOU:0.5444766011751683\n",
      "Train Epoch:1 --- Running Loss:0.6419479250907898 --- Running mIOU:0.5921088562402128\n",
      "Train Epoch:2 --- Running Loss:0.6404526233673096 --- Running mIOU:0.5650835296852859\n",
      "Train Epoch:2 --- Running Loss:0.6163062453269958 --- Running mIOU:0.5769549929002592\n",
      "Train Epoch:2 --- Running Loss:0.654234766960144 --- Running mIOU:0.5311610145079497\n",
      "Train Epoch:2 --- Running Loss:0.6172205209732056 --- Running mIOU:0.5928586744162161\n",
      "Train Epoch:2 --- Running Loss:0.6413345336914062 --- Running mIOU:0.5706035769075097\n",
      "Train Epoch:2 --- Running Loss:0.6106728911399841 --- Running mIOU:0.5855787622784072\n",
      "Train Epoch:2 --- Running Loss:0.6010528206825256 --- Running mIOU:0.5934277034935245\n",
      "Train Epoch:2 --- Running Loss:0.5797277688980103 --- Running mIOU:0.6212032049932684\n",
      "Train Epoch:2 --- Running Loss:0.6048453450202942 --- Running mIOU:0.5794057189451288\n",
      "Train Epoch:2 --- Running Loss:0.6076773405075073 --- Running mIOU:0.565409647335542\n",
      "Train Epoch:3 --- Running Loss:0.6003477573394775 --- Running mIOU:0.5838841069330868\n",
      "Train Epoch:3 --- Running Loss:0.5546359419822693 --- Running mIOU:0.6089034627776754\n",
      "Train Epoch:3 --- Running Loss:0.5736996531486511 --- Running mIOU:0.6164332504786162\n",
      "Train Epoch:3 --- Running Loss:0.5748550891876221 --- Running mIOU:0.5960285977315262\n",
      "Train Epoch:3 --- Running Loss:0.5570119023323059 --- Running mIOU:0.5994058535104463\n",
      "Train Epoch:3 --- Running Loss:0.5642454624176025 --- Running mIOU:0.6026904320005244\n",
      "Train Epoch:3 --- Running Loss:0.5738246440887451 --- Running mIOU:0.5900476036772474\n",
      "Train Epoch:3 --- Running Loss:0.5348334312438965 --- Running mIOU:0.6204921088745047\n",
      "Train Epoch:3 --- Running Loss:0.5424785614013672 --- Running mIOU:0.6219656415572475\n",
      "Train Epoch:3 --- Running Loss:0.5643900632858276 --- Running mIOU:0.6009793662276257\n",
      "Train Epoch:4 --- Running Loss:0.5385130047798157 --- Running mIOU:0.6267563755497103\n",
      "Train Epoch:4 --- Running Loss:0.563101053237915 --- Running mIOU:0.5954700767641947\n",
      "Train Epoch:4 --- Running Loss:0.5466243028640747 --- Running mIOU:0.6471782118150916\n",
      "Train Epoch:4 --- Running Loss:0.5384040474891663 --- Running mIOU:0.652991683873452\n",
      "Train Epoch:4 --- Running Loss:0.5570876598358154 --- Running mIOU:0.6046689272715549\n",
      "Train Epoch:4 --- Running Loss:0.5503570437431335 --- Running mIOU:0.6138251562495978\n",
      "Train Epoch:4 --- Running Loss:0.5390281677246094 --- Running mIOU:0.6320504411292891\n",
      "Train Epoch:4 --- Running Loss:0.5377638936042786 --- Running mIOU:0.6259340191335482\n",
      "Train Epoch:4 --- Running Loss:0.5524230599403381 --- Running mIOU:0.6151898877156997\n",
      "Train Epoch:4 --- Running Loss:0.5148358941078186 --- Running mIOU:0.6580005181734713\n",
      "Train Epoch:5 --- Running Loss:0.5191258788108826 --- Running mIOU:0.6448718661754917\n",
      "Train Epoch:5 --- Running Loss:0.5278743505477905 --- Running mIOU:0.6575139405352374\n",
      "Train Epoch:5 --- Running Loss:0.5322074890136719 --- Running mIOU:0.6161768062621115\n",
      "Train Epoch:5 --- Running Loss:0.5451033115386963 --- Running mIOU:0.6248139578563283\n",
      "Train Epoch:5 --- Running Loss:0.5127861499786377 --- Running mIOU:0.6431783109165949\n",
      "Train Epoch:5 --- Running Loss:0.5149312019348145 --- Running mIOU:0.6793290417406328\n",
      "Train Epoch:5 --- Running Loss:0.5077550411224365 --- Running mIOU:0.6735656581925505\n",
      "Train Epoch:5 --- Running Loss:0.5194777250289917 --- Running mIOU:0.6473708355775787\n",
      "Train Epoch:5 --- Running Loss:0.4947013854980469 --- Running mIOU:0.6624686216136676\n",
      "Train Epoch:5 --- Running Loss:0.451599657535553 --- Running mIOU:0.7027596496759051\n",
      "Train Epoch:6 --- Running Loss:0.5382854342460632 --- Running mIOU:0.6379504224325806\n",
      "Train Epoch:6 --- Running Loss:0.48943889141082764 --- Running mIOU:0.6482835631244883\n",
      "Train Epoch:6 --- Running Loss:0.5151389837265015 --- Running mIOU:0.6258797368218334\n",
      "Train Epoch:6 --- Running Loss:0.5292754769325256 --- Running mIOU:0.644797771287638\n",
      "Train Epoch:6 --- Running Loss:0.48083212971687317 --- Running mIOU:0.6693622128015521\n",
      "Train Epoch:6 --- Running Loss:0.4935230612754822 --- Running mIOU:0.6886301559256893\n",
      "Train Epoch:6 --- Running Loss:0.49412786960601807 --- Running mIOU:0.681722359789311\n",
      "Train Epoch:6 --- Running Loss:0.48858368396759033 --- Running mIOU:0.7030374033940968\n",
      "Train Epoch:6 --- Running Loss:0.4855943024158478 --- Running mIOU:0.6642513845179394\n",
      "Train Epoch:6 --- Running Loss:0.45996275544166565 --- Running mIOU:0.6832538323560623\n",
      "Train Epoch:7 --- Running Loss:0.48790061473846436 --- Running mIOU:0.6665492148148275\n",
      "Train Epoch:7 --- Running Loss:0.5289789438247681 --- Running mIOU:0.6077337379326074\n",
      "Train Epoch:7 --- Running Loss:0.49015653133392334 --- Running mIOU:0.6384984002138705\n",
      "Train Epoch:7 --- Running Loss:0.5167838335037231 --- Running mIOU:0.6382424865092666\n",
      "Train Epoch:7 --- Running Loss:0.5143995881080627 --- Running mIOU:0.6377044944416593\n",
      "Train Epoch:7 --- Running Loss:0.45798224210739136 --- Running mIOU:0.6966033514733205\n",
      "Train Epoch:7 --- Running Loss:0.4907431900501251 --- Running mIOU:0.6464391798913407\n",
      "Train Epoch:7 --- Running Loss:0.4892655611038208 --- Running mIOU:0.6668512039423751\n",
      "Train Epoch:7 --- Running Loss:0.4979820251464844 --- Running mIOU:0.6433753177604556\n",
      "Train Epoch:7 --- Running Loss:0.4636303782463074 --- Running mIOU:0.6711824950701535\n",
      "Train Epoch:8 --- Running Loss:0.5007251501083374 --- Running mIOU:0.6341589309240605\n",
      "Train Epoch:8 --- Running Loss:0.4989079535007477 --- Running mIOU:0.6203730280903004\n",
      "Train Epoch:8 --- Running Loss:0.4706421494483948 --- Running mIOU:0.6428144713440473\n",
      "Train Epoch:8 --- Running Loss:0.4923616051673889 --- Running mIOU:0.6526461251561794\n",
      "Train Epoch:8 --- Running Loss:0.49577420949935913 --- Running mIOU:0.6786835750351681\n",
      "Train Epoch:8 --- Running Loss:0.4595809876918793 --- Running mIOU:0.6876532928551234\n",
      "Train Epoch:8 --- Running Loss:0.49079275131225586 --- Running mIOU:0.667535789221593\n",
      "Train Epoch:8 --- Running Loss:0.4875350892543793 --- Running mIOU:0.7035811751507511\n",
      "Train Epoch:8 --- Running Loss:0.46214836835861206 --- Running mIOU:0.7035837234160989\n",
      "Train Epoch:8 --- Running Loss:0.4445086717605591 --- Running mIOU:0.7054837843848881\n",
      "Train Epoch:9 --- Running Loss:0.4368731677532196 --- Running mIOU:0.7091639954525335\n",
      "Train Epoch:9 --- Running Loss:0.4481515884399414 --- Running mIOU:0.6860926969702488\n",
      "Train Epoch:9 --- Running Loss:0.46950578689575195 --- Running mIOU:0.6738385090689074\n",
      "Train Epoch:9 --- Running Loss:0.4743959903717041 --- Running mIOU:0.6634913795076074\n",
      "Train Epoch:9 --- Running Loss:0.4697694778442383 --- Running mIOU:0.6682503706424492\n",
      "Train Epoch:9 --- Running Loss:0.47386837005615234 --- Running mIOU:0.680039590202136\n",
      "Train Epoch:9 --- Running Loss:0.45612281560897827 --- Running mIOU:0.6756890354605583\n",
      "Train Epoch:9 --- Running Loss:0.48282313346862793 --- Running mIOU:0.6812353014109042\n",
      "Train Epoch:9 --- Running Loss:0.4564002454280853 --- Running mIOU:0.6989711998240863\n",
      "Train Epoch:9 --- Running Loss:0.46366655826568604 --- Running mIOU:0.662684271679546\n",
      "Train Epoch:10 --- Running Loss:0.44904443621635437 --- Running mIOU:0.7050741383904988\n",
      "Train Epoch:10 --- Running Loss:0.4737096130847931 --- Running mIOU:0.6749296616114617\n",
      "Train Epoch:10 --- Running Loss:0.499728262424469 --- Running mIOU:0.6693969201848479\n",
      "Train Epoch:10 --- Running Loss:0.46872931718826294 --- Running mIOU:0.7162675601429734\n",
      "Train Epoch:10 --- Running Loss:0.481475293636322 --- Running mIOU:0.7049514783381092\n",
      "Train Epoch:10 --- Running Loss:0.40208160877227783 --- Running mIOU:0.7377753283876358\n",
      "Train Epoch:10 --- Running Loss:0.5131580829620361 --- Running mIOU:0.6320431226559493\n",
      "Train Epoch:10 --- Running Loss:0.4649296700954437 --- Running mIOU:0.6763773428780524\n",
      "Train Epoch:10 --- Running Loss:0.4695037603378296 --- Running mIOU:0.6629816440443096\n",
      "Train Epoch:10 --- Running Loss:0.46630021929740906 --- Running mIOU:0.6536120778826217\n",
      "Running Loss:0.6028082370758057 --- Running mIOU:0.6310599157782245\n",
      "Running Loss:0.6171613931655884 --- Running mIOU:0.6750171892957397\n",
      "Running Loss:0.7042253017425537 --- Running mIOU:0.6207234915366431\n",
      "Running Loss:0.7543650269508362 --- Running mIOU:0.6702169782668423\n",
      "Running Loss:0.503475546836853 --- Running mIOU:0.689120755733612\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Train Epoch:11 --- Running Loss:0.47559240460395813 --- Running mIOU:0.6486229780891848\n",
      "Train Epoch:11 --- Running Loss:0.4531397223472595 --- Running mIOU:0.7144035613306565\n",
      "Train Epoch:11 --- Running Loss:0.4462214410305023 --- Running mIOU:0.699612218126398\n",
      "Train Epoch:11 --- Running Loss:0.4505296051502228 --- Running mIOU:0.6792047552426129\n",
      "Train Epoch:11 --- Running Loss:0.44587862491607666 --- Running mIOU:0.7026322051550761\n",
      "Train Epoch:11 --- Running Loss:0.4518224895000458 --- Running mIOU:0.7028259983267047\n",
      "Train Epoch:11 --- Running Loss:0.46724438667297363 --- Running mIOU:0.7087918458020813\n",
      "Train Epoch:11 --- Running Loss:0.45851022005081177 --- Running mIOU:0.7020476134896815\n",
      "Train Epoch:11 --- Running Loss:0.4412578344345093 --- Running mIOU:0.6861063279900891\n",
      "Train Epoch:11 --- Running Loss:0.46545886993408203 --- Running mIOU:0.6628819050597557\n",
      "Train Epoch:12 --- Running Loss:0.42636731266975403 --- Running mIOU:0.7373944008185763\n",
      "Train Epoch:12 --- Running Loss:0.4252810776233673 --- Running mIOU:0.7104413464492878\n",
      "Train Epoch:12 --- Running Loss:0.4286152124404907 --- Running mIOU:0.701549736022122\n",
      "Train Epoch:12 --- Running Loss:0.4237729609012604 --- Running mIOU:0.7038087101071974\n",
      "Train Epoch:12 --- Running Loss:0.44825509190559387 --- Running mIOU:0.6692855719261441\n",
      "Train Epoch:12 --- Running Loss:0.435790479183197 --- Running mIOU:0.7229670612092983\n",
      "Train Epoch:12 --- Running Loss:0.39248988032341003 --- Running mIOU:0.7389662935306478\n",
      "Train Epoch:12 --- Running Loss:0.45627328753471375 --- Running mIOU:0.6645305841869418\n",
      "Train Epoch:12 --- Running Loss:0.45435386896133423 --- Running mIOU:0.6679727651844353\n",
      "Train Epoch:12 --- Running Loss:0.39956551790237427 --- Running mIOU:0.7347645559619163\n",
      "Train Epoch:13 --- Running Loss:0.43853577971458435 --- Running mIOU:0.6799229572256896\n",
      "Train Epoch:13 --- Running Loss:0.4650777578353882 --- Running mIOU:0.6521337940495285\n",
      "Train Epoch:13 --- Running Loss:0.4253559708595276 --- Running mIOU:0.7095591232691442\n",
      "Train Epoch:13 --- Running Loss:0.4594029486179352 --- Running mIOU:0.693432459421976\n",
      "Train Epoch:13 --- Running Loss:0.4639045298099518 --- Running mIOU:0.66801238471872\n",
      "Train Epoch:13 --- Running Loss:0.4656130075454712 --- Running mIOU:0.6663264681740777\n",
      "Train Epoch:13 --- Running Loss:0.43095046281814575 --- Running mIOU:0.7128288347678653\n",
      "Train Epoch:13 --- Running Loss:0.4560965299606323 --- Running mIOU:0.7202824363975735\n",
      "Train Epoch:13 --- Running Loss:0.459137886762619 --- Running mIOU:0.6904927993828431\n",
      "Train Epoch:13 --- Running Loss:0.45949888229370117 --- Running mIOU:0.7080693036127111\n",
      "Train Epoch:14 --- Running Loss:0.44905325770378113 --- Running mIOU:0.6685896589469258\n",
      "Train Epoch:14 --- Running Loss:0.4851398766040802 --- Running mIOU:0.7011398475463073\n",
      "Train Epoch:14 --- Running Loss:0.43999505043029785 --- Running mIOU:0.7064762750405679\n",
      "Train Epoch:14 --- Running Loss:0.40340715646743774 --- Running mIOU:0.7306230486058009\n",
      "Train Epoch:14 --- Running Loss:0.4304850995540619 --- Running mIOU:0.7435158813852655\n",
      "Train Epoch:14 --- Running Loss:0.43472540378570557 --- Running mIOU:0.71648283337486\n",
      "Train Epoch:14 --- Running Loss:0.4622754454612732 --- Running mIOU:0.671018660171485\n",
      "Train Epoch:14 --- Running Loss:0.3932461738586426 --- Running mIOU:0.7422467605076688\n",
      "Train Epoch:14 --- Running Loss:0.44765907526016235 --- Running mIOU:0.6882666877248341\n",
      "Train Epoch:14 --- Running Loss:0.4514181613922119 --- Running mIOU:0.7015890092476195\n",
      "Train Epoch:15 --- Running Loss:0.41593044996261597 --- Running mIOU:0.6898115352559968\n",
      "Train Epoch:15 --- Running Loss:0.4324061870574951 --- Running mIOU:0.7239349913405074\n",
      "Train Epoch:15 --- Running Loss:0.41641587018966675 --- Running mIOU:0.6834357433265967\n",
      "Train Epoch:15 --- Running Loss:0.38356316089630127 --- Running mIOU:0.7241757011332707\n",
      "Train Epoch:15 --- Running Loss:0.45941874384880066 --- Running mIOU:0.6814178237868938\n",
      "Train Epoch:15 --- Running Loss:0.4126337170600891 --- Running mIOU:0.7099306077368914\n",
      "Train Epoch:15 --- Running Loss:0.45980843901634216 --- Running mIOU:0.6626409879318086\n",
      "Train Epoch:15 --- Running Loss:0.39738327264785767 --- Running mIOU:0.7285759707147399\n",
      "Train Epoch:15 --- Running Loss:0.4513721466064453 --- Running mIOU:0.6840832415885711\n",
      "Train Epoch:15 --- Running Loss:0.38722336292266846 --- Running mIOU:0.7801277293137019\n",
      "Train Epoch:16 --- Running Loss:0.395365446805954 --- Running mIOU:0.7278759863011274\n",
      "Train Epoch:16 --- Running Loss:0.4310505986213684 --- Running mIOU:0.7172751422378131\n",
      "Train Epoch:16 --- Running Loss:0.38697361946105957 --- Running mIOU:0.7353730522896007\n",
      "Train Epoch:16 --- Running Loss:0.39328208565711975 --- Running mIOU:0.7271733603883529\n",
      "Train Epoch:16 --- Running Loss:0.41216838359832764 --- Running mIOU:0.7683537513528327\n",
      "Train Epoch:16 --- Running Loss:0.4150450527667999 --- Running mIOU:0.7615322692107821\n",
      "Train Epoch:16 --- Running Loss:0.4043629765510559 --- Running mIOU:0.6949326957762972\n",
      "Train Epoch:16 --- Running Loss:0.39011526107788086 --- Running mIOU:0.7134503289642506\n",
      "Train Epoch:16 --- Running Loss:0.3749901056289673 --- Running mIOU:0.7497419718531779\n",
      "Train Epoch:16 --- Running Loss:0.4170396625995636 --- Running mIOU:0.6855986040972992\n",
      "Train Epoch:17 --- Running Loss:0.4146106243133545 --- Running mIOU:0.7157726346278369\n",
      "Train Epoch:17 --- Running Loss:0.4209859073162079 --- Running mIOU:0.7137298886034908\n",
      "Train Epoch:17 --- Running Loss:0.4535627067089081 --- Running mIOU:0.6963341695801433\n",
      "Train Epoch:17 --- Running Loss:0.4335956871509552 --- Running mIOU:0.6737320363545256\n",
      "Train Epoch:17 --- Running Loss:0.39648115634918213 --- Running mIOU:0.7496071032601824\n",
      "Train Epoch:17 --- Running Loss:0.45154935121536255 --- Running mIOU:0.693249246828261\n",
      "Train Epoch:17 --- Running Loss:0.4242331385612488 --- Running mIOU:0.7009812082798951\n",
      "Train Epoch:17 --- Running Loss:0.3720655143260956 --- Running mIOU:0.7357832689665862\n",
      "Train Epoch:17 --- Running Loss:0.42313939332962036 --- Running mIOU:0.7415730403904028\n",
      "Train Epoch:17 --- Running Loss:0.37657061219215393 --- Running mIOU:0.7447443553645314\n",
      "Train Epoch:18 --- Running Loss:0.3592225909233093 --- Running mIOU:0.7553223476422285\n",
      "Train Epoch:18 --- Running Loss:0.41228151321411133 --- Running mIOU:0.7160565869306258\n",
      "Train Epoch:18 --- Running Loss:0.3958866000175476 --- Running mIOU:0.7401567602409198\n",
      "Train Epoch:18 --- Running Loss:0.34887242317199707 --- Running mIOU:0.7676461422163414\n",
      "Train Epoch:18 --- Running Loss:0.3896316587924957 --- Running mIOU:0.7155659299514014\n",
      "Train Epoch:18 --- Running Loss:0.39036107063293457 --- Running mIOU:0.7399505825714319\n",
      "Train Epoch:18 --- Running Loss:0.39361274242401123 --- Running mIOU:0.7235774389345561\n",
      "Train Epoch:18 --- Running Loss:0.3809390366077423 --- Running mIOU:0.7567982167867857\n",
      "Train Epoch:18 --- Running Loss:0.4077901840209961 --- Running mIOU:0.7000048596889761\n",
      "Train Epoch:18 --- Running Loss:0.4032635986804962 --- Running mIOU:0.6990723007044105\n",
      "Train Epoch:19 --- Running Loss:0.42978984117507935 --- Running mIOU:0.6982669001318896\n",
      "Train Epoch:19 --- Running Loss:0.40191736817359924 --- Running mIOU:0.7202078169210442\n",
      "Train Epoch:19 --- Running Loss:0.4056174159049988 --- Running mIOU:0.7233977011011823\n",
      "Train Epoch:19 --- Running Loss:0.3799789547920227 --- Running mIOU:0.7506848077980484\n",
      "Train Epoch:19 --- Running Loss:0.367729514837265 --- Running mIOU:0.7505155924204459\n",
      "Train Epoch:19 --- Running Loss:0.42365357279777527 --- Running mIOU:0.7171192952452233\n",
      "Train Epoch:19 --- Running Loss:0.38163790106773376 --- Running mIOU:0.7335034732637856\n",
      "Train Epoch:19 --- Running Loss:0.40121421217918396 --- Running mIOU:0.751629100236705\n",
      "Train Epoch:19 --- Running Loss:0.35678696632385254 --- Running mIOU:0.7666350072180829\n",
      "Train Epoch:19 --- Running Loss:0.4149373769760132 --- Running mIOU:0.7045627341260285\n",
      "Train Epoch:20 --- Running Loss:0.4450489580631256 --- Running mIOU:0.7021043571958505\n",
      "Train Epoch:20 --- Running Loss:0.3933597505092621 --- Running mIOU:0.7569662832321027\n",
      "Train Epoch:20 --- Running Loss:0.38447505235671997 --- Running mIOU:0.7601068348909137\n",
      "Train Epoch:20 --- Running Loss:0.41388463973999023 --- Running mIOU:0.680284551619668\n",
      "Train Epoch:20 --- Running Loss:0.36573439836502075 --- Running mIOU:0.7365663073616799\n",
      "Train Epoch:20 --- Running Loss:0.41856327652931213 --- Running mIOU:0.6798925335831552\n",
      "Train Epoch:20 --- Running Loss:0.40219244360923767 --- Running mIOU:0.730641398019705\n",
      "Train Epoch:20 --- Running Loss:0.3859807848930359 --- Running mIOU:0.730025115244873\n",
      "Train Epoch:20 --- Running Loss:0.34971684217453003 --- Running mIOU:0.7799674601840159\n",
      "Train Epoch:20 --- Running Loss:0.37905389070510864 --- Running mIOU:0.7409428328269874\n",
      "Running Loss:0.42519477009773254 --- Running mIOU:0.7209119951224718\n",
      "Running Loss:0.3963703513145447 --- Running mIOU:0.6849462768501795\n",
      "Running Loss:0.4054749608039856 --- Running mIOU:0.6922642631593839\n",
      "Running Loss:0.41239404678344727 --- Running mIOU:0.6943268494299017\n",
      "Running Loss:0.4170968234539032 --- Running mIOU:0.6738189844180005\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Train Epoch:21 --- Running Loss:0.35917532444000244 --- Running mIOU:0.740038518770304\n",
      "Train Epoch:21 --- Running Loss:0.4190545082092285 --- Running mIOU:0.676544829832824\n",
      "Train Epoch:21 --- Running Loss:0.37224915623664856 --- Running mIOU:0.7005615812918993\n",
      "Train Epoch:21 --- Running Loss:0.37608206272125244 --- Running mIOU:0.7129681898023903\n",
      "Train Epoch:21 --- Running Loss:0.37022674083709717 --- Running mIOU:0.7047262890418511\n",
      "Train Epoch:21 --- Running Loss:0.37717437744140625 --- Running mIOU:0.761341929734789\n",
      "Train Epoch:21 --- Running Loss:0.37071022391319275 --- Running mIOU:0.7431582083390804\n",
      "Train Epoch:21 --- Running Loss:0.3837224841117859 --- Running mIOU:0.7072712330996267\n",
      "Train Epoch:21 --- Running Loss:0.36317843198776245 --- Running mIOU:0.7582056409342378\n",
      "Train Epoch:21 --- Running Loss:0.4003913104534149 --- Running mIOU:0.6954617554721294\n",
      "Train Epoch:22 --- Running Loss:0.3711662292480469 --- Running mIOU:0.7053128192866195\n",
      "Train Epoch:22 --- Running Loss:0.4257461130619049 --- Running mIOU:0.679138772650376\n",
      "Train Epoch:22 --- Running Loss:0.34481197595596313 --- Running mIOU:0.7316645024894528\n",
      "Train Epoch:22 --- Running Loss:0.38409435749053955 --- Running mIOU:0.7175296775316735\n",
      "Train Epoch:22 --- Running Loss:0.42346271872520447 --- Running mIOU:0.6862334669967831\n",
      "Train Epoch:22 --- Running Loss:0.3353824019432068 --- Running mIOU:0.7355980501800534\n",
      "Train Epoch:22 --- Running Loss:0.36746108531951904 --- Running mIOU:0.7457033246047742\n",
      "Train Epoch:22 --- Running Loss:0.40371155738830566 --- Running mIOU:0.7090059033472753\n",
      "Train Epoch:22 --- Running Loss:0.3547990620136261 --- Running mIOU:0.7521292574630729\n",
      "Train Epoch:22 --- Running Loss:0.38713401556015015 --- Running mIOU:0.7612322286475995\n",
      "Train Epoch:23 --- Running Loss:0.41208553314208984 --- Running mIOU:0.7493035823436904\n",
      "Train Epoch:23 --- Running Loss:0.4448235034942627 --- Running mIOU:0.7086830617527273\n",
      "Train Epoch:23 --- Running Loss:0.3362339735031128 --- Running mIOU:0.7501632866750652\n",
      "Train Epoch:23 --- Running Loss:0.4076792597770691 --- Running mIOU:0.7059207656803143\n",
      "Train Epoch:23 --- Running Loss:0.3539704978466034 --- Running mIOU:0.7420563965663669\n",
      "Train Epoch:23 --- Running Loss:0.3811253309249878 --- Running mIOU:0.7219288452801121\n",
      "Train Epoch:23 --- Running Loss:0.373243510723114 --- Running mIOU:0.7439472476804342\n",
      "Train Epoch:23 --- Running Loss:0.39788612723350525 --- Running mIOU:0.694200441398166\n",
      "Train Epoch:23 --- Running Loss:0.36807283759117126 --- Running mIOU:0.7613623086489191\n",
      "Train Epoch:23 --- Running Loss:0.36396324634552 --- Running mIOU:0.746650399262276\n",
      "Train Epoch:24 --- Running Loss:0.4111182689666748 --- Running mIOU:0.7771650632840579\n",
      "Train Epoch:24 --- Running Loss:0.3955201208591461 --- Running mIOU:0.7497034525717978\n",
      "Train Epoch:24 --- Running Loss:0.38205304741859436 --- Running mIOU:0.708013440189758\n",
      "Train Epoch:24 --- Running Loss:0.38298529386520386 --- Running mIOU:0.7365677388240701\n",
      "Train Epoch:24 --- Running Loss:0.37571126222610474 --- Running mIOU:0.739252886909642\n",
      "Train Epoch:24 --- Running Loss:0.41592109203338623 --- Running mIOU:0.7013392202019901\n",
      "Train Epoch:24 --- Running Loss:0.39093244075775146 --- Running mIOU:0.7309610928397996\n",
      "Train Epoch:24 --- Running Loss:0.381394624710083 --- Running mIOU:0.7178849581665675\n",
      "Train Epoch:24 --- Running Loss:0.387533038854599 --- Running mIOU:0.7500479298141066\n",
      "Train Epoch:24 --- Running Loss:0.3212301433086395 --- Running mIOU:0.7520415990186798\n",
      "Train Epoch:25 --- Running Loss:0.39138561487197876 --- Running mIOU:0.7031432723105482\n",
      "Train Epoch:25 --- Running Loss:0.383642315864563 --- Running mIOU:0.7813423352738849\n",
      "Train Epoch:25 --- Running Loss:0.36961689591407776 --- Running mIOU:0.7595923055400309\n",
      "Train Epoch:25 --- Running Loss:0.37074822187423706 --- Running mIOU:0.7691293418999638\n",
      "Train Epoch:25 --- Running Loss:0.351108580827713 --- Running mIOU:0.7537290465628093\n",
      "Train Epoch:25 --- Running Loss:0.3721151053905487 --- Running mIOU:0.6972171642386873\n",
      "Train Epoch:25 --- Running Loss:0.35293978452682495 --- Running mIOU:0.7472844575958261\n",
      "Train Epoch:25 --- Running Loss:0.3744189143180847 --- Running mIOU:0.7329732027986515\n",
      "Train Epoch:25 --- Running Loss:0.39464274048805237 --- Running mIOU:0.7430514294152983\n",
      "Train Epoch:25 --- Running Loss:0.3633379638195038 --- Running mIOU:0.7200174317007658\n",
      "Train Epoch:26 --- Running Loss:0.3689535856246948 --- Running mIOU:0.7556796263574117\n",
      "Train Epoch:26 --- Running Loss:0.40486761927604675 --- Running mIOU:0.7073112971886456\n",
      "Train Epoch:26 --- Running Loss:0.35729923844337463 --- Running mIOU:0.7380499108251923\n",
      "Train Epoch:26 --- Running Loss:0.4206736385822296 --- Running mIOU:0.681909636836431\n",
      "Train Epoch:26 --- Running Loss:0.40246087312698364 --- Running mIOU:0.7358574731258656\n",
      "Train Epoch:26 --- Running Loss:0.3465166687965393 --- Running mIOU:0.751856680423984\n",
      "Train Epoch:26 --- Running Loss:0.4352923035621643 --- Running mIOU:0.7089112936855508\n",
      "Train Epoch:26 --- Running Loss:0.37101808190345764 --- Running mIOU:0.7515037919551015\n",
      "Train Epoch:26 --- Running Loss:0.3241015076637268 --- Running mIOU:0.7730089505099794\n",
      "Train Epoch:26 --- Running Loss:0.3605082333087921 --- Running mIOU:0.7444918973937193\n",
      "Train Epoch:27 --- Running Loss:0.31902632117271423 --- Running mIOU:0.7945564746552418\n",
      "Train Epoch:27 --- Running Loss:0.2917313277721405 --- Running mIOU:0.7976999185650864\n",
      "Train Epoch:27 --- Running Loss:0.31060969829559326 --- Running mIOU:0.7559611364738698\n",
      "Train Epoch:27 --- Running Loss:0.3070130944252014 --- Running mIOU:0.770286766631145\n",
      "Train Epoch:27 --- Running Loss:0.3313596844673157 --- Running mIOU:0.7264383823590173\n",
      "Train Epoch:27 --- Running Loss:0.32638102769851685 --- Running mIOU:0.7196180275243996\n",
      "Train Epoch:27 --- Running Loss:0.32251471281051636 --- Running mIOU:0.7795871040211066\n",
      "Train Epoch:27 --- Running Loss:0.351672887802124 --- Running mIOU:0.7185184677082097\n",
      "Train Epoch:27 --- Running Loss:0.3399081230163574 --- Running mIOU:0.7674399084783695\n",
      "Train Epoch:27 --- Running Loss:0.37234508991241455 --- Running mIOU:0.7134827463265329\n",
      "Train Epoch:28 --- Running Loss:0.39566367864608765 --- Running mIOU:0.7653752597012584\n",
      "Train Epoch:28 --- Running Loss:0.36890992522239685 --- Running mIOU:0.7339718937408606\n",
      "Train Epoch:28 --- Running Loss:0.3757978677749634 --- Running mIOU:0.7783430906808271\n",
      "Train Epoch:28 --- Running Loss:0.3901602029800415 --- Running mIOU:0.7360264329534243\n",
      "Train Epoch:28 --- Running Loss:0.4200218915939331 --- Running mIOU:0.7010588198415088\n",
      "Train Epoch:28 --- Running Loss:0.4192196726799011 --- Running mIOU:0.7301230461616691\n",
      "Train Epoch:28 --- Running Loss:0.37478774785995483 --- Running mIOU:0.7902248330453476\n",
      "Train Epoch:28 --- Running Loss:0.3957354426383972 --- Running mIOU:0.7257393722877162\n",
      "Train Epoch:28 --- Running Loss:0.35691729187965393 --- Running mIOU:0.7851605625529122\n",
      "Train Epoch:28 --- Running Loss:0.3528033494949341 --- Running mIOU:0.7358713488691981\n",
      "Train Epoch:29 --- Running Loss:0.4102954864501953 --- Running mIOU:0.725890445986848\n",
      "Train Epoch:29 --- Running Loss:0.30248385667800903 --- Running mIOU:0.7688511999482825\n",
      "Train Epoch:29 --- Running Loss:0.4470341205596924 --- Running mIOU:0.6483759639171268\n",
      "Train Epoch:29 --- Running Loss:0.31407591700553894 --- Running mIOU:0.7750911989504906\n",
      "Train Epoch:29 --- Running Loss:0.33322450518608093 --- Running mIOU:0.7787873706718654\n",
      "Train Epoch:29 --- Running Loss:0.38729485869407654 --- Running mIOU:0.729006047769765\n",
      "Train Epoch:29 --- Running Loss:0.32993844151496887 --- Running mIOU:0.7607730721709197\n",
      "Train Epoch:29 --- Running Loss:0.3097480833530426 --- Running mIOU:0.764853805366142\n",
      "Train Epoch:29 --- Running Loss:0.3803180456161499 --- Running mIOU:0.7376237464274931\n",
      "Train Epoch:29 --- Running Loss:0.3378793001174927 --- Running mIOU:0.7456515197327559\n",
      "Train Epoch:30 --- Running Loss:0.3457949459552765 --- Running mIOU:0.7790695236039369\n",
      "Train Epoch:30 --- Running Loss:0.3723781704902649 --- Running mIOU:0.7511983358323588\n",
      "Train Epoch:30 --- Running Loss:0.2841320335865021 --- Running mIOU:0.780800039100991\n",
      "Train Epoch:30 --- Running Loss:0.336912602186203 --- Running mIOU:0.7622187583782998\n",
      "Train Epoch:30 --- Running Loss:0.33545559644699097 --- Running mIOU:0.7489370759043984\n",
      "Train Epoch:30 --- Running Loss:0.3437160551548004 --- Running mIOU:0.7470782904839357\n",
      "Train Epoch:30 --- Running Loss:0.31858137249946594 --- Running mIOU:0.7661151802782229\n",
      "Train Epoch:30 --- Running Loss:0.3551313877105713 --- Running mIOU:0.725720941351788\n",
      "Train Epoch:30 --- Running Loss:0.3314856290817261 --- Running mIOU:0.7528227714702895\n",
      "Train Epoch:30 --- Running Loss:0.3994206488132477 --- Running mIOU:0.736322548862308\n",
      "Running Loss:0.4089086055755615 --- Running mIOU:0.685747544655086\n",
      "Running Loss:0.3841262757778168 --- Running mIOU:0.6558094173710667\n",
      "Running Loss:0.3805065453052521 --- Running mIOU:0.725852200033493\n",
      "Running Loss:0.43875187635421753 --- Running mIOU:0.6817067642309644\n",
      "Running Loss:0.493409663438797 --- Running mIOU:0.6100501828525804\n",
      "Train Epoch:31 --- Running Loss:0.31840357184410095 --- Running mIOU:0.772569766561795\n",
      "Train Epoch:31 --- Running Loss:0.3653981387615204 --- Running mIOU:0.750611668445218\n",
      "Train Epoch:31 --- Running Loss:0.35384079813957214 --- Running mIOU:0.740679758314833\n",
      "Train Epoch:31 --- Running Loss:0.3673204183578491 --- Running mIOU:0.7609901520650113\n",
      "Train Epoch:31 --- Running Loss:0.35965630412101746 --- Running mIOU:0.7476609745960439\n",
      "Train Epoch:31 --- Running Loss:0.32409530878067017 --- Running mIOU:0.7669753698561178\n",
      "Train Epoch:31 --- Running Loss:0.29696154594421387 --- Running mIOU:0.7737370968881597\n",
      "Train Epoch:31 --- Running Loss:0.3799119293689728 --- Running mIOU:0.7229656369417373\n",
      "Train Epoch:31 --- Running Loss:0.32804057002067566 --- Running mIOU:0.7638874727080284\n",
      "Train Epoch:31 --- Running Loss:0.3835625648498535 --- Running mIOU:0.7427423267625619\n",
      "Train Epoch:32 --- Running Loss:0.27564433217048645 --- Running mIOU:0.7896885810335426\n",
      "Train Epoch:32 --- Running Loss:0.3712582588195801 --- Running mIOU:0.7190902040558791\n",
      "Train Epoch:32 --- Running Loss:0.38960346579551697 --- Running mIOU:0.7255317472477728\n",
      "Train Epoch:32 --- Running Loss:0.32877445220947266 --- Running mIOU:0.7832560486235798\n",
      "Train Epoch:32 --- Running Loss:0.30587923526763916 --- Running mIOU:0.7879204886226767\n",
      "Train Epoch:32 --- Running Loss:0.3552522659301758 --- Running mIOU:0.7952788872125458\n",
      "Train Epoch:32 --- Running Loss:0.3604232370853424 --- Running mIOU:0.7593207693245931\n",
      "Train Epoch:32 --- Running Loss:0.3191587030887604 --- Running mIOU:0.775950369276692\n",
      "Train Epoch:32 --- Running Loss:0.33074769377708435 --- Running mIOU:0.7676375128356718\n",
      "Train Epoch:32 --- Running Loss:0.3405977189540863 --- Running mIOU:0.7706546519202315\n",
      "Train Epoch:33 --- Running Loss:0.32655584812164307 --- Running mIOU:0.7366803347374132\n",
      "Train Epoch:33 --- Running Loss:0.31284964084625244 --- Running mIOU:0.7638118422074548\n",
      "Train Epoch:33 --- Running Loss:0.3293510377407074 --- Running mIOU:0.7572030247717123\n",
      "Train Epoch:33 --- Running Loss:0.3375606834888458 --- Running mIOU:0.7460629314248322\n",
      "Train Epoch:33 --- Running Loss:0.3040691614151001 --- Running mIOU:0.7692126980445995\n",
      "Train Epoch:33 --- Running Loss:0.460260808467865 --- Running mIOU:0.6650696628575751\n",
      "Train Epoch:33 --- Running Loss:0.36124736070632935 --- Running mIOU:0.7733720099234244\n",
      "Train Epoch:33 --- Running Loss:0.39506810903549194 --- Running mIOU:0.710501448999079\n",
      "Train Epoch:33 --- Running Loss:0.25151222944259644 --- Running mIOU:0.7746356515425737\n",
      "Train Epoch:33 --- Running Loss:0.31457409262657166 --- Running mIOU:0.7760020988292108\n",
      "Train Epoch:34 --- Running Loss:0.32784295082092285 --- Running mIOU:0.7804385192507879\n",
      "Train Epoch:34 --- Running Loss:0.3558090031147003 --- Running mIOU:0.7698287185052912\n",
      "Train Epoch:34 --- Running Loss:0.32367992401123047 --- Running mIOU:0.7473162534110249\n",
      "Train Epoch:34 --- Running Loss:0.3313406705856323 --- Running mIOU:0.76035617312409\n",
      "Train Epoch:34 --- Running Loss:0.3016115427017212 --- Running mIOU:0.7678978667238827\n",
      "Train Epoch:34 --- Running Loss:0.31951144337654114 --- Running mIOU:0.782201188201867\n",
      "Train Epoch:34 --- Running Loss:0.3445304334163666 --- Running mIOU:0.7613812558616864\n",
      "Train Epoch:34 --- Running Loss:0.3451463282108307 --- Running mIOU:0.7532871468025637\n",
      "Train Epoch:34 --- Running Loss:0.35500380396842957 --- Running mIOU:0.7660656853060689\n",
      "Train Epoch:34 --- Running Loss:0.4430723786354065 --- Running mIOU:0.6998323777971925\n",
      "Train Epoch:35 --- Running Loss:0.313002347946167 --- Running mIOU:0.7507005404497386\n",
      "Train Epoch:35 --- Running Loss:0.3509137034416199 --- Running mIOU:0.7966664411507925\n",
      "Train Epoch:35 --- Running Loss:0.3256227374076843 --- Running mIOU:0.7947245967106031\n",
      "Train Epoch:35 --- Running Loss:0.33511969447135925 --- Running mIOU:0.7575497794128196\n",
      "Train Epoch:35 --- Running Loss:0.28269821405410767 --- Running mIOU:0.7548458253943062\n",
      "Train Epoch:35 --- Running Loss:0.32526928186416626 --- Running mIOU:0.7316906888430599\n",
      "Train Epoch:35 --- Running Loss:0.3391137719154358 --- Running mIOU:0.7598360336255989\n",
      "Train Epoch:35 --- Running Loss:0.31841975450515747 --- Running mIOU:0.7964253223455585\n",
      "Train Epoch:35 --- Running Loss:0.32229799032211304 --- Running mIOU:0.7980227135307245\n",
      "Train Epoch:35 --- Running Loss:0.3276771903038025 --- Running mIOU:0.7228470408118117\n",
      "Train Epoch:36 --- Running Loss:0.36221590638160706 --- Running mIOU:0.7785358679758667\n",
      "Train Epoch:36 --- Running Loss:0.33492475748062134 --- Running mIOU:0.7861107496155049\n",
      "Train Epoch:36 --- Running Loss:0.3142441213130951 --- Running mIOU:0.8255312919944169\n",
      "Train Epoch:36 --- Running Loss:0.3746296763420105 --- Running mIOU:0.760938621642265\n",
      "Train Epoch:36 --- Running Loss:0.3543117642402649 --- Running mIOU:0.777106746287776\n",
      "Train Epoch:36 --- Running Loss:0.33966901898384094 --- Running mIOU:0.7713307068443751\n",
      "Train Epoch:36 --- Running Loss:0.3514334559440613 --- Running mIOU:0.7615113480800322\n",
      "Train Epoch:36 --- Running Loss:0.3620889186859131 --- Running mIOU:0.7649815131526865\n",
      "Train Epoch:36 --- Running Loss:0.34976741671562195 --- Running mIOU:0.7547096899736954\n",
      "Train Epoch:36 --- Running Loss:0.312203586101532 --- Running mIOU:0.812867330596926\n",
      "Train Epoch:37 --- Running Loss:0.38032370805740356 --- Running mIOU:0.7535714712969578\n",
      "Train Epoch:37 --- Running Loss:0.3235895037651062 --- Running mIOU:0.756354046922131\n",
      "Train Epoch:37 --- Running Loss:0.3444831371307373 --- Running mIOU:0.7563510334200142\n",
      "Train Epoch:37 --- Running Loss:0.31117650866508484 --- Running mIOU:0.7984862157214554\n",
      "Train Epoch:37 --- Running Loss:0.3097211420536041 --- Running mIOU:0.7877314428049387\n",
      "Train Epoch:37 --- Running Loss:0.294607549905777 --- Running mIOU:0.789193420703231\n",
      "Train Epoch:37 --- Running Loss:0.27713024616241455 --- Running mIOU:0.7864701836025443\n",
      "Train Epoch:37 --- Running Loss:0.3628622591495514 --- Running mIOU:0.7569911268934422\n",
      "Train Epoch:37 --- Running Loss:0.3126436173915863 --- Running mIOU:0.7833383104501721\n",
      "Train Epoch:37 --- Running Loss:0.3374452590942383 --- Running mIOU:0.7277213258729951\n",
      "Train Epoch:38 --- Running Loss:0.38133811950683594 --- Running mIOU:0.74757786147578\n",
      "Train Epoch:38 --- Running Loss:0.3295902609825134 --- Running mIOU:0.7697209291211258\n",
      "Train Epoch:38 --- Running Loss:0.36467206478118896 --- Running mIOU:0.7856306483755137\n",
      "Train Epoch:38 --- Running Loss:0.38984352350234985 --- Running mIOU:0.7451724652949576\n",
      "Train Epoch:38 --- Running Loss:0.35936450958251953 --- Running mIOU:0.7718491819771913\n",
      "Train Epoch:38 --- Running Loss:0.3919213116168976 --- Running mIOU:0.7047681998946476\n",
      "Train Epoch:38 --- Running Loss:0.3257971704006195 --- Running mIOU:0.7715249441417522\n",
      "Train Epoch:38 --- Running Loss:0.388566792011261 --- Running mIOU:0.7142373906573983\n",
      "Train Epoch:38 --- Running Loss:0.3967517614364624 --- Running mIOU:0.723916543954977\n",
      "Train Epoch:38 --- Running Loss:0.3848034143447876 --- Running mIOU:0.7343182582338292\n",
      "Train Epoch:39 --- Running Loss:0.4010796844959259 --- Running mIOU:0.7536715950690307\n",
      "Train Epoch:39 --- Running Loss:0.41055455803871155 --- Running mIOU:0.7366405651840181\n",
      "Train Epoch:39 --- Running Loss:0.29582932591438293 --- Running mIOU:0.7688097854468189\n",
      "Train Epoch:39 --- Running Loss:0.36071914434432983 --- Running mIOU:0.8032798837330936\n",
      "Train Epoch:39 --- Running Loss:0.3975869417190552 --- Running mIOU:0.7712285141473758\n",
      "Train Epoch:39 --- Running Loss:0.3644936978816986 --- Running mIOU:0.7325770633927483\n",
      "Train Epoch:39 --- Running Loss:0.30722203850746155 --- Running mIOU:0.7699470283179274\n",
      "Train Epoch:39 --- Running Loss:0.3844509720802307 --- Running mIOU:0.7468858174785029\n",
      "Train Epoch:39 --- Running Loss:0.3788958489894867 --- Running mIOU:0.7530825622391737\n",
      "Train Epoch:39 --- Running Loss:0.3153728246688843 --- Running mIOU:0.8034162933730498\n",
      "Train Epoch:40 --- Running Loss:0.3165639042854309 --- Running mIOU:0.7463392497508508\n",
      "Train Epoch:40 --- Running Loss:0.32198795676231384 --- Running mIOU:0.7531961167395984\n",
      "Train Epoch:40 --- Running Loss:0.3427174687385559 --- Running mIOU:0.7826160891193469\n",
      "Train Epoch:40 --- Running Loss:0.3547723889350891 --- Running mIOU:0.768016972763544\n",
      "Train Epoch:40 --- Running Loss:0.36210036277770996 --- Running mIOU:0.7618397584183956\n",
      "Train Epoch:40 --- Running Loss:0.3484629690647125 --- Running mIOU:0.7650751134999143\n",
      "Train Epoch:40 --- Running Loss:0.325344055891037 --- Running mIOU:0.8199162392293133\n",
      "Train Epoch:40 --- Running Loss:0.27512863278388977 --- Running mIOU:0.8102488569831514\n",
      "Train Epoch:40 --- Running Loss:0.3525103032588959 --- Running mIOU:0.7361248356558615\n",
      "Train Epoch:40 --- Running Loss:0.36174482107162476 --- Running mIOU:0.7546005694986346\n",
      "Running Loss:0.3544692099094391 --- Running mIOU:0.7885759332757829\n",
      "Running Loss:0.30637282133102417 --- Running mIOU:0.767338720592023\n",
      "Running Loss:0.3016844391822815 --- Running mIOU:0.7733709894241929\n",
      "Running Loss:0.3108066916465759 --- Running mIOU:0.761734388926519\n",
      "Running Loss:0.4157473146915436 --- Running mIOU:0.7304963753438891\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Train Epoch:41 --- Running Loss:0.276634156703949 --- Running mIOU:0.786727438921385\n",
      "Train Epoch:41 --- Running Loss:0.3646796643733978 --- Running mIOU:0.7590247577603209\n",
      "Train Epoch:41 --- Running Loss:0.38371387124061584 --- Running mIOU:0.74987851651065\n",
      "Train Epoch:41 --- Running Loss:0.32897788286209106 --- Running mIOU:0.7948601173558403\n",
      "Train Epoch:41 --- Running Loss:0.31819719076156616 --- Running mIOU:0.7397646200452024\n",
      "Train Epoch:41 --- Running Loss:0.26862800121307373 --- Running mIOU:0.801130436286019\n",
      "Train Epoch:41 --- Running Loss:0.426194429397583 --- Running mIOU:0.6879869045197131\n",
      "Train Epoch:41 --- Running Loss:0.3193940222263336 --- Running mIOU:0.7889737700858039\n",
      "Train Epoch:41 --- Running Loss:0.2823569178581238 --- Running mIOU:0.7986205075015298\n",
      "Train Epoch:41 --- Running Loss:0.302070289850235 --- Running mIOU:0.7844360973685952\n",
      "Train Epoch:42 --- Running Loss:0.3554193079471588 --- Running mIOU:0.7407660507297682\n",
      "Train Epoch:42 --- Running Loss:0.3780685067176819 --- Running mIOU:0.7896524381023309\n",
      "Train Epoch:42 --- Running Loss:0.27309849858283997 --- Running mIOU:0.766297619864059\n",
      "Train Epoch:42 --- Running Loss:0.3158286511898041 --- Running mIOU:0.7868757593301738\n",
      "Train Epoch:42 --- Running Loss:0.26683950424194336 --- Running mIOU:0.8165027076746684\n",
      "Train Epoch:42 --- Running Loss:0.2298269271850586 --- Running mIOU:0.8272691512907289\n",
      "Train Epoch:42 --- Running Loss:0.2789034843444824 --- Running mIOU:0.810438359105889\n",
      "Train Epoch:42 --- Running Loss:0.3649367094039917 --- Running mIOU:0.7797935522812374\n",
      "Train Epoch:42 --- Running Loss:0.3288911283016205 --- Running mIOU:0.780351568917406\n",
      "Train Epoch:42 --- Running Loss:0.2821158468723297 --- Running mIOU:0.7952575083530574\n",
      "Train Epoch:43 --- Running Loss:0.35330930352211 --- Running mIOU:0.752714486666499\n",
      "Train Epoch:43 --- Running Loss:0.2850026488304138 --- Running mIOU:0.8292631044179084\n",
      "Train Epoch:43 --- Running Loss:0.2709347605705261 --- Running mIOU:0.7734445638874711\n",
      "Train Epoch:43 --- Running Loss:0.2875214219093323 --- Running mIOU:0.8075233401212891\n",
      "Train Epoch:43 --- Running Loss:0.33955249190330505 --- Running mIOU:0.7807386321822904\n",
      "Train Epoch:43 --- Running Loss:0.2857488691806793 --- Running mIOU:0.7543166099087592\n",
      "Train Epoch:43 --- Running Loss:0.30711430311203003 --- Running mIOU:0.747360211953775\n",
      "Train Epoch:43 --- Running Loss:0.36733999848365784 --- Running mIOU:0.7369709123376105\n",
      "Train Epoch:43 --- Running Loss:0.2738856077194214 --- Running mIOU:0.7878575571991225\n",
      "Train Epoch:43 --- Running Loss:0.2736317217350006 --- Running mIOU:0.7710259206297879\n",
      "Train Epoch:44 --- Running Loss:0.3308156430721283 --- Running mIOU:0.79439493346278\n",
      "Train Epoch:44 --- Running Loss:0.364880234003067 --- Running mIOU:0.7268539315049773\n",
      "Train Epoch:44 --- Running Loss:0.3673640191555023 --- Running mIOU:0.7627278298757059\n",
      "Train Epoch:44 --- Running Loss:0.32733750343322754 --- Running mIOU:0.7760399660576844\n",
      "Train Epoch:44 --- Running Loss:0.3205256164073944 --- Running mIOU:0.8057177150290848\n",
      "Train Epoch:44 --- Running Loss:0.3789163827896118 --- Running mIOU:0.7521555785668566\n",
      "Train Epoch:44 --- Running Loss:0.34341487288475037 --- Running mIOU:0.7830140923101281\n",
      "Train Epoch:44 --- Running Loss:0.3441676199436188 --- Running mIOU:0.7824308242365957\n",
      "Train Epoch:44 --- Running Loss:0.2753196358680725 --- Running mIOU:0.7876202385773687\n",
      "Train Epoch:44 --- Running Loss:0.36286377906799316 --- Running mIOU:0.7462330046411194\n",
      "Train Epoch:45 --- Running Loss:0.2917349934577942 --- Running mIOU:0.8051664232465985\n",
      "Train Epoch:45 --- Running Loss:0.2960079312324524 --- Running mIOU:0.8025327864491199\n",
      "Train Epoch:45 --- Running Loss:0.3284547030925751 --- Running mIOU:0.7938994913446968\n",
      "Train Epoch:45 --- Running Loss:0.379939466714859 --- Running mIOU:0.7858885220126379\n",
      "Train Epoch:45 --- Running Loss:0.34812161326408386 --- Running mIOU:0.7948169745156863\n",
      "Train Epoch:45 --- Running Loss:0.3306862711906433 --- Running mIOU:0.7895618577092061\n",
      "Train Epoch:45 --- Running Loss:0.3052613437175751 --- Running mIOU:0.7906203625213373\n",
      "Train Epoch:45 --- Running Loss:0.36130809783935547 --- Running mIOU:0.7358192081839887\n",
      "Train Epoch:45 --- Running Loss:0.32672086358070374 --- Running mIOU:0.773371095375653\n",
      "Train Epoch:45 --- Running Loss:0.4630279541015625 --- Running mIOU:0.6811327807266728\n",
      "Train Epoch:46 --- Running Loss:0.3751178979873657 --- Running mIOU:0.7398647251088835\n",
      "Train Epoch:46 --- Running Loss:0.3502533435821533 --- Running mIOU:0.7680956320531209\n",
      "Train Epoch:46 --- Running Loss:0.371128112077713 --- Running mIOU:0.7405324372613136\n",
      "Train Epoch:46 --- Running Loss:0.3294185698032379 --- Running mIOU:0.7888721907338927\n",
      "Train Epoch:46 --- Running Loss:0.32129088044166565 --- Running mIOU:0.7967271018404425\n",
      "Train Epoch:46 --- Running Loss:0.3331049978733063 --- Running mIOU:0.8280887363322434\n",
      "Train Epoch:46 --- Running Loss:0.36823928356170654 --- Running mIOU:0.7499807379544304\n",
      "Train Epoch:46 --- Running Loss:0.32666316628456116 --- Running mIOU:0.8115398657509507\n",
      "Train Epoch:46 --- Running Loss:0.2653340697288513 --- Running mIOU:0.7936587231046757\n",
      "Train Epoch:46 --- Running Loss:0.29311344027519226 --- Running mIOU:0.7559700574502399\n",
      "Train Epoch:47 --- Running Loss:0.3107508420944214 --- Running mIOU:0.7803919376602094\n",
      "Train Epoch:47 --- Running Loss:0.33309537172317505 --- Running mIOU:0.7880939187043055\n",
      "Train Epoch:47 --- Running Loss:0.368673712015152 --- Running mIOU:0.7507413798879181\n",
      "Train Epoch:47 --- Running Loss:0.25739607214927673 --- Running mIOU:0.7967345149622223\n",
      "Train Epoch:47 --- Running Loss:0.36260196566581726 --- Running mIOU:0.7742452148649294\n",
      "Train Epoch:47 --- Running Loss:0.2678677439689636 --- Running mIOU:0.8157470911310294\n",
      "Train Epoch:47 --- Running Loss:0.3426600694656372 --- Running mIOU:0.7785144864345154\n",
      "Train Epoch:47 --- Running Loss:0.3530995845794678 --- Running mIOU:0.7710999633201606\n",
      "Train Epoch:47 --- Running Loss:0.32683470845222473 --- Running mIOU:0.7582077672598204\n",
      "Train Epoch:47 --- Running Loss:0.3846016228199005 --- Running mIOU:0.7151076102557219\n",
      "Train Epoch:48 --- Running Loss:0.28221917152404785 --- Running mIOU:0.780430547188359\n",
      "Train Epoch:48 --- Running Loss:0.3142792880535126 --- Running mIOU:0.7931113060384242\n",
      "Train Epoch:48 --- Running Loss:0.41371235251426697 --- Running mIOU:0.7755156119674542\n",
      "Train Epoch:48 --- Running Loss:0.37295180559158325 --- Running mIOU:0.7310029913482062\n",
      "Train Epoch:48 --- Running Loss:0.33717769384384155 --- Running mIOU:0.7654602259886456\n",
      "Train Epoch:48 --- Running Loss:0.2949110269546509 --- Running mIOU:0.7801727501072062\n",
      "Train Epoch:48 --- Running Loss:0.3160346448421478 --- Running mIOU:0.7834932692618619\n",
      "Train Epoch:48 --- Running Loss:0.31514784693717957 --- Running mIOU:0.7820000557510232\n",
      "Train Epoch:48 --- Running Loss:0.30823785066604614 --- Running mIOU:0.7933703508115114\n",
      "Train Epoch:48 --- Running Loss:0.2924351990222931 --- Running mIOU:0.7545922027326573\n",
      "Train Epoch:49 --- Running Loss:0.33010584115982056 --- Running mIOU:0.7780138972034867\n",
      "Train Epoch:49 --- Running Loss:0.3469441831111908 --- Running mIOU:0.7603343137908236\n",
      "Train Epoch:49 --- Running Loss:0.3596251308917999 --- Running mIOU:0.7749642155507757\n",
      "Train Epoch:49 --- Running Loss:0.2668550908565521 --- Running mIOU:0.8181292549909092\n",
      "Train Epoch:49 --- Running Loss:0.2971659302711487 --- Running mIOU:0.7843285094000798\n",
      "Train Epoch:49 --- Running Loss:0.32008111476898193 --- Running mIOU:0.7865281400835299\n",
      "Train Epoch:49 --- Running Loss:0.33177852630615234 --- Running mIOU:0.7644885281108804\n",
      "Train Epoch:49 --- Running Loss:0.3741919696331024 --- Running mIOU:0.7661611819305064\n",
      "Train Epoch:49 --- Running Loss:0.32236212491989136 --- Running mIOU:0.7688534382422928\n",
      "Train Epoch:49 --- Running Loss:0.32041966915130615 --- Running mIOU:0.7908782280738393\n",
      "Train Epoch:50 --- Running Loss:0.26047253608703613 --- Running mIOU:0.7774514125514878\n",
      "Train Epoch:50 --- Running Loss:0.2796207368373871 --- Running mIOU:0.7998296502649285\n",
      "Train Epoch:50 --- Running Loss:0.30709537863731384 --- Running mIOU:0.767168482996132\n",
      "Train Epoch:50 --- Running Loss:0.31181660294532776 --- Running mIOU:0.7767753222033204\n",
      "Train Epoch:50 --- Running Loss:0.20138752460479736 --- Running mIOU:0.8448900806901245\n",
      "Train Epoch:50 --- Running Loss:0.21791638433933258 --- Running mIOU:0.8087763666064582\n",
      "Train Epoch:50 --- Running Loss:0.2579520344734192 --- Running mIOU:0.8109325637973392\n",
      "Train Epoch:50 --- Running Loss:0.29430949687957764 --- Running mIOU:0.7856090322845872\n",
      "Train Epoch:50 --- Running Loss:0.29852932691574097 --- Running mIOU:0.749714365176509\n",
      "Train Epoch:50 --- Running Loss:0.2522326111793518 --- Running mIOU:0.7979431038592518\n",
      "Running Loss:0.3431263864040375 --- Running mIOU:0.696087019310541\n",
      "Running Loss:0.36703720688819885 --- Running mIOU:0.7429052916333969\n",
      "Running Loss:0.38918837904930115 --- Running mIOU:0.715395140004101\n",
      "Running Loss:0.4554852843284607 --- Running mIOU:0.6678241900640329\n",
      "Running Loss:0.3659110963344574 --- Running mIOU:0.7392480025248548\n",
      "Train Epoch:51 --- Running Loss:0.34304335713386536 --- Running mIOU:0.795140812494614\n",
      "Train Epoch:51 --- Running Loss:0.27698856592178345 --- Running mIOU:0.8070913618523803\n",
      "Train Epoch:51 --- Running Loss:0.31238478422164917 --- Running mIOU:0.7895862809400158\n",
      "Train Epoch:51 --- Running Loss:0.31178778409957886 --- Running mIOU:0.7748327146337572\n",
      "Train Epoch:51 --- Running Loss:0.35648345947265625 --- Running mIOU:0.7810102041728292\n",
      "Train Epoch:51 --- Running Loss:0.32532998919487 --- Running mIOU:0.7806365499387249\n",
      "Train Epoch:51 --- Running Loss:0.3358342945575714 --- Running mIOU:0.7751564562409825\n",
      "Train Epoch:51 --- Running Loss:0.2993486523628235 --- Running mIOU:0.8100344794981744\n",
      "Train Epoch:51 --- Running Loss:0.26656338572502136 --- Running mIOU:0.8222432137120825\n",
      "Train Epoch:51 --- Running Loss:0.3242112994194031 --- Running mIOU:0.7384922566000733\n",
      "Train Epoch:52 --- Running Loss:0.3421699106693268 --- Running mIOU:0.788206719741886\n",
      "Train Epoch:52 --- Running Loss:0.34068042039871216 --- Running mIOU:0.7701268840532023\n",
      "Train Epoch:52 --- Running Loss:0.317373663187027 --- Running mIOU:0.7970516961600931\n",
      "Train Epoch:52 --- Running Loss:0.36811530590057373 --- Running mIOU:0.7750647048949959\n",
      "Train Epoch:52 --- Running Loss:0.28177329897880554 --- Running mIOU:0.7925826613465256\n",
      "Train Epoch:52 --- Running Loss:0.3227071166038513 --- Running mIOU:0.8088054793277568\n",
      "Train Epoch:52 --- Running Loss:0.29731497168540955 --- Running mIOU:0.809052906387451\n",
      "Train Epoch:52 --- Running Loss:0.3360201120376587 --- Running mIOU:0.7674350077775516\n",
      "Train Epoch:52 --- Running Loss:0.3536123037338257 --- Running mIOU:0.7632751896455563\n",
      "Train Epoch:52 --- Running Loss:0.29760706424713135 --- Running mIOU:0.7695329768683141\n",
      "Train Epoch:53 --- Running Loss:0.2093740999698639 --- Running mIOU:0.8011744010784437\n",
      "Train Epoch:53 --- Running Loss:0.3179783225059509 --- Running mIOU:0.7866399166527873\n",
      "Train Epoch:53 --- Running Loss:0.3339787721633911 --- Running mIOU:0.7575801489884973\n",
      "Train Epoch:53 --- Running Loss:0.33928433060646057 --- Running mIOU:0.8073084995637541\n",
      "Train Epoch:53 --- Running Loss:0.3192179203033447 --- Running mIOU:0.7523742634942396\n",
      "Train Epoch:53 --- Running Loss:0.278913676738739 --- Running mIOU:0.817523020642915\n",
      "Train Epoch:53 --- Running Loss:0.3157344460487366 --- Running mIOU:0.7383482179123342\n",
      "Train Epoch:53 --- Running Loss:0.27485108375549316 --- Running mIOU:0.7881042083716645\n",
      "Train Epoch:53 --- Running Loss:0.3085479438304901 --- Running mIOU:0.7461309040508577\n",
      "Train Epoch:53 --- Running Loss:0.3424835205078125 --- Running mIOU:0.7854136678367876\n",
      "Train Epoch:54 --- Running Loss:0.24535825848579407 --- Running mIOU:0.793184739210146\n",
      "Train Epoch:54 --- Running Loss:0.318431556224823 --- Running mIOU:0.7895649098337839\n",
      "Train Epoch:54 --- Running Loss:0.31804418563842773 --- Running mIOU:0.7802188389167032\n",
      "Train Epoch:54 --- Running Loss:0.3646434247493744 --- Running mIOU:0.8023341389296007\n",
      "Train Epoch:54 --- Running Loss:0.2723282277584076 --- Running mIOU:0.8177260137097834\n",
      "Train Epoch:54 --- Running Loss:0.252020925283432 --- Running mIOU:0.7991804213928106\n",
      "Train Epoch:54 --- Running Loss:0.3728293180465698 --- Running mIOU:0.7637280622323339\n",
      "Train Epoch:54 --- Running Loss:0.3604404032230377 --- Running mIOU:0.7669756768475975\n",
      "Train Epoch:54 --- Running Loss:0.28816214203834534 --- Running mIOU:0.8251849630338627\n",
      "Train Epoch:54 --- Running Loss:0.3507542014122009 --- Running mIOU:0.7700903199858862\n",
      "Train Epoch:55 --- Running Loss:0.3183632791042328 --- Running mIOU:0.7892024680182754\n",
      "Train Epoch:55 --- Running Loss:0.32170170545578003 --- Running mIOU:0.7872587257841714\n",
      "Train Epoch:55 --- Running Loss:0.2599862217903137 --- Running mIOU:0.7788732392868118\n",
      "Train Epoch:55 --- Running Loss:0.2299196422100067 --- Running mIOU:0.8138989645661214\n",
      "Train Epoch:55 --- Running Loss:0.36436647176742554 --- Running mIOU:0.8025927548820513\n",
      "Train Epoch:55 --- Running Loss:0.34382855892181396 --- Running mIOU:0.8000906210335975\n",
      "Train Epoch:55 --- Running Loss:0.3266791105270386 --- Running mIOU:0.7717492716580088\n",
      "Train Epoch:55 --- Running Loss:0.3198719024658203 --- Running mIOU:0.8012490601899944\n",
      "Train Epoch:55 --- Running Loss:0.36063167452812195 --- Running mIOU:0.8257219020622482\n",
      "Train Epoch:55 --- Running Loss:0.25946179032325745 --- Running mIOU:0.7843481233473313\n",
      "Train Epoch:56 --- Running Loss:0.29038742184638977 --- Running mIOU:0.769787783599429\n",
      "Train Epoch:56 --- Running Loss:0.35524746775627136 --- Running mIOU:0.7578735702173196\n",
      "Train Epoch:56 --- Running Loss:0.31039923429489136 --- Running mIOU:0.7914512371425284\n",
      "Train Epoch:56 --- Running Loss:0.31960785388946533 --- Running mIOU:0.7979873493356696\n",
      "Train Epoch:56 --- Running Loss:0.22958259284496307 --- Running mIOU:0.789232838122421\n",
      "Train Epoch:56 --- Running Loss:0.32410094141960144 --- Running mIOU:0.7760115353695689\n",
      "Train Epoch:56 --- Running Loss:0.34510746598243713 --- Running mIOU:0.8040246739002206\n",
      "Train Epoch:56 --- Running Loss:0.2729591727256775 --- Running mIOU:0.7898368196756895\n",
      "Train Epoch:56 --- Running Loss:0.3058164417743683 --- Running mIOU:0.809161194725097\n",
      "Train Epoch:56 --- Running Loss:0.2862900197505951 --- Running mIOU:0.80084087743443\n",
      "Train Epoch:57 --- Running Loss:0.2983521521091461 --- Running mIOU:0.7622634999070808\n",
      "Train Epoch:57 --- Running Loss:0.3305400013923645 --- Running mIOU:0.8096070156607038\n",
      "Train Epoch:57 --- Running Loss:0.1841869056224823 --- Running mIOU:0.8262744428876734\n",
      "Train Epoch:57 --- Running Loss:0.28730279207229614 --- Running mIOU:0.7764743667880101\n",
      "Train Epoch:57 --- Running Loss:0.3071937561035156 --- Running mIOU:0.7934087141825873\n",
      "Train Epoch:57 --- Running Loss:0.23189473152160645 --- Running mIOU:0.8319309719295087\n",
      "Train Epoch:57 --- Running Loss:0.37134337425231934 --- Running mIOU:0.787628274826133\n",
      "Train Epoch:57 --- Running Loss:0.3055759370326996 --- Running mIOU:0.7790355147662855\n",
      "Train Epoch:57 --- Running Loss:0.25649183988571167 --- Running mIOU:0.7848526709274988\n",
      "Train Epoch:57 --- Running Loss:0.338053822517395 --- Running mIOU:0.7604036593228594\n",
      "Train Epoch:58 --- Running Loss:0.3228590488433838 --- Running mIOU:0.7402010592013453\n",
      "Train Epoch:58 --- Running Loss:0.26407647132873535 --- Running mIOU:0.789359806161408\n",
      "Train Epoch:58 --- Running Loss:0.4043198823928833 --- Running mIOU:0.7615739141297873\n",
      "Train Epoch:58 --- Running Loss:0.2619514465332031 --- Running mIOU:0.8224538972321576\n",
      "Train Epoch:58 --- Running Loss:0.34574010968208313 --- Running mIOU:0.7610677332071252\n",
      "Train Epoch:58 --- Running Loss:0.2784182131290436 --- Running mIOU:0.8072209463604227\n",
      "Train Epoch:58 --- Running Loss:0.325937956571579 --- Running mIOU:0.7663236534653985\n",
      "Train Epoch:58 --- Running Loss:0.39125856757164 --- Running mIOU:0.740304771195792\n",
      "Train Epoch:58 --- Running Loss:0.38595613837242126 --- Running mIOU:0.8038762823908558\n",
      "Train Epoch:58 --- Running Loss:0.30503812432289124 --- Running mIOU:0.7776571835095083\n",
      "Train Epoch:59 --- Running Loss:0.3465159833431244 --- Running mIOU:0.7760620713043458\n",
      "Train Epoch:59 --- Running Loss:0.2701750099658966 --- Running mIOU:0.7611023393348526\n",
      "Train Epoch:59 --- Running Loss:0.3120632767677307 --- Running mIOU:0.8099363659574538\n",
      "Train Epoch:59 --- Running Loss:0.32321086525917053 --- Running mIOU:0.7864689895583276\n",
      "Train Epoch:59 --- Running Loss:0.3757847845554352 --- Running mIOU:0.7341861082888674\n",
      "Train Epoch:59 --- Running Loss:0.27461591362953186 --- Running mIOU:0.7687872310804373\n",
      "Train Epoch:59 --- Running Loss:0.3045811951160431 --- Running mIOU:0.8126417405071881\n",
      "Train Epoch:59 --- Running Loss:0.2961874008178711 --- Running mIOU:0.7955924340592365\n",
      "Train Epoch:59 --- Running Loss:0.26990365982055664 --- Running mIOU:0.7983562493638455\n",
      "Train Epoch:59 --- Running Loss:0.31244799494743347 --- Running mIOU:0.7604884568521565\n",
      "Train Epoch:60 --- Running Loss:0.3243068754673004 --- Running mIOU:0.76480232332906\n",
      "Train Epoch:60 --- Running Loss:0.2597719430923462 --- Running mIOU:0.8248192376932191\n",
      "Train Epoch:60 --- Running Loss:0.3327188193798065 --- Running mIOU:0.7271372987683784\n",
      "Train Epoch:60 --- Running Loss:0.303880512714386 --- Running mIOU:0.8072553466806489\n",
      "Train Epoch:60 --- Running Loss:0.34046852588653564 --- Running mIOU:0.8099911215899176\n",
      "Train Epoch:60 --- Running Loss:0.26304891705513 --- Running mIOU:0.8314066920314604\n",
      "Train Epoch:60 --- Running Loss:0.32145655155181885 --- Running mIOU:0.8160001652143009\n",
      "Train Epoch:60 --- Running Loss:0.20305398106575012 --- Running mIOU:0.8057724889921183\n",
      "Train Epoch:60 --- Running Loss:0.3519194722175598 --- Running mIOU:0.7708169604159487\n",
      "Train Epoch:60 --- Running Loss:0.30961400270462036 --- Running mIOU:0.7381371013714328\n",
      "Running Loss:0.4884577691555023 --- Running mIOU:0.6280770120743032\n",
      "Running Loss:0.4231001138687134 --- Running mIOU:0.6739454556456312\n",
      "Running Loss:0.3326873183250427 --- Running mIOU:0.688132584218664\n",
      "Running Loss:0.3763531446456909 --- Running mIOU:0.7220808941141263\n",
      "Running Loss:0.4138655662536621 --- Running mIOU:0.7059972296965655\n",
      "Train Epoch:61 --- Running Loss:0.26492857933044434 --- Running mIOU:0.7765725059988007\n",
      "Train Epoch:61 --- Running Loss:0.32238566875457764 --- Running mIOU:0.7815239479530509\n",
      "Train Epoch:61 --- Running Loss:0.29212528467178345 --- Running mIOU:0.7782925059123409\n",
      "Train Epoch:61 --- Running Loss:0.3377774655818939 --- Running mIOU:0.7817049822462626\n",
      "Train Epoch:61 --- Running Loss:0.28342825174331665 --- Running mIOU:0.7818382528523745\n",
      "Train Epoch:61 --- Running Loss:0.33849725127220154 --- Running mIOU:0.7258162815879556\n",
      "Train Epoch:61 --- Running Loss:0.34038686752319336 --- Running mIOU:0.7888655971691755\n",
      "Train Epoch:61 --- Running Loss:0.35449397563934326 --- Running mIOU:0.781565781527497\n",
      "Train Epoch:61 --- Running Loss:0.2934713661670685 --- Running mIOU:0.8106446237163067\n",
      "Train Epoch:61 --- Running Loss:0.32962581515312195 --- Running mIOU:0.7421224837435446\n",
      "Train Epoch:62 --- Running Loss:0.3556636571884155 --- Running mIOU:0.7914502119490474\n",
      "Train Epoch:62 --- Running Loss:0.3008296489715576 --- Running mIOU:0.7978289624129451\n",
      "Train Epoch:62 --- Running Loss:0.3327023684978485 --- Running mIOU:0.7417721343360413\n",
      "Train Epoch:62 --- Running Loss:0.31150659918785095 --- Running mIOU:0.8143502604241125\n",
      "Train Epoch:62 --- Running Loss:0.29684752225875854 --- Running mIOU:0.7853584721467983\n",
      "Train Epoch:62 --- Running Loss:0.305100679397583 --- Running mIOU:0.8114782267185072\n",
      "Train Epoch:62 --- Running Loss:0.31805020570755005 --- Running mIOU:0.8407730020301776\n",
      "Train Epoch:62 --- Running Loss:0.28485310077667236 --- Running mIOU:0.776105846229165\n",
      "Train Epoch:62 --- Running Loss:0.2801697850227356 --- Running mIOU:0.8025210538469159\n",
      "Train Epoch:62 --- Running Loss:0.25034043192863464 --- Running mIOU:0.7979702309695478\n",
      "Train Epoch:63 --- Running Loss:0.34423819184303284 --- Running mIOU:0.7956350825874927\n",
      "Train Epoch:63 --- Running Loss:0.32859376072883606 --- Running mIOU:0.7635674611897177\n",
      "Train Epoch:63 --- Running Loss:0.33024361729621887 --- Running mIOU:0.7643612055640594\n",
      "Train Epoch:63 --- Running Loss:0.34866979718208313 --- Running mIOU:0.7955886660399891\n",
      "Train Epoch:63 --- Running Loss:0.36801227927207947 --- Running mIOU:0.7479538172195186\n",
      "Train Epoch:63 --- Running Loss:0.2678028345108032 --- Running mIOU:0.7943411573548924\n",
      "Train Epoch:63 --- Running Loss:0.35381245613098145 --- Running mIOU:0.7525370569585742\n",
      "Train Epoch:63 --- Running Loss:0.2990809977054596 --- Running mIOU:0.7917271468715859\n",
      "Train Epoch:63 --- Running Loss:0.24576956033706665 --- Running mIOU:0.8251726134328983\n",
      "Train Epoch:63 --- Running Loss:0.2791202664375305 --- Running mIOU:0.7932611810563336\n",
      "Train Epoch:64 --- Running Loss:0.2707446813583374 --- Running mIOU:0.8025943318890116\n",
      "Train Epoch:64 --- Running Loss:0.3190523386001587 --- Running mIOU:0.7809360191099863\n",
      "Train Epoch:64 --- Running Loss:0.3647114038467407 --- Running mIOU:0.7651658119562874\n",
      "Train Epoch:64 --- Running Loss:0.33795085549354553 --- Running mIOU:0.7265939337974084\n",
      "Train Epoch:64 --- Running Loss:0.3036671280860901 --- Running mIOU:0.8199101311725286\n",
      "Train Epoch:64 --- Running Loss:0.31985682249069214 --- Running mIOU:0.7871917822591047\n",
      "Train Epoch:64 --- Running Loss:0.26196086406707764 --- Running mIOU:0.7958248289449328\n",
      "Train Epoch:64 --- Running Loss:0.28609392046928406 --- Running mIOU:0.8106058893151553\n",
      "Train Epoch:64 --- Running Loss:0.32395243644714355 --- Running mIOU:0.7762485869222973\n",
      "Train Epoch:64 --- Running Loss:0.3550570607185364 --- Running mIOU:0.7353378621134147\n",
      "Train Epoch:65 --- Running Loss:0.2587882876396179 --- Running mIOU:0.847644262722459\n",
      "Train Epoch:65 --- Running Loss:0.29471340775489807 --- Running mIOU:0.8166892313942149\n",
      "Train Epoch:65 --- Running Loss:0.2755917012691498 --- Running mIOU:0.811830673100383\n",
      "Train Epoch:65 --- Running Loss:0.29034581780433655 --- Running mIOU:0.7720101744339951\n",
      "Train Epoch:65 --- Running Loss:0.28901755809783936 --- Running mIOU:0.7733962952970403\n",
      "Train Epoch:65 --- Running Loss:0.3374953269958496 --- Running mIOU:0.7991424441090691\n",
      "Train Epoch:65 --- Running Loss:0.28948935866355896 --- Running mIOU:0.8081508230647205\n",
      "Train Epoch:65 --- Running Loss:0.23531553149223328 --- Running mIOU:0.845165248294922\n",
      "Train Epoch:65 --- Running Loss:0.29800617694854736 --- Running mIOU:0.7783277806776338\n",
      "Train Epoch:65 --- Running Loss:0.3576962947845459 --- Running mIOU:0.7661094440769454\n",
      "Train Epoch:66 --- Running Loss:0.2685677409172058 --- Running mIOU:0.8046899329423054\n",
      "Train Epoch:66 --- Running Loss:0.3320618271827698 --- Running mIOU:0.7456815680243886\n",
      "Train Epoch:66 --- Running Loss:0.3329809308052063 --- Running mIOU:0.7918864314853831\n",
      "Train Epoch:66 --- Running Loss:0.3148599863052368 --- Running mIOU:0.7773184321142232\n",
      "Train Epoch:66 --- Running Loss:0.32705625891685486 --- Running mIOU:0.784810413164309\n",
      "Train Epoch:66 --- Running Loss:0.26322078704833984 --- Running mIOU:0.8048485729255553\n",
      "Train Epoch:66 --- Running Loss:0.2627285420894623 --- Running mIOU:0.8014781288222248\n",
      "Train Epoch:66 --- Running Loss:0.23470847308635712 --- Running mIOU:0.8282576617791753\n",
      "Train Epoch:66 --- Running Loss:0.2988402247428894 --- Running mIOU:0.7889904713443856\n",
      "Train Epoch:66 --- Running Loss:0.31719860434532166 --- Running mIOU:0.8262248221535831\n",
      "Train Epoch:67 --- Running Loss:0.2961482107639313 --- Running mIOU:0.8355593648793971\n",
      "Train Epoch:67 --- Running Loss:0.22192056477069855 --- Running mIOU:0.8096166665465993\n",
      "Train Epoch:67 --- Running Loss:0.2727459669113159 --- Running mIOU:0.7788722644506869\n",
      "Train Epoch:67 --- Running Loss:0.26168927550315857 --- Running mIOU:0.8085395734696811\n",
      "Train Epoch:67 --- Running Loss:0.3474425673484802 --- Running mIOU:0.7552713587887264\n",
      "Train Epoch:67 --- Running Loss:0.30688780546188354 --- Running mIOU:0.7766592615192079\n",
      "Train Epoch:67 --- Running Loss:0.3784741163253784 --- Running mIOU:0.7376689863618318\n",
      "Train Epoch:67 --- Running Loss:0.2894722521305084 --- Running mIOU:0.8065407185952531\n",
      "Train Epoch:67 --- Running Loss:0.30292782187461853 --- Running mIOU:0.8055524623036865\n",
      "Train Epoch:67 --- Running Loss:0.40981337428092957 --- Running mIOU:0.7195695092659286\n",
      "Train Epoch:68 --- Running Loss:0.32471033930778503 --- Running mIOU:0.8170342389521112\n",
      "Train Epoch:68 --- Running Loss:0.3957744538784027 --- Running mIOU:0.754297912202596\n",
      "Train Epoch:68 --- Running Loss:0.37132471799850464 --- Running mIOU:0.7882097970381029\n",
      "Train Epoch:68 --- Running Loss:0.3437381684780121 --- Running mIOU:0.7884357248571869\n",
      "Train Epoch:68 --- Running Loss:0.2791704833507538 --- Running mIOU:0.8222554068559262\n",
      "Train Epoch:68 --- Running Loss:0.2994979918003082 --- Running mIOU:0.8042025842351761\n",
      "Train Epoch:68 --- Running Loss:0.2936858534812927 --- Running mIOU:0.796258348705696\n",
      "Train Epoch:68 --- Running Loss:0.34289899468421936 --- Running mIOU:0.7289854986800833\n",
      "Train Epoch:68 --- Running Loss:0.27587947249412537 --- Running mIOU:0.777936276005114\n",
      "Train Epoch:68 --- Running Loss:0.280557781457901 --- Running mIOU:0.7834580638971924\n",
      "Train Epoch:69 --- Running Loss:0.3594095706939697 --- Running mIOU:0.7788490399319921\n",
      "Train Epoch:69 --- Running Loss:0.29178017377853394 --- Running mIOU:0.7989270592917448\n",
      "Train Epoch:69 --- Running Loss:0.3034089505672455 --- Running mIOU:0.8047196029497781\n",
      "Train Epoch:69 --- Running Loss:0.2741738557815552 --- Running mIOU:0.8137788587997685\n",
      "Train Epoch:69 --- Running Loss:0.37852612137794495 --- Running mIOU:0.7141217896986157\n",
      "Train Epoch:69 --- Running Loss:0.29185745120048523 --- Running mIOU:0.7975879231280998\n",
      "Train Epoch:69 --- Running Loss:0.32612401247024536 --- Running mIOU:0.7437970366613752\n",
      "Train Epoch:69 --- Running Loss:0.24387337267398834 --- Running mIOU:0.8048256094999766\n",
      "Train Epoch:69 --- Running Loss:0.3177083134651184 --- Running mIOU:0.8243271475079135\n",
      "Train Epoch:69 --- Running Loss:0.27787357568740845 --- Running mIOU:0.8329114691195811\n",
      "Train Epoch:70 --- Running Loss:0.30970677733421326 --- Running mIOU:0.8301043193214925\n",
      "Train Epoch:70 --- Running Loss:0.35043466091156006 --- Running mIOU:0.782606588429781\n",
      "Train Epoch:70 --- Running Loss:0.2624364495277405 --- Running mIOU:0.822528081910846\n",
      "Train Epoch:70 --- Running Loss:0.20857113599777222 --- Running mIOU:0.8011778412933703\n",
      "Train Epoch:70 --- Running Loss:0.28191056847572327 --- Running mIOU:0.8399166005796301\n",
      "Train Epoch:70 --- Running Loss:0.24283650517463684 --- Running mIOU:0.8296617218844857\n",
      "Train Epoch:70 --- Running Loss:0.262515127658844 --- Running mIOU:0.8067557501860504\n",
      "Train Epoch:70 --- Running Loss:0.20309554040431976 --- Running mIOU:0.8130403087708231\n",
      "Train Epoch:70 --- Running Loss:0.337491899728775 --- Running mIOU:0.7496192052350757\n",
      "Train Epoch:70 --- Running Loss:0.28358975052833557 --- Running mIOU:0.7421022141706808\n",
      "Running Loss:0.3572900891304016 --- Running mIOU:0.7090449811928918\n",
      "Running Loss:0.3165746331214905 --- Running mIOU:0.7687249631499665\n",
      "Running Loss:0.32796257734298706 --- Running mIOU:0.7443474247066313\n",
      "Running Loss:0.28100478649139404 --- Running mIOU:0.7641010179152035\n",
      "Running Loss:0.3350766897201538 --- Running mIOU:0.7146868045762343\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Train Epoch:71 --- Running Loss:0.25756964087486267 --- Running mIOU:0.8177263919530762\n",
      "Train Epoch:71 --- Running Loss:0.29362979531288147 --- Running mIOU:0.8186134249231555\n",
      "Train Epoch:71 --- Running Loss:0.2058565616607666 --- Running mIOU:0.8270748986130954\n",
      "Train Epoch:71 --- Running Loss:0.2917969226837158 --- Running mIOU:0.8241922564060189\n",
      "Train Epoch:71 --- Running Loss:0.34538906812667847 --- Running mIOU:0.7661194859894389\n",
      "Train Epoch:71 --- Running Loss:0.2749449610710144 --- Running mIOU:0.7864443563193984\n",
      "Train Epoch:71 --- Running Loss:0.3836984932422638 --- Running mIOU:0.7855051475729294\n",
      "Train Epoch:71 --- Running Loss:0.24631209671497345 --- Running mIOU:0.8266713567708882\n",
      "Train Epoch:71 --- Running Loss:0.3483336269855499 --- Running mIOU:0.8024020910069269\n",
      "Train Epoch:71 --- Running Loss:0.3108768165111542 --- Running mIOU:0.7541486876301373\n",
      "Train Epoch:72 --- Running Loss:0.2708691954612732 --- Running mIOU:0.8250628451077435\n",
      "Train Epoch:72 --- Running Loss:0.29029223322868347 --- Running mIOU:0.7946922796220195\n",
      "Train Epoch:72 --- Running Loss:0.2173551619052887 --- Running mIOU:0.8169039159681075\n",
      "Train Epoch:72 --- Running Loss:0.26237615942955017 --- Running mIOU:0.7830805413306996\n",
      "Train Epoch:72 --- Running Loss:0.33088135719299316 --- Running mIOU:0.8033588557655453\n",
      "Train Epoch:72 --- Running Loss:0.3206086754798889 --- Running mIOU:0.8105272812430268\n",
      "Train Epoch:72 --- Running Loss:0.2620403468608856 --- Running mIOU:0.818001504589656\n",
      "Train Epoch:72 --- Running Loss:0.3058900833129883 --- Running mIOU:0.8045189940018715\n",
      "Train Epoch:72 --- Running Loss:0.385819673538208 --- Running mIOU:0.7580336718219001\n",
      "Train Epoch:72 --- Running Loss:0.2742946147918701 --- Running mIOU:0.8434187453643078\n",
      "Train Epoch:73 --- Running Loss:0.22022883594036102 --- Running mIOU:0.8599196415008631\n",
      "Train Epoch:73 --- Running Loss:0.29849478602409363 --- Running mIOU:0.8192355877891597\n",
      "Train Epoch:73 --- Running Loss:0.28400319814682007 --- Running mIOU:0.7802752338011649\n",
      "Train Epoch:73 --- Running Loss:0.2702323794364929 --- Running mIOU:0.8172849849353578\n",
      "Train Epoch:73 --- Running Loss:0.28556838631629944 --- Running mIOU:0.8461378729787923\n",
      "Train Epoch:73 --- Running Loss:0.2821350693702698 --- Running mIOU:0.7983215412612192\n",
      "Train Epoch:73 --- Running Loss:0.30151286721229553 --- Running mIOU:0.79648050593093\n",
      "Train Epoch:73 --- Running Loss:0.25101912021636963 --- Running mIOU:0.8102113178430079\n",
      "Train Epoch:73 --- Running Loss:0.272663414478302 --- Running mIOU:0.8155327821355469\n",
      "Train Epoch:73 --- Running Loss:0.2877504825592041 --- Running mIOU:0.7866321973539092\n",
      "Train Epoch:74 --- Running Loss:0.22560366988182068 --- Running mIOU:0.8263167724474256\n",
      "Train Epoch:74 --- Running Loss:0.2885350286960602 --- Running mIOU:0.801236914992355\n",
      "Train Epoch:74 --- Running Loss:0.27569952607154846 --- Running mIOU:0.809117950969724\n",
      "Train Epoch:74 --- Running Loss:0.3087283670902252 --- Running mIOU:0.8383721089069658\n",
      "Train Epoch:74 --- Running Loss:0.3084503710269928 --- Running mIOU:0.8016016054664962\n",
      "Train Epoch:74 --- Running Loss:0.3066332936286926 --- Running mIOU:0.7704980550723279\n",
      "Train Epoch:74 --- Running Loss:0.2694804072380066 --- Running mIOU:0.8198783702851276\n",
      "Train Epoch:74 --- Running Loss:0.348124623298645 --- Running mIOU:0.7657985801023799\n",
      "Train Epoch:74 --- Running Loss:0.34458333253860474 --- Running mIOU:0.8471101328431239\n",
      "Train Epoch:74 --- Running Loss:0.26409071683883667 --- Running mIOU:0.81714711568875\n",
      "Train Epoch:75 --- Running Loss:0.3575034737586975 --- Running mIOU:0.773735787424781\n",
      "Train Epoch:75 --- Running Loss:0.25203344225883484 --- Running mIOU:0.824985794082244\n",
      "Train Epoch:75 --- Running Loss:0.2535109519958496 --- Running mIOU:0.8188893006303124\n",
      "Train Epoch:75 --- Running Loss:0.3507278859615326 --- Running mIOU:0.8187084823786881\n",
      "Train Epoch:75 --- Running Loss:0.3624085783958435 --- Running mIOU:0.7678886719696153\n",
      "Train Epoch:75 --- Running Loss:0.21391145884990692 --- Running mIOU:0.8410396793945114\n",
      "Train Epoch:75 --- Running Loss:0.27390822768211365 --- Running mIOU:0.786068948436625\n",
      "Train Epoch:75 --- Running Loss:0.34834715723991394 --- Running mIOU:0.8325883800780624\n",
      "Train Epoch:75 --- Running Loss:0.34847140312194824 --- Running mIOU:0.792936214518225\n",
      "Train Epoch:75 --- Running Loss:0.22504673898220062 --- Running mIOU:0.7876139177689064\n",
      "Train Epoch:76 --- Running Loss:0.21185854077339172 --- Running mIOU:0.8480250944303762\n",
      "Train Epoch:76 --- Running Loss:0.17463155090808868 --- Running mIOU:0.8313264923822963\n",
      "Train Epoch:76 --- Running Loss:0.3415902853012085 --- Running mIOU:0.8049327514086411\n",
      "Train Epoch:76 --- Running Loss:0.2715838849544525 --- Running mIOU:0.8017241510606653\n",
      "Train Epoch:76 --- Running Loss:0.2559216618537903 --- Running mIOU:0.8450562205829422\n",
      "Train Epoch:76 --- Running Loss:0.2650868594646454 --- Running mIOU:0.8453986424111709\n",
      "Train Epoch:76 --- Running Loss:0.29301196336746216 --- Running mIOU:0.807697165734659\n",
      "Train Epoch:76 --- Running Loss:0.267436146736145 --- Running mIOU:0.7976819808560713\n",
      "Train Epoch:76 --- Running Loss:0.3197469115257263 --- Running mIOU:0.808876025266398\n",
      "Train Epoch:76 --- Running Loss:0.3361002802848816 --- Running mIOU:0.7692103117075881\n",
      "Train Epoch:77 --- Running Loss:0.2689855992794037 --- Running mIOU:0.8193242823459221\n",
      "Train Epoch:77 --- Running Loss:0.26910310983657837 --- Running mIOU:0.8351589002414951\n",
      "Train Epoch:77 --- Running Loss:0.3103364408016205 --- Running mIOU:0.8217475804357408\n",
      "Train Epoch:77 --- Running Loss:0.2967165410518646 --- Running mIOU:0.7778925694376169\n",
      "Train Epoch:77 --- Running Loss:0.3031293451786041 --- Running mIOU:0.7894679950086891\n",
      "Train Epoch:77 --- Running Loss:0.2843293845653534 --- Running mIOU:0.8144713967341787\n",
      "Train Epoch:77 --- Running Loss:0.30858322978019714 --- Running mIOU:0.7850440544048743\n",
      "Train Epoch:77 --- Running Loss:0.3156088590621948 --- Running mIOU:0.7815225832954452\n",
      "Train Epoch:77 --- Running Loss:0.28433114290237427 --- Running mIOU:0.811721743432843\n",
      "Train Epoch:77 --- Running Loss:0.3014589846134186 --- Running mIOU:0.785488963314698\n",
      "Train Epoch:78 --- Running Loss:0.29425176978111267 --- Running mIOU:0.7732001631872146\n",
      "Train Epoch:78 --- Running Loss:0.25097113847732544 --- Running mIOU:0.810458858721328\n",
      "Train Epoch:78 --- Running Loss:0.3012840151786804 --- Running mIOU:0.7992930018633555\n",
      "Train Epoch:78 --- Running Loss:0.3567301630973816 --- Running mIOU:0.8036420769236894\n",
      "Train Epoch:78 --- Running Loss:0.3110564649105072 --- Running mIOU:0.8215420525671788\n",
      "Train Epoch:78 --- Running Loss:0.38397353887557983 --- Running mIOU:0.8317310314607838\n",
      "Train Epoch:78 --- Running Loss:0.32336297631263733 --- Running mIOU:0.8094360834744139\n",
      "Train Epoch:78 --- Running Loss:0.27965426445007324 --- Running mIOU:0.8107994056213088\n",
      "Train Epoch:78 --- Running Loss:0.32937660813331604 --- Running mIOU:0.7802092793295419\n",
      "Train Epoch:78 --- Running Loss:0.26020583510398865 --- Running mIOU:0.8482020480456051\n",
      "Train Epoch:79 --- Running Loss:0.2729138135910034 --- Running mIOU:0.7996975077778273\n",
      "Train Epoch:79 --- Running Loss:0.24259983003139496 --- Running mIOU:0.7703716873140822\n",
      "Train Epoch:79 --- Running Loss:0.24735578894615173 --- Running mIOU:0.8175641609871724\n",
      "Train Epoch:79 --- Running Loss:0.24248357117176056 --- Running mIOU:0.8268129375810251\n",
      "Train Epoch:79 --- Running Loss:0.2678431272506714 --- Running mIOU:0.7894156775362167\n",
      "Train Epoch:79 --- Running Loss:0.25072339177131653 --- Running mIOU:0.7821354239253915\n",
      "Train Epoch:79 --- Running Loss:0.23993481695652008 --- Running mIOU:0.8383471361019164\n",
      "Train Epoch:79 --- Running Loss:0.33878445625305176 --- Running mIOU:0.778601906400592\n",
      "Train Epoch:79 --- Running Loss:0.21945375204086304 --- Running mIOU:0.840282638324432\n",
      "Train Epoch:79 --- Running Loss:0.2649816870689392 --- Running mIOU:0.809738849796084\n",
      "Train Epoch:80 --- Running Loss:0.24693280458450317 --- Running mIOU:0.8413517384019455\n",
      "Train Epoch:80 --- Running Loss:0.2971462309360504 --- Running mIOU:0.7993255218087423\n",
      "Train Epoch:80 --- Running Loss:0.3020338714122772 --- Running mIOU:0.7696165835651709\n",
      "Train Epoch:80 --- Running Loss:0.28718024492263794 --- Running mIOU:0.7698714445333136\n",
      "Train Epoch:80 --- Running Loss:0.3811871409416199 --- Running mIOU:0.8201537837581552\n",
      "Train Epoch:80 --- Running Loss:0.34505802392959595 --- Running mIOU:0.7643389313432345\n",
      "Train Epoch:80 --- Running Loss:0.3269001245498657 --- Running mIOU:0.7624829760042676\n",
      "Train Epoch:80 --- Running Loss:0.2721971571445465 --- Running mIOU:0.7729797127561551\n",
      "Train Epoch:80 --- Running Loss:0.28073009848594666 --- Running mIOU:0.8384014229840866\n",
      "Train Epoch:80 --- Running Loss:0.2995368242263794 --- Running mIOU:0.7889841012569228\n",
      "Running Loss:0.30560511350631714 --- Running mIOU:0.7280937422337485\n",
      "Running Loss:0.35025110840797424 --- Running mIOU:0.7606012932854769\n",
      "Running Loss:0.36463743448257446 --- Running mIOU:0.7538478538961642\n",
      "Running Loss:0.4037652313709259 --- Running mIOU:0.7024985283358325\n",
      "Running Loss:0.46548980474472046 --- Running mIOU:0.6367458487893165\n",
      "Train Epoch:81 --- Running Loss:0.3212224245071411 --- Running mIOU:0.8152317055092042\n",
      "Train Epoch:81 --- Running Loss:0.28482526540756226 --- Running mIOU:0.8350691048979579\n",
      "Train Epoch:81 --- Running Loss:0.2749633491039276 --- Running mIOU:0.8145324804032607\n",
      "Train Epoch:81 --- Running Loss:0.3543299734592438 --- Running mIOU:0.7563849382337344\n",
      "Train Epoch:81 --- Running Loss:0.3228439390659332 --- Running mIOU:0.7982339316793088\n",
      "Train Epoch:81 --- Running Loss:0.35581281781196594 --- Running mIOU:0.7673398849233082\n",
      "Train Epoch:81 --- Running Loss:0.305265873670578 --- Running mIOU:0.7994158573638019\n",
      "Train Epoch:81 --- Running Loss:0.34757643938064575 --- Running mIOU:0.752584015183829\n",
      "Train Epoch:81 --- Running Loss:0.3216402530670166 --- Running mIOU:0.8199009811668277\n",
      "Train Epoch:81 --- Running Loss:0.24250337481498718 --- Running mIOU:0.8121400997373504\n",
      "Train Epoch:82 --- Running Loss:0.3201567828655243 --- Running mIOU:0.793191592314697\n",
      "Train Epoch:82 --- Running Loss:0.2920700013637543 --- Running mIOU:0.8139238242884252\n",
      "Train Epoch:82 --- Running Loss:0.20533689856529236 --- Running mIOU:0.8169348861345531\n",
      "Train Epoch:82 --- Running Loss:0.268729567527771 --- Running mIOU:0.8265827662105731\n",
      "Train Epoch:82 --- Running Loss:0.2378338724374771 --- Running mIOU:0.7966087074635402\n",
      "Train Epoch:82 --- Running Loss:0.24645179510116577 --- Running mIOU:0.8081886549184449\n",
      "Train Epoch:82 --- Running Loss:0.2774786055088043 --- Running mIOU:0.7843819651026379\n",
      "Train Epoch:82 --- Running Loss:0.26797837018966675 --- Running mIOU:0.828316771673355\n",
      "Train Epoch:82 --- Running Loss:0.2574337124824524 --- Running mIOU:0.7791747826510318\n",
      "Train Epoch:82 --- Running Loss:0.2767726182937622 --- Running mIOU:0.7792717069274674\n",
      "Train Epoch:83 --- Running Loss:0.2884371876716614 --- Running mIOU:0.7970638789456937\n",
      "Train Epoch:83 --- Running Loss:0.20274539291858673 --- Running mIOU:0.8594383509315799\n",
      "Train Epoch:83 --- Running Loss:0.30362871289253235 --- Running mIOU:0.7731876340194928\n",
      "Train Epoch:83 --- Running Loss:0.3658609986305237 --- Running mIOU:0.7670666236682654\n",
      "Train Epoch:83 --- Running Loss:0.1866801530122757 --- Running mIOU:0.8395543146171867\n",
      "Train Epoch:83 --- Running Loss:0.24008449912071228 --- Running mIOU:0.7904227104099535\n",
      "Train Epoch:83 --- Running Loss:0.30486050248146057 --- Running mIOU:0.8444610723063248\n",
      "Train Epoch:83 --- Running Loss:0.2779885530471802 --- Running mIOU:0.7863474532032526\n",
      "Train Epoch:83 --- Running Loss:0.33759158849716187 --- Running mIOU:0.7863082462532327\n",
      "Train Epoch:83 --- Running Loss:0.2826445400714874 --- Running mIOU:0.7886726007603999\n",
      "Train Epoch:84 --- Running Loss:0.3085976243019104 --- Running mIOU:0.8244517953600841\n",
      "Train Epoch:84 --- Running Loss:0.21248549222946167 --- Running mIOU:0.8449393626111452\n",
      "Train Epoch:84 --- Running Loss:0.2750405967235565 --- Running mIOU:0.8091207461883705\n",
      "Train Epoch:84 --- Running Loss:0.34317314624786377 --- Running mIOU:0.7861167926664726\n",
      "Train Epoch:84 --- Running Loss:0.30730730295181274 --- Running mIOU:0.8083893379518996\n",
      "Train Epoch:84 --- Running Loss:0.35969340801239014 --- Running mIOU:0.7323451506255212\n",
      "Train Epoch:84 --- Running Loss:0.33080407977104187 --- Running mIOU:0.7528814680843245\n",
      "Train Epoch:84 --- Running Loss:0.35035789012908936 --- Running mIOU:0.7927563686547521\n",
      "Train Epoch:84 --- Running Loss:0.30776986479759216 --- Running mIOU:0.8074154752755895\n",
      "Train Epoch:84 --- Running Loss:0.29214605689048767 --- Running mIOU:0.768909647604719\n",
      "Train Epoch:85 --- Running Loss:0.26817330718040466 --- Running mIOU:0.8129584049343004\n",
      "Train Epoch:85 --- Running Loss:0.27499985694885254 --- Running mIOU:0.8021944733624644\n",
      "Train Epoch:85 --- Running Loss:0.2818832993507385 --- Running mIOU:0.7763438611347153\n",
      "Train Epoch:85 --- Running Loss:0.3471914827823639 --- Running mIOU:0.7678763469766218\n",
      "Train Epoch:85 --- Running Loss:0.31990817189216614 --- Running mIOU:0.7691690977562501\n",
      "Train Epoch:85 --- Running Loss:0.23989813029766083 --- Running mIOU:0.8176780834500017\n",
      "Train Epoch:85 --- Running Loss:0.3164612650871277 --- Running mIOU:0.790253141157832\n",
      "Train Epoch:85 --- Running Loss:0.2911732792854309 --- Running mIOU:0.7855380047249154\n",
      "Train Epoch:85 --- Running Loss:0.3702978193759918 --- Running mIOU:0.7583240012323393\n",
      "Train Epoch:85 --- Running Loss:0.34547483921051025 --- Running mIOU:0.7396863491133441\n",
      "Train Epoch:86 --- Running Loss:0.23747199773788452 --- Running mIOU:0.8243621546892133\n",
      "Train Epoch:86 --- Running Loss:0.2667401134967804 --- Running mIOU:0.8302186869623852\n",
      "Train Epoch:86 --- Running Loss:0.3839436173439026 --- Running mIOU:0.7466510168851499\n",
      "Train Epoch:86 --- Running Loss:0.26175457239151 --- Running mIOU:0.8213271613927078\n",
      "Train Epoch:86 --- Running Loss:0.4027343690395355 --- Running mIOU:0.7658952489831343\n",
      "Train Epoch:86 --- Running Loss:0.29589158296585083 --- Running mIOU:0.827761897777969\n",
      "Train Epoch:86 --- Running Loss:0.2890493869781494 --- Running mIOU:0.8312511041756291\n",
      "Train Epoch:86 --- Running Loss:0.3893548846244812 --- Running mIOU:0.8194301812002495\n",
      "Train Epoch:86 --- Running Loss:0.2339860051870346 --- Running mIOU:0.8309467959485005\n",
      "Train Epoch:86 --- Running Loss:0.3920827805995941 --- Running mIOU:0.7748892804666693\n",
      "Train Epoch:87 --- Running Loss:0.2707604467868805 --- Running mIOU:0.8116435416981216\n",
      "Train Epoch:87 --- Running Loss:0.2112034261226654 --- Running mIOU:0.8424283973563456\n",
      "Train Epoch:87 --- Running Loss:0.2525542080402374 --- Running mIOU:0.8228014558354653\n",
      "Train Epoch:87 --- Running Loss:0.2513754069805145 --- Running mIOU:0.8163912270568219\n",
      "Train Epoch:87 --- Running Loss:0.24391625821590424 --- Running mIOU:0.8569877615909325\n",
      "Train Epoch:87 --- Running Loss:0.32448872923851013 --- Running mIOU:0.8506849770718196\n",
      "Train Epoch:87 --- Running Loss:0.17222195863723755 --- Running mIOU:0.8634709910257876\n",
      "Train Epoch:87 --- Running Loss:0.3342090845108032 --- Running mIOU:0.7611209268436948\n",
      "Train Epoch:87 --- Running Loss:0.3258220851421356 --- Running mIOU:0.7853065883080033\n",
      "Train Epoch:87 --- Running Loss:0.22381088137626648 --- Running mIOU:0.8207745543610607\n",
      "Train Epoch:88 --- Running Loss:0.2908657193183899 --- Running mIOU:0.8541741528600605\n",
      "Train Epoch:88 --- Running Loss:0.3461421728134155 --- Running mIOU:0.7579206217945755\n",
      "Train Epoch:88 --- Running Loss:0.24357226490974426 --- Running mIOU:0.7796741117165505\n",
      "Train Epoch:88 --- Running Loss:0.21580539643764496 --- Running mIOU:0.8322976830607157\n",
      "Train Epoch:88 --- Running Loss:0.2815275192260742 --- Running mIOU:0.8337952508831632\n",
      "Train Epoch:88 --- Running Loss:0.30514171719551086 --- Running mIOU:0.8282583190909741\n",
      "Train Epoch:88 --- Running Loss:0.2435234636068344 --- Running mIOU:0.8613710505792169\n",
      "Train Epoch:88 --- Running Loss:0.3007376194000244 --- Running mIOU:0.8459966538039853\n",
      "Train Epoch:88 --- Running Loss:0.23838955163955688 --- Running mIOU:0.8456020550328152\n",
      "Train Epoch:88 --- Running Loss:0.2683663070201874 --- Running mIOU:0.8799348822679534\n",
      "Train Epoch:89 --- Running Loss:0.22316059470176697 --- Running mIOU:0.7921603474159544\n",
      "Train Epoch:89 --- Running Loss:0.2565346956253052 --- Running mIOU:0.8353246850388186\n",
      "Train Epoch:89 --- Running Loss:0.20632214844226837 --- Running mIOU:0.7865370168221464\n",
      "Train Epoch:89 --- Running Loss:0.2745892405509949 --- Running mIOU:0.8105973873550869\n",
      "Train Epoch:89 --- Running Loss:0.24547137320041656 --- Running mIOU:0.8118293299289092\n",
      "Train Epoch:89 --- Running Loss:0.348702609539032 --- Running mIOU:0.8180499022341099\n",
      "Train Epoch:89 --- Running Loss:0.3392631709575653 --- Running mIOU:0.7973356263337315\n",
      "Train Epoch:89 --- Running Loss:0.225982666015625 --- Running mIOU:0.8223466060831087\n",
      "Train Epoch:89 --- Running Loss:0.2787659168243408 --- Running mIOU:0.8046814975763671\n",
      "Train Epoch:89 --- Running Loss:0.2339981496334076 --- Running mIOU:0.8366770166576605\n",
      "Train Epoch:90 --- Running Loss:0.3050134778022766 --- Running mIOU:0.8417867671675767\n",
      "Train Epoch:90 --- Running Loss:0.29016420245170593 --- Running mIOU:0.795145247615354\n",
      "Train Epoch:90 --- Running Loss:0.290701299905777 --- Running mIOU:0.8143063207533678\n",
      "Train Epoch:90 --- Running Loss:0.30113282799720764 --- Running mIOU:0.8503562668784634\n",
      "Train Epoch:90 --- Running Loss:0.2554919719696045 --- Running mIOU:0.8031756526932207\n",
      "Train Epoch:90 --- Running Loss:0.2778972089290619 --- Running mIOU:0.817242878773617\n",
      "Train Epoch:90 --- Running Loss:0.22423119843006134 --- Running mIOU:0.8457412309378378\n",
      "Train Epoch:90 --- Running Loss:0.31161758303642273 --- Running mIOU:0.793697765393629\n",
      "Train Epoch:90 --- Running Loss:0.2522536516189575 --- Running mIOU:0.8467675681325548\n",
      "Train Epoch:90 --- Running Loss:0.2872158885002136 --- Running mIOU:0.807611500620497\n",
      "Running Loss:0.30545908212661743 --- Running mIOU:0.7152733234150829\n",
      "Running Loss:0.39071014523506165 --- Running mIOU:0.7277016891574504\n",
      "Running Loss:0.4115987718105316 --- Running mIOU:0.6534460450330608\n",
      "Running Loss:0.3412177264690399 --- Running mIOU:0.6850920220616121\n",
      "Running Loss:0.3778523802757263 --- Running mIOU:0.7603201600819574\n",
      "Train Epoch:91 --- Running Loss:0.20513203740119934 --- Running mIOU:0.822492514980727\n",
      "Train Epoch:91 --- Running Loss:0.2742120325565338 --- Running mIOU:0.8375126636008141\n",
      "Train Epoch:91 --- Running Loss:0.2680538296699524 --- Running mIOU:0.80941213461475\n",
      "Train Epoch:91 --- Running Loss:0.34743550419807434 --- Running mIOU:0.8296624129032448\n",
      "Train Epoch:91 --- Running Loss:0.32457274198532104 --- Running mIOU:0.8297145929021055\n",
      "Train Epoch:91 --- Running Loss:0.3087094724178314 --- Running mIOU:0.823604032459313\n",
      "Train Epoch:91 --- Running Loss:0.299993097782135 --- Running mIOU:0.8016218059082196\n",
      "Train Epoch:91 --- Running Loss:0.2525683343410492 --- Running mIOU:0.86474456747392\n",
      "Train Epoch:91 --- Running Loss:0.2255798578262329 --- Running mIOU:0.8253360526036033\n",
      "Train Epoch:91 --- Running Loss:0.26555323600769043 --- Running mIOU:0.7720376119738299\n",
      "Train Epoch:92 --- Running Loss:0.3368757367134094 --- Running mIOU:0.8030757940168431\n",
      "Train Epoch:92 --- Running Loss:0.27370452880859375 --- Running mIOU:0.8503338154540352\n",
      "Train Epoch:92 --- Running Loss:0.25695037841796875 --- Running mIOU:0.8495295199446424\n",
      "Train Epoch:92 --- Running Loss:0.23063911497592926 --- Running mIOU:0.8375507331569171\n",
      "Train Epoch:92 --- Running Loss:0.2957395315170288 --- Running mIOU:0.7758126595052957\n",
      "Train Epoch:92 --- Running Loss:0.34900757670402527 --- Running mIOU:0.8138286628590088\n",
      "Train Epoch:92 --- Running Loss:0.26157665252685547 --- Running mIOU:0.8427381440944567\n",
      "Train Epoch:92 --- Running Loss:0.27668023109436035 --- Running mIOU:0.8295986743838226\n",
      "Train Epoch:92 --- Running Loss:0.2569172978401184 --- Running mIOU:0.7937438667662708\n",
      "Train Epoch:92 --- Running Loss:0.2365432232618332 --- Running mIOU:0.7706536074064316\n",
      "Train Epoch:93 --- Running Loss:0.3059340715408325 --- Running mIOU:0.8008045404058288\n",
      "Train Epoch:93 --- Running Loss:0.40595516562461853 --- Running mIOU:0.7559657402545927\n",
      "Train Epoch:93 --- Running Loss:0.28088492155075073 --- Running mIOU:0.839486403416517\n",
      "Train Epoch:93 --- Running Loss:0.35462599992752075 --- Running mIOU:0.7630475885584792\n",
      "Train Epoch:93 --- Running Loss:0.20580390095710754 --- Running mIOU:0.8254459929979854\n",
      "Train Epoch:93 --- Running Loss:0.290249764919281 --- Running mIOU:0.7918095900414455\n",
      "Train Epoch:93 --- Running Loss:0.274911493062973 --- Running mIOU:0.8316362031543405\n",
      "Train Epoch:93 --- Running Loss:0.264994353055954 --- Running mIOU:0.8605144519673171\n",
      "Train Epoch:93 --- Running Loss:0.265954852104187 --- Running mIOU:0.8153723136864353\n",
      "Train Epoch:93 --- Running Loss:0.35922670364379883 --- Running mIOU:0.7642691526753007\n",
      "Train Epoch:94 --- Running Loss:0.3228295147418976 --- Running mIOU:0.7610100230919492\n",
      "Train Epoch:94 --- Running Loss:0.309611976146698 --- Running mIOU:0.8482182234012106\n",
      "Train Epoch:94 --- Running Loss:0.2884148061275482 --- Running mIOU:0.8349139363949987\n",
      "Train Epoch:94 --- Running Loss:0.2979280948638916 --- Running mIOU:0.8380962525246203\n",
      "Train Epoch:94 --- Running Loss:0.2637021243572235 --- Running mIOU:0.8276332290503696\n",
      "Train Epoch:94 --- Running Loss:0.18195980787277222 --- Running mIOU:0.8386567592081875\n",
      "Train Epoch:94 --- Running Loss:0.2755909860134125 --- Running mIOU:0.8004919797884261\n",
      "Train Epoch:94 --- Running Loss:0.3014008700847626 --- Running mIOU:0.7939448483244138\n",
      "Train Epoch:94 --- Running Loss:0.2567073702812195 --- Running mIOU:0.8423687797011019\n",
      "Train Epoch:94 --- Running Loss:0.2661820352077484 --- Running mIOU:0.8563934539999687\n",
      "Train Epoch:95 --- Running Loss:0.3433995544910431 --- Running mIOU:0.797785909263039\n",
      "Train Epoch:95 --- Running Loss:0.3175889849662781 --- Running mIOU:0.7729207081727892\n",
      "Train Epoch:95 --- Running Loss:0.2809949815273285 --- Running mIOU:0.8027153357264136\n",
      "Train Epoch:95 --- Running Loss:0.3327096402645111 --- Running mIOU:0.7855727561511492\n",
      "Train Epoch:95 --- Running Loss:0.37243160605430603 --- Running mIOU:0.7728448023117057\n",
      "Train Epoch:95 --- Running Loss:0.2377224713563919 --- Running mIOU:0.83655813897921\n",
      "Train Epoch:95 --- Running Loss:0.3463132977485657 --- Running mIOU:0.8269708495279362\n",
      "Train Epoch:95 --- Running Loss:0.31921684741973877 --- Running mIOU:0.7735514592538768\n",
      "Train Epoch:95 --- Running Loss:0.29095226526260376 --- Running mIOU:0.8488591679407769\n",
      "Train Epoch:95 --- Running Loss:0.2636472284793854 --- Running mIOU:0.8643621141143665\n",
      "Train Epoch:96 --- Running Loss:0.2336091697216034 --- Running mIOU:0.8564878842095366\n",
      "Train Epoch:96 --- Running Loss:0.16953614354133606 --- Running mIOU:0.8436208664910594\n",
      "Train Epoch:96 --- Running Loss:0.27804046869277954 --- Running mIOU:0.8094017402494722\n",
      "Train Epoch:96 --- Running Loss:0.3193773627281189 --- Running mIOU:0.7799797179865223\n",
      "Train Epoch:96 --- Running Loss:0.29966798424720764 --- Running mIOU:0.7942788912754295\n",
      "Train Epoch:96 --- Running Loss:0.2935755252838135 --- Running mIOU:0.7946548075902351\n",
      "Train Epoch:96 --- Running Loss:0.31982171535491943 --- Running mIOU:0.7863312188369509\n",
      "Train Epoch:96 --- Running Loss:0.22880689799785614 --- Running mIOU:0.8430726803102353\n",
      "Train Epoch:96 --- Running Loss:0.24002718925476074 --- Running mIOU:0.8396108816632578\n",
      "Train Epoch:96 --- Running Loss:0.37006038427352905 --- Running mIOU:0.8194315387102228\n",
      "Train Epoch:97 --- Running Loss:0.32763707637786865 --- Running mIOU:0.8448127915720107\n",
      "Train Epoch:97 --- Running Loss:0.29544007778167725 --- Running mIOU:0.8304584351615079\n",
      "Train Epoch:97 --- Running Loss:0.3039678633213043 --- Running mIOU:0.7895928798509058\n",
      "Train Epoch:97 --- Running Loss:0.29014483094215393 --- Running mIOU:0.8586192652087209\n",
      "Train Epoch:97 --- Running Loss:0.29256755113601685 --- Running mIOU:0.8164502744942044\n",
      "Train Epoch:97 --- Running Loss:0.24335576593875885 --- Running mIOU:0.8506450536324269\n",
      "Train Epoch:97 --- Running Loss:0.3522103428840637 --- Running mIOU:0.8191239963957909\n",
      "Train Epoch:97 --- Running Loss:0.27772095799446106 --- Running mIOU:0.7927217631723672\n",
      "Train Epoch:97 --- Running Loss:0.2415243685245514 --- Running mIOU:0.8196289097901193\n",
      "Train Epoch:97 --- Running Loss:0.30538880825042725 --- Running mIOU:0.7929084212959305\n",
      "Train Epoch:98 --- Running Loss:0.26652318239212036 --- Running mIOU:0.808590442683298\n",
      "Train Epoch:98 --- Running Loss:0.2663857638835907 --- Running mIOU:0.787978936144243\n",
      "Train Epoch:98 --- Running Loss:0.22139710187911987 --- Running mIOU:0.8186243600955128\n",
      "Train Epoch:98 --- Running Loss:0.24439772963523865 --- Running mIOU:0.846025214388102\n",
      "Train Epoch:98 --- Running Loss:0.2822054922580719 --- Running mIOU:0.8262073255190043\n",
      "Train Epoch:98 --- Running Loss:0.3302927017211914 --- Running mIOU:0.8330887935310141\n",
      "Train Epoch:98 --- Running Loss:0.3138773441314697 --- Running mIOU:0.806813252599538\n",
      "Train Epoch:98 --- Running Loss:0.32316333055496216 --- Running mIOU:0.7732674238002165\n",
      "Train Epoch:98 --- Running Loss:0.3620993494987488 --- Running mIOU:0.7950650146000149\n",
      "Train Epoch:98 --- Running Loss:0.3569251298904419 --- Running mIOU:0.7702979191834463\n",
      "Train Epoch:99 --- Running Loss:0.2351132482290268 --- Running mIOU:0.8410081716959426\n",
      "Train Epoch:99 --- Running Loss:0.28990790247917175 --- Running mIOU:0.8099704032655819\n",
      "Train Epoch:99 --- Running Loss:0.24233099818229675 --- Running mIOU:0.8080966684426065\n",
      "Train Epoch:99 --- Running Loss:0.2477746605873108 --- Running mIOU:0.8011494497702627\n",
      "Train Epoch:99 --- Running Loss:0.38666200637817383 --- Running mIOU:0.8005924076802657\n",
      "Train Epoch:99 --- Running Loss:0.3133905827999115 --- Running mIOU:0.8151431027904895\n",
      "Train Epoch:99 --- Running Loss:0.270052969455719 --- Running mIOU:0.8173797853491651\n",
      "Train Epoch:99 --- Running Loss:0.3195158839225769 --- Running mIOU:0.8009133771226273\n",
      "Train Epoch:99 --- Running Loss:0.2867589294910431 --- Running mIOU:0.7645796532545017\n",
      "Train Epoch:99 --- Running Loss:0.2120434045791626 --- Running mIOU:0.8336680408880095\n",
      "Train Epoch:100 --- Running Loss:0.37748536467552185 --- Running mIOU:0.8169548853067163\n",
      "Train Epoch:100 --- Running Loss:0.31599903106689453 --- Running mIOU:0.8051786125096568\n",
      "Train Epoch:100 --- Running Loss:0.3050680160522461 --- Running mIOU:0.8138851504342826\n",
      "Train Epoch:100 --- Running Loss:0.18454623222351074 --- Running mIOU:0.8319420693602051\n",
      "Train Epoch:100 --- Running Loss:0.16750511527061462 --- Running mIOU:0.810145078230013\n",
      "Train Epoch:100 --- Running Loss:0.27375417947769165 --- Running mIOU:0.850522526282192\n",
      "Train Epoch:100 --- Running Loss:0.2254306972026825 --- Running mIOU:0.7912868466666017\n",
      "Train Epoch:100 --- Running Loss:0.322887659072876 --- Running mIOU:0.7933435662725289\n",
      "Train Epoch:100 --- Running Loss:0.2476448118686676 --- Running mIOU:0.7964981795530177\n",
      "Train Epoch:100 --- Running Loss:0.2744951546192169 --- Running mIOU:0.8421881769557034\n",
      "Running Loss:0.30544403195381165 --- Running mIOU:0.7582247134182185\n",
      "Running Loss:0.47067421674728394 --- Running mIOU:0.6244217569809999\n",
      "Running Loss:0.34926676750183105 --- Running mIOU:0.7025173102303995\n",
      "Running Loss:0.31038087606430054 --- Running mIOU:0.7594649496412349\n",
      "Running Loss:0.4633621573448181 --- Running mIOU:0.6024303074574213\n",
      "Train Epoch:101 --- Running Loss:0.29691657423973083 --- Running mIOU:0.7780910249964457\n",
      "Train Epoch:101 --- Running Loss:0.27740129828453064 --- Running mIOU:0.8129682076539431\n",
      "Train Epoch:101 --- Running Loss:0.24936872720718384 --- Running mIOU:0.8185072783407357\n",
      "Train Epoch:101 --- Running Loss:0.28377634286880493 --- Running mIOU:0.8298862449631159\n",
      "Train Epoch:101 --- Running Loss:0.30527231097221375 --- Running mIOU:0.8210823287203292\n",
      "Train Epoch:101 --- Running Loss:0.31141555309295654 --- Running mIOU:0.8006415302560616\n",
      "Train Epoch:101 --- Running Loss:0.32706218957901 --- Running mIOU:0.8090717015968114\n",
      "Train Epoch:101 --- Running Loss:0.3230535387992859 --- Running mIOU:0.7913946349042404\n",
      "Train Epoch:101 --- Running Loss:0.2696887254714966 --- Running mIOU:0.8420462490168208\n",
      "Train Epoch:101 --- Running Loss:0.265022337436676 --- Running mIOU:0.8634414874796871\n",
      "Train Epoch:102 --- Running Loss:0.2482314258813858 --- Running mIOU:0.815109031483166\n",
      "Train Epoch:102 --- Running Loss:0.2646426856517792 --- Running mIOU:0.793125857726193\n",
      "Train Epoch:102 --- Running Loss:0.2507348656654358 --- Running mIOU:0.8335944712899056\n",
      "Train Epoch:102 --- Running Loss:0.31746906042099 --- Running mIOU:0.8237205238122334\n",
      "Train Epoch:102 --- Running Loss:0.32552486658096313 --- Running mIOU:0.831710321766199\n",
      "Train Epoch:102 --- Running Loss:0.26444125175476074 --- Running mIOU:0.8240494471417708\n",
      "Train Epoch:102 --- Running Loss:0.2744099497795105 --- Running mIOU:0.8013900697425329\n",
      "Train Epoch:102 --- Running Loss:0.39365437626838684 --- Running mIOU:0.8189293865545944\n",
      "Train Epoch:102 --- Running Loss:0.29311466217041016 --- Running mIOU:0.7748690024476881\n",
      "Train Epoch:102 --- Running Loss:0.2578829526901245 --- Running mIOU:0.8233769862452092\n",
      "Train Epoch:103 --- Running Loss:0.309085488319397 --- Running mIOU:0.8341497927736469\n",
      "Train Epoch:103 --- Running Loss:0.3080180585384369 --- Running mIOU:0.8338266702919488\n",
      "Train Epoch:103 --- Running Loss:0.3360801935195923 --- Running mIOU:0.7944466262366647\n",
      "Train Epoch:103 --- Running Loss:0.3032456338405609 --- Running mIOU:0.8144162397808452\n",
      "Train Epoch:103 --- Running Loss:0.3000408411026001 --- Running mIOU:0.7850520281693216\n",
      "Train Epoch:103 --- Running Loss:0.28319576382637024 --- Running mIOU:0.8203066838298902\n",
      "Train Epoch:103 --- Running Loss:0.294314980506897 --- Running mIOU:0.8197072047915961\n",
      "Train Epoch:103 --- Running Loss:0.3564207851886749 --- Running mIOU:0.785984459461962\n",
      "Train Epoch:103 --- Running Loss:0.25573328137397766 --- Running mIOU:0.8084416469668639\n",
      "Train Epoch:103 --- Running Loss:0.3277263939380646 --- Running mIOU:0.7716561905203783\n",
      "Train Epoch:104 --- Running Loss:0.3603030741214752 --- Running mIOU:0.8160097697544861\n",
      "Train Epoch:104 --- Running Loss:0.3052467107772827 --- Running mIOU:0.7881101310195441\n",
      "Train Epoch:104 --- Running Loss:0.23793591558933258 --- Running mIOU:0.836791293661403\n",
      "Train Epoch:104 --- Running Loss:0.2847011387348175 --- Running mIOU:0.8348635162182108\n",
      "Train Epoch:104 --- Running Loss:0.2813494801521301 --- Running mIOU:0.8517715145065958\n",
      "Train Epoch:104 --- Running Loss:0.2890602946281433 --- Running mIOU:0.8069345246177778\n",
      "Train Epoch:104 --- Running Loss:0.29607415199279785 --- Running mIOU:0.7822137931206155\n",
      "Train Epoch:104 --- Running Loss:0.34143364429473877 --- Running mIOU:0.7948207279330164\n",
      "Train Epoch:104 --- Running Loss:0.29854676127433777 --- Running mIOU:0.8092936917712952\n",
      "Train Epoch:104 --- Running Loss:0.2746075689792633 --- Running mIOU:0.8389099874350532\n",
      "Train Epoch:105 --- Running Loss:0.3187802731990814 --- Running mIOU:0.7670788288518404\n",
      "Train Epoch:105 --- Running Loss:0.2840075194835663 --- Running mIOU:0.7952301254266487\n",
      "Train Epoch:105 --- Running Loss:0.285241961479187 --- Running mIOU:0.8103508861038049\n",
      "Train Epoch:105 --- Running Loss:0.25389015674591064 --- Running mIOU:0.8351978242123624\n",
      "Train Epoch:105 --- Running Loss:0.33087679743766785 --- Running mIOU:0.8353449899828558\n",
      "Train Epoch:105 --- Running Loss:0.3380151093006134 --- Running mIOU:0.7552682974384277\n",
      "Train Epoch:105 --- Running Loss:0.25078698992729187 --- Running mIOU:0.781960124417753\n",
      "Train Epoch:105 --- Running Loss:0.2842542827129364 --- Running mIOU:0.771746088052504\n",
      "Train Epoch:105 --- Running Loss:0.29430535435676575 --- Running mIOU:0.7870729197588594\n",
      "Train Epoch:105 --- Running Loss:0.27836787700653076 --- Running mIOU:0.8062815913821\n",
      "Train Epoch:106 --- Running Loss:0.31503671407699585 --- Running mIOU:0.8237761891627164\n",
      "Train Epoch:106 --- Running Loss:0.2809939682483673 --- Running mIOU:0.825424283581849\n",
      "Train Epoch:106 --- Running Loss:0.1830519288778305 --- Running mIOU:0.8409455226512739\n",
      "Train Epoch:106 --- Running Loss:0.2690996825695038 --- Running mIOU:0.8261561033442018\n",
      "Train Epoch:106 --- Running Loss:0.27196213603019714 --- Running mIOU:0.8402580695979385\n",
      "Train Epoch:106 --- Running Loss:0.2016613483428955 --- Running mIOU:0.8242301420827669\n",
      "Train Epoch:106 --- Running Loss:0.30239298939704895 --- Running mIOU:0.8144642034779312\n",
      "Train Epoch:106 --- Running Loss:0.23485200107097626 --- Running mIOU:0.8473628759300347\n",
      "Train Epoch:106 --- Running Loss:0.25438010692596436 --- Running mIOU:0.8477651331120716\n",
      "Train Epoch:106 --- Running Loss:0.23099341988563538 --- Running mIOU:0.8141514745777968\n",
      "Train Epoch:107 --- Running Loss:0.22082015872001648 --- Running mIOU:0.839410595443457\n",
      "Train Epoch:107 --- Running Loss:0.25364968180656433 --- Running mIOU:0.8377898211357404\n",
      "Train Epoch:107 --- Running Loss:0.30146896839141846 --- Running mIOU:0.7778975472185987\n",
      "Train Epoch:107 --- Running Loss:0.3672480583190918 --- Running mIOU:0.7909138622890308\n",
      "Train Epoch:107 --- Running Loss:0.26482903957366943 --- Running mIOU:0.7941229919659555\n",
      "Train Epoch:107 --- Running Loss:0.23789727687835693 --- Running mIOU:0.8681109191066434\n",
      "Train Epoch:107 --- Running Loss:0.2986544966697693 --- Running mIOU:0.8311364952890854\n",
      "Train Epoch:107 --- Running Loss:0.34365931153297424 --- Running mIOU:0.8316642533606675\n",
      "Train Epoch:107 --- Running Loss:0.2154158055782318 --- Running mIOU:0.824049610669598\n",
      "Train Epoch:107 --- Running Loss:0.24879100918769836 --- Running mIOU:0.7702455520386482\n",
      "Train Epoch:108 --- Running Loss:0.2212008386850357 --- Running mIOU:0.8543340077231008\n",
      "Train Epoch:108 --- Running Loss:0.28842830657958984 --- Running mIOU:0.8254269469126498\n",
      "Train Epoch:108 --- Running Loss:0.229105606675148 --- Running mIOU:0.8158607964037361\n",
      "Train Epoch:108 --- Running Loss:0.2845170795917511 --- Running mIOU:0.799001806630906\n",
      "Train Epoch:108 --- Running Loss:0.235235333442688 --- Running mIOU:0.8302007010017809\n",
      "Train Epoch:108 --- Running Loss:0.20341916382312775 --- Running mIOU:0.8434807493985652\n",
      "Train Epoch:108 --- Running Loss:0.28175660967826843 --- Running mIOU:0.840856382162873\n",
      "Train Epoch:108 --- Running Loss:0.29249095916748047 --- Running mIOU:0.8098980952995032\n",
      "Train Epoch:108 --- Running Loss:0.2169663906097412 --- Running mIOU:0.8429273007799583\n",
      "Train Epoch:108 --- Running Loss:0.3478349447250366 --- Running mIOU:0.8478640296654976\n",
      "Train Epoch:109 --- Running Loss:0.2553747296333313 --- Running mIOU:0.8778072245864257\n",
      "Train Epoch:109 --- Running Loss:0.27703970670700073 --- Running mIOU:0.8287121821295562\n",
      "Train Epoch:109 --- Running Loss:0.26343682408332825 --- Running mIOU:0.8683053053753822\n",
      "Train Epoch:109 --- Running Loss:0.24113550782203674 --- Running mIOU:0.82844959480189\n",
      "Train Epoch:109 --- Running Loss:0.18162569403648376 --- Running mIOU:0.8536553809585652\n",
      "Train Epoch:109 --- Running Loss:0.2295522689819336 --- Running mIOU:0.7955669408491233\n",
      "Train Epoch:109 --- Running Loss:0.21240602433681488 --- Running mIOU:0.8165125922580743\n",
      "Train Epoch:109 --- Running Loss:0.2178792953491211 --- Running mIOU:0.8213919045459357\n",
      "Train Epoch:109 --- Running Loss:0.22703154385089874 --- Running mIOU:0.8610560934413632\n",
      "Train Epoch:109 --- Running Loss:0.3555278182029724 --- Running mIOU:0.7461064759129994\n",
      "Train Epoch:110 --- Running Loss:0.2618887424468994 --- Running mIOU:0.8510771394275871\n",
      "Train Epoch:110 --- Running Loss:0.27053409814834595 --- Running mIOU:0.8041492889588886\n",
      "Train Epoch:110 --- Running Loss:0.2914367914199829 --- Running mIOU:0.8258761963651375\n",
      "Train Epoch:110 --- Running Loss:0.2955060601234436 --- Running mIOU:0.83151715427561\n",
      "Train Epoch:110 --- Running Loss:0.28440937399864197 --- Running mIOU:0.7935072446642694\n",
      "Train Epoch:110 --- Running Loss:0.3753735423088074 --- Running mIOU:0.7540507263104577\n",
      "Train Epoch:110 --- Running Loss:0.24313831329345703 --- Running mIOU:0.8624099495775912\n",
      "Train Epoch:110 --- Running Loss:0.26696962118148804 --- Running mIOU:0.8178776242473491\n",
      "Train Epoch:110 --- Running Loss:0.28904688358306885 --- Running mIOU:0.7971904321584753\n",
      "Train Epoch:110 --- Running Loss:0.3265502452850342 --- Running mIOU:0.7783160403237376\n",
      "Running Loss:0.3525695204734802 --- Running mIOU:0.7556128020074073\n",
      "Running Loss:0.38169580698013306 --- Running mIOU:0.7178005798266814\n",
      "Running Loss:0.4233742356300354 --- Running mIOU:0.6574384504380643\n",
      "Running Loss:0.38955557346343994 --- Running mIOU:0.7183371404395061\n",
      "Running Loss:0.38179048895835876 --- Running mIOU:0.7554129936327224\n",
      "Train Epoch:111 --- Running Loss:0.34129825234413147 --- Running mIOU:0.7943697741829507\n",
      "Train Epoch:111 --- Running Loss:0.293529212474823 --- Running mIOU:0.7662185447669307\n",
      "Train Epoch:111 --- Running Loss:0.26681551337242126 --- Running mIOU:0.7962613259148491\n",
      "Train Epoch:111 --- Running Loss:0.21707159280776978 --- Running mIOU:0.8157252459859763\n",
      "Train Epoch:111 --- Running Loss:0.20884636044502258 --- Running mIOU:0.8452867727760403\n",
      "Train Epoch:111 --- Running Loss:0.3018174469470978 --- Running mIOU:0.8037652519661853\n",
      "Train Epoch:111 --- Running Loss:0.3081570267677307 --- Running mIOU:0.8312461385298782\n",
      "Train Epoch:111 --- Running Loss:0.2511429786682129 --- Running mIOU:0.8279176535292919\n",
      "Train Epoch:111 --- Running Loss:0.266213059425354 --- Running mIOU:0.8030259093988088\n",
      "Train Epoch:111 --- Running Loss:0.2629447877407074 --- Running mIOU:0.7843805530358416\n",
      "Train Epoch:112 --- Running Loss:0.31722939014434814 --- Running mIOU:0.7721310265579714\n",
      "Train Epoch:112 --- Running Loss:0.20485764741897583 --- Running mIOU:0.8682699962436522\n",
      "Train Epoch:112 --- Running Loss:0.3471212387084961 --- Running mIOU:0.765117624045532\n",
      "Train Epoch:112 --- Running Loss:0.33050912618637085 --- Running mIOU:0.8311929191254429\n",
      "Train Epoch:112 --- Running Loss:0.2606874406337738 --- Running mIOU:0.8472858192805646\n",
      "Train Epoch:112 --- Running Loss:0.23428396880626678 --- Running mIOU:0.8424264214013961\n",
      "Train Epoch:112 --- Running Loss:0.3275921046733856 --- Running mIOU:0.8349589583457413\n",
      "Train Epoch:112 --- Running Loss:0.3150790333747864 --- Running mIOU:0.8303844545482488\n",
      "Train Epoch:112 --- Running Loss:0.3338293135166168 --- Running mIOU:0.7965338477099914\n",
      "Train Epoch:112 --- Running Loss:0.3623916208744049 --- Running mIOU:0.7732532382211843\n",
      "Train Epoch:113 --- Running Loss:0.266169011592865 --- Running mIOU:0.850686958034653\n",
      "Train Epoch:113 --- Running Loss:0.2846378982067108 --- Running mIOU:0.8190246194330837\n",
      "Train Epoch:113 --- Running Loss:0.28937435150146484 --- Running mIOU:0.7664723495820719\n",
      "Train Epoch:113 --- Running Loss:0.23238195478916168 --- Running mIOU:0.8859236471455296\n",
      "Train Epoch:113 --- Running Loss:0.3111385107040405 --- Running mIOU:0.8028561573275018\n",
      "Train Epoch:113 --- Running Loss:0.25006675720214844 --- Running mIOU:0.8549266779572262\n",
      "Train Epoch:113 --- Running Loss:0.32728537917137146 --- Running mIOU:0.848860454060128\n",
      "Train Epoch:113 --- Running Loss:0.3202649652957916 --- Running mIOU:0.774391279627842\n",
      "Train Epoch:113 --- Running Loss:0.23569266498088837 --- Running mIOU:0.8406271564247905\n",
      "Train Epoch:113 --- Running Loss:0.2499881088733673 --- Running mIOU:0.8822727486954468\n",
      "Train Epoch:114 --- Running Loss:0.3253147602081299 --- Running mIOU:0.829305015758706\n",
      "Train Epoch:114 --- Running Loss:0.20735296607017517 --- Running mIOU:0.8420674064274413\n",
      "Train Epoch:114 --- Running Loss:0.314273864030838 --- Running mIOU:0.804238388692613\n",
      "Train Epoch:114 --- Running Loss:0.2820659875869751 --- Running mIOU:0.7870154691308009\n",
      "Train Epoch:114 --- Running Loss:0.30617284774780273 --- Running mIOU:0.842166001576216\n",
      "Train Epoch:114 --- Running Loss:0.30592775344848633 --- Running mIOU:0.7867012196462221\n",
      "Train Epoch:114 --- Running Loss:0.2912396192550659 --- Running mIOU:0.8470241202199507\n",
      "Train Epoch:114 --- Running Loss:0.2297976315021515 --- Running mIOU:0.8072864516913774\n",
      "Train Epoch:114 --- Running Loss:0.21859872341156006 --- Running mIOU:0.8622257066698659\n",
      "Train Epoch:114 --- Running Loss:0.39042818546295166 --- Running mIOU:0.7412359664651733\n",
      "Train Epoch:115 --- Running Loss:0.24494485557079315 --- Running mIOU:0.8214202058156483\n",
      "Train Epoch:115 --- Running Loss:0.2637064456939697 --- Running mIOU:0.8246384247248243\n",
      "Train Epoch:115 --- Running Loss:0.2904440760612488 --- Running mIOU:0.8182326412333275\n",
      "Train Epoch:115 --- Running Loss:0.2320818156003952 --- Running mIOU:0.795287179353731\n",
      "Train Epoch:115 --- Running Loss:0.26121047139167786 --- Running mIOU:0.8299120187169547\n",
      "Train Epoch:115 --- Running Loss:0.24652652442455292 --- Running mIOU:0.8174413563007776\n",
      "Train Epoch:115 --- Running Loss:0.2567550837993622 --- Running mIOU:0.8333502935045305\n",
      "Train Epoch:115 --- Running Loss:0.2561075687408447 --- Running mIOU:0.8291075597314983\n",
      "Train Epoch:115 --- Running Loss:0.3555431365966797 --- Running mIOU:0.8042255327675984\n",
      "Train Epoch:115 --- Running Loss:0.230291947722435 --- Running mIOU:0.8126141839772478\n",
      "Train Epoch:116 --- Running Loss:0.33236250281333923 --- Running mIOU:0.7918631712763922\n",
      "Train Epoch:116 --- Running Loss:0.22606304287910461 --- Running mIOU:0.791248290550087\n",
      "Train Epoch:116 --- Running Loss:0.21790680289268494 --- Running mIOU:0.8659666822867564\n",
      "Train Epoch:116 --- Running Loss:0.22176899015903473 --- Running mIOU:0.809776865514303\n",
      "Train Epoch:116 --- Running Loss:0.3064062297344208 --- Running mIOU:0.7995568948375325\n",
      "Train Epoch:116 --- Running Loss:0.3332325518131256 --- Running mIOU:0.7672432249983437\n",
      "Train Epoch:116 --- Running Loss:0.26407137513160706 --- Running mIOU:0.8317430167899587\n",
      "Train Epoch:116 --- Running Loss:0.2508234977722168 --- Running mIOU:0.8732944281518531\n",
      "Train Epoch:116 --- Running Loss:0.26321882009506226 --- Running mIOU:0.8241783319461784\n",
      "Train Epoch:116 --- Running Loss:0.2812426686286926 --- Running mIOU:0.7815577376622118\n",
      "Train Epoch:117 --- Running Loss:0.22000767290592194 --- Running mIOU:0.833170201215539\n",
      "Train Epoch:117 --- Running Loss:0.2827088534832001 --- Running mIOU:0.8300929574831937\n",
      "Train Epoch:117 --- Running Loss:0.3338477313518524 --- Running mIOU:0.791192914486578\n",
      "Train Epoch:117 --- Running Loss:0.2962176203727722 --- Running mIOU:0.847372686700198\n",
      "Train Epoch:117 --- Running Loss:0.2763816714286804 --- Running mIOU:0.7960135145622317\n",
      "Train Epoch:117 --- Running Loss:0.29912370443344116 --- Running mIOU:0.8122904537526576\n",
      "Train Epoch:117 --- Running Loss:0.3304702937602997 --- Running mIOU:0.7812888643291157\n",
      "Train Epoch:117 --- Running Loss:0.2617935538291931 --- Running mIOU:0.8162531141650836\n",
      "Train Epoch:117 --- Running Loss:0.2787279784679413 --- Running mIOU:0.8197071013219341\n",
      "Train Epoch:117 --- Running Loss:0.2251819521188736 --- Running mIOU:0.88326635418958\n",
      "Train Epoch:118 --- Running Loss:0.2970584034919739 --- Running mIOU:0.8119043523179229\n",
      "Train Epoch:118 --- Running Loss:0.29948219656944275 --- Running mIOU:0.8038478885059762\n",
      "Train Epoch:118 --- Running Loss:0.3686661422252655 --- Running mIOU:0.808076630138701\n",
      "Train Epoch:118 --- Running Loss:0.3059816062450409 --- Running mIOU:0.7810551323311532\n",
      "Train Epoch:118 --- Running Loss:0.2473078817129135 --- Running mIOU:0.7944689544012066\n",
      "Train Epoch:118 --- Running Loss:0.2544279992580414 --- Running mIOU:0.8424500758456183\n",
      "Train Epoch:118 --- Running Loss:0.27049124240875244 --- Running mIOU:0.8012725992699836\n",
      "Train Epoch:118 --- Running Loss:0.2640624940395355 --- Running mIOU:0.8176520987514067\n",
      "Train Epoch:118 --- Running Loss:0.29899200797080994 --- Running mIOU:0.7961938554761533\n",
      "Train Epoch:118 --- Running Loss:0.3530992865562439 --- Running mIOU:0.780694189935998\n",
      "Train Epoch:119 --- Running Loss:0.2871628403663635 --- Running mIOU:0.7633596029500656\n",
      "Train Epoch:119 --- Running Loss:0.16882777214050293 --- Running mIOU:0.8323395200987596\n",
      "Train Epoch:119 --- Running Loss:0.25205284357070923 --- Running mIOU:0.8106780973028679\n",
      "Train Epoch:119 --- Running Loss:0.2617757022380829 --- Running mIOU:0.8302486210349472\n",
      "Train Epoch:119 --- Running Loss:0.25018197298049927 --- Running mIOU:0.8040594494109763\n",
      "Train Epoch:119 --- Running Loss:0.2892746329307556 --- Running mIOU:0.7986045838126061\n",
      "Train Epoch:119 --- Running Loss:0.2615415155887604 --- Running mIOU:0.8087543392002631\n",
      "Train Epoch:119 --- Running Loss:0.2517172694206238 --- Running mIOU:0.836191050603057\n",
      "Train Epoch:119 --- Running Loss:0.23855246603488922 --- Running mIOU:0.8332981750080698\n",
      "Train Epoch:119 --- Running Loss:0.2915658950805664 --- Running mIOU:0.8009809012529339\n",
      "Train Epoch:120 --- Running Loss:0.2878609299659729 --- Running mIOU:0.8214228847983892\n",
      "Train Epoch:120 --- Running Loss:0.2664734125137329 --- Running mIOU:0.7963235863044782\n",
      "Train Epoch:120 --- Running Loss:0.2602764964103699 --- Running mIOU:0.8387001386627219\n",
      "Train Epoch:120 --- Running Loss:0.2865831255912781 --- Running mIOU:0.8357244606118561\n",
      "Train Epoch:120 --- Running Loss:0.23613113164901733 --- Running mIOU:0.8249521308702515\n",
      "Train Epoch:120 --- Running Loss:0.3038806915283203 --- Running mIOU:0.7936745191550909\n",
      "Train Epoch:120 --- Running Loss:0.18328028917312622 --- Running mIOU:0.8397751962231808\n",
      "Train Epoch:120 --- Running Loss:0.3218768537044525 --- Running mIOU:0.8544519374987474\n",
      "Train Epoch:120 --- Running Loss:0.20613157749176025 --- Running mIOU:0.8423490513329203\n",
      "Train Epoch:120 --- Running Loss:0.27844828367233276 --- Running mIOU:0.8004093163106505\n",
      "Running Loss:0.34620776772499084 --- Running mIOU:0.7361416697026506\n",
      "Running Loss:0.38528698682785034 --- Running mIOU:0.7408209095647058\n",
      "Running Loss:0.36735954880714417 --- Running mIOU:0.6704608324538346\n",
      "Running Loss:0.38865751028060913 --- Running mIOU:0.7237832076840034\n",
      "Running Loss:0.3757379949092865 --- Running mIOU:0.6814521069737145\n",
      "Train Epoch:121 --- Running Loss:0.25232407450675964 --- Running mIOU:0.8351450475094986\n",
      "Train Epoch:121 --- Running Loss:0.3164648115634918 --- Running mIOU:0.8434474730590713\n",
      "Train Epoch:121 --- Running Loss:0.27187955379486084 --- Running mIOU:0.859560308470517\n",
      "Train Epoch:121 --- Running Loss:0.2959265410900116 --- Running mIOU:0.8205157781618988\n",
      "Train Epoch:121 --- Running Loss:0.30409693717956543 --- Running mIOU:0.824708154247309\n",
      "Train Epoch:121 --- Running Loss:0.27356842160224915 --- Running mIOU:0.8120489686664871\n",
      "Train Epoch:121 --- Running Loss:0.29197630286216736 --- Running mIOU:0.8262774580752603\n",
      "Train Epoch:121 --- Running Loss:0.2733904719352722 --- Running mIOU:0.8329507994062921\n",
      "Train Epoch:121 --- Running Loss:0.33016687631607056 --- Running mIOU:0.807985521986025\n",
      "Train Epoch:121 --- Running Loss:0.2755126953125 --- Running mIOU:0.8366980875705914\n",
      "Train Epoch:122 --- Running Loss:0.32366687059402466 --- Running mIOU:0.8055586149726156\n",
      "Train Epoch:122 --- Running Loss:0.2235458344221115 --- Running mIOU:0.8450616820089456\n",
      "Train Epoch:122 --- Running Loss:0.2713094651699066 --- Running mIOU:0.8473722082829687\n",
      "Train Epoch:122 --- Running Loss:0.28516262769699097 --- Running mIOU:0.7920101732029861\n",
      "Train Epoch:122 --- Running Loss:0.2503450810909271 --- Running mIOU:0.8013407896694262\n",
      "Train Epoch:122 --- Running Loss:0.24037760496139526 --- Running mIOU:0.7951350700566279\n",
      "Train Epoch:122 --- Running Loss:0.24396994709968567 --- Running mIOU:0.847417922442545\n",
      "Train Epoch:122 --- Running Loss:0.3004775643348694 --- Running mIOU:0.8379423706017348\n",
      "Train Epoch:122 --- Running Loss:0.23817315697669983 --- Running mIOU:0.8117134525681755\n",
      "Train Epoch:122 --- Running Loss:0.37715667486190796 --- Running mIOU:0.6980353513558347\n",
      "Train Epoch:123 --- Running Loss:0.2840314507484436 --- Running mIOU:0.7891864671229738\n",
      "Train Epoch:123 --- Running Loss:0.2542703449726105 --- Running mIOU:0.8518568369495507\n",
      "Train Epoch:123 --- Running Loss:0.22803384065628052 --- Running mIOU:0.8902125331139459\n",
      "Train Epoch:123 --- Running Loss:0.3372538685798645 --- Running mIOU:0.7798239693906098\n",
      "Train Epoch:123 --- Running Loss:0.22323700785636902 --- Running mIOU:0.8294448956407756\n",
      "Train Epoch:123 --- Running Loss:0.268947571516037 --- Running mIOU:0.8203572029279045\n",
      "Train Epoch:123 --- Running Loss:0.23539841175079346 --- Running mIOU:0.8232170833922242\n",
      "Train Epoch:123 --- Running Loss:0.3116055130958557 --- Running mIOU:0.8223891584137293\n",
      "Train Epoch:123 --- Running Loss:0.2961590588092804 --- Running mIOU:0.8310765064844303\n",
      "Train Epoch:123 --- Running Loss:0.22920989990234375 --- Running mIOU:0.86936285628688\n",
      "Train Epoch:124 --- Running Loss:0.2575231194496155 --- Running mIOU:0.8153807107514538\n",
      "Train Epoch:124 --- Running Loss:0.2736683487892151 --- Running mIOU:0.838709555141588\n",
      "Train Epoch:124 --- Running Loss:0.27179381251335144 --- Running mIOU:0.8492777889666819\n",
      "Train Epoch:124 --- Running Loss:0.2336786687374115 --- Running mIOU:0.8288805393251998\n",
      "Train Epoch:124 --- Running Loss:0.31557103991508484 --- Running mIOU:0.7617661259944686\n",
      "Train Epoch:124 --- Running Loss:0.3276241719722748 --- Running mIOU:0.8083619846036487\n",
      "Train Epoch:124 --- Running Loss:0.2334606796503067 --- Running mIOU:0.8701386898477002\n",
      "Train Epoch:124 --- Running Loss:0.36167073249816895 --- Running mIOU:0.8512245460506076\n",
      "Train Epoch:124 --- Running Loss:0.2802126109600067 --- Running mIOU:0.8132450186446304\n",
      "Train Epoch:124 --- Running Loss:0.3310243487358093 --- Running mIOU:0.7547628146032435\n",
      "Train Epoch:125 --- Running Loss:0.25458332896232605 --- Running mIOU:0.8431213769219201\n",
      "Train Epoch:125 --- Running Loss:0.2965885400772095 --- Running mIOU:0.7897123492952556\n",
      "Train Epoch:125 --- Running Loss:0.2487211525440216 --- Running mIOU:0.8333760799367921\n",
      "Train Epoch:125 --- Running Loss:0.16938766837120056 --- Running mIOU:0.8648553863137811\n",
      "Train Epoch:125 --- Running Loss:0.2759774625301361 --- Running mIOU:0.8287471349232554\n",
      "Train Epoch:125 --- Running Loss:0.25349414348602295 --- Running mIOU:0.852735274830867\n",
      "Train Epoch:125 --- Running Loss:0.2533734440803528 --- Running mIOU:0.810235213167573\n",
      "Train Epoch:125 --- Running Loss:0.39489227533340454 --- Running mIOU:0.7346187046725055\n",
      "Train Epoch:125 --- Running Loss:0.29734519124031067 --- Running mIOU:0.8500636002885682\n",
      "Train Epoch:125 --- Running Loss:0.2606506645679474 --- Running mIOU:0.8536482977240034\n",
      "Train Epoch:126 --- Running Loss:0.2943801283836365 --- Running mIOU:0.8204149652615239\n",
      "Train Epoch:126 --- Running Loss:0.25057631731033325 --- Running mIOU:0.8539085906817043\n",
      "Train Epoch:126 --- Running Loss:0.26240429282188416 --- Running mIOU:0.8467410237569801\n",
      "Train Epoch:126 --- Running Loss:0.24628718197345734 --- Running mIOU:0.8145596795382086\n",
      "Train Epoch:126 --- Running Loss:0.23656408488750458 --- Running mIOU:0.8705594019497995\n",
      "Train Epoch:126 --- Running Loss:0.24198879301548004 --- Running mIOU:0.8425506235483187\n",
      "Train Epoch:126 --- Running Loss:0.18525220453739166 --- Running mIOU:0.863494931001896\n",
      "Train Epoch:126 --- Running Loss:0.2869856655597687 --- Running mIOU:0.8561047351504378\n",
      "Train Epoch:126 --- Running Loss:0.27951711416244507 --- Running mIOU:0.8464807190561707\n",
      "Train Epoch:126 --- Running Loss:0.25818562507629395 --- Running mIOU:0.8539740048471727\n",
      "Train Epoch:127 --- Running Loss:0.3475903868675232 --- Running mIOU:0.8004645102301496\n",
      "Train Epoch:127 --- Running Loss:0.312707781791687 --- Running mIOU:0.7909670575841932\n",
      "Train Epoch:127 --- Running Loss:0.1816093474626541 --- Running mIOU:0.875861650626179\n",
      "Train Epoch:127 --- Running Loss:0.31328532099723816 --- Running mIOU:0.7895426078581322\n",
      "Train Epoch:127 --- Running Loss:0.2834882438182831 --- Running mIOU:0.822739692483571\n",
      "Train Epoch:127 --- Running Loss:0.20129573345184326 --- Running mIOU:0.8980957578311477\n",
      "Train Epoch:127 --- Running Loss:0.28908994793891907 --- Running mIOU:0.8349566069116724\n",
      "Train Epoch:127 --- Running Loss:0.2626410126686096 --- Running mIOU:0.802102595214716\n",
      "Train Epoch:127 --- Running Loss:0.2640611231327057 --- Running mIOU:0.812210318371646\n",
      "Train Epoch:127 --- Running Loss:0.22898773849010468 --- Running mIOU:0.8182965000374731\n",
      "Train Epoch:128 --- Running Loss:0.2350815087556839 --- Running mIOU:0.8703304078629339\n",
      "Train Epoch:128 --- Running Loss:0.29828596115112305 --- Running mIOU:0.8212132394027953\n",
      "Train Epoch:128 --- Running Loss:0.1836611032485962 --- Running mIOU:0.8741531287042348\n",
      "Train Epoch:128 --- Running Loss:0.2730906009674072 --- Running mIOU:0.8451365071141186\n",
      "Train Epoch:128 --- Running Loss:0.24921004474163055 --- Running mIOU:0.8426851137229533\n",
      "Train Epoch:128 --- Running Loss:0.3173871636390686 --- Running mIOU:0.7993055003965615\n",
      "Train Epoch:128 --- Running Loss:0.19347509741783142 --- Running mIOU:0.861617626018598\n",
      "Train Epoch:128 --- Running Loss:0.2132992297410965 --- Running mIOU:0.8423095148972539\n",
      "Train Epoch:128 --- Running Loss:0.25868698954582214 --- Running mIOU:0.845015405186025\n",
      "Train Epoch:128 --- Running Loss:0.19666911661624908 --- Running mIOU:0.8525036475087451\n",
      "Train Epoch:129 --- Running Loss:0.32744699716567993 --- Running mIOU:0.8007141833586621\n",
      "Train Epoch:129 --- Running Loss:0.23359496891498566 --- Running mIOU:0.8312012126866499\n",
      "Train Epoch:129 --- Running Loss:0.321662038564682 --- Running mIOU:0.8158246822452814\n",
      "Train Epoch:129 --- Running Loss:0.24760691821575165 --- Running mIOU:0.8172820359122005\n",
      "Train Epoch:129 --- Running Loss:0.2721821963787079 --- Running mIOU:0.8813213364188586\n",
      "Train Epoch:129 --- Running Loss:0.3144833743572235 --- Running mIOU:0.7988671931851505\n",
      "Train Epoch:129 --- Running Loss:0.20202888548374176 --- Running mIOU:0.8557388567431126\n",
      "Train Epoch:129 --- Running Loss:0.2617338001728058 --- Running mIOU:0.8648996030051394\n",
      "Train Epoch:129 --- Running Loss:0.3118131160736084 --- Running mIOU:0.8213817713941192\n",
      "Train Epoch:129 --- Running Loss:0.3582848906517029 --- Running mIOU:0.7482686494680569\n",
      "Train Epoch:130 --- Running Loss:0.3204689025878906 --- Running mIOU:0.8195780615728191\n",
      "Train Epoch:130 --- Running Loss:0.18281829357147217 --- Running mIOU:0.8120432344991455\n",
      "Train Epoch:130 --- Running Loss:0.2671133577823639 --- Running mIOU:0.816307571798903\n",
      "Train Epoch:130 --- Running Loss:0.2543438673019409 --- Running mIOU:0.8206821691672836\n",
      "Train Epoch:130 --- Running Loss:0.16523613035678864 --- Running mIOU:0.9011697484762444\n",
      "Train Epoch:130 --- Running Loss:0.2013297975063324 --- Running mIOU:0.8525121091661197\n",
      "Train Epoch:130 --- Running Loss:0.3104592561721802 --- Running mIOU:0.839185463979996\n",
      "Train Epoch:130 --- Running Loss:0.2913525700569153 --- Running mIOU:0.7792805947531098\n",
      "Train Epoch:130 --- Running Loss:0.30722877383232117 --- Running mIOU:0.8029605461075704\n",
      "Train Epoch:130 --- Running Loss:0.30199769139289856 --- Running mIOU:0.8589961312856036\n",
      "Running Loss:0.40711709856987 --- Running mIOU:0.6470835911321019\n",
      "Running Loss:0.373572438955307 --- Running mIOU:0.7301512427809563\n",
      "Running Loss:0.2854062616825104 --- Running mIOU:0.7755056976994179\n",
      "Running Loss:0.33016645908355713 --- Running mIOU:0.7508743564428145\n",
      "Running Loss:0.3562735319137573 --- Running mIOU:0.7052159869381137\n",
      "Train Epoch:131 --- Running Loss:0.274362176656723 --- Running mIOU:0.8051808800118823\n",
      "Train Epoch:131 --- Running Loss:0.2077288031578064 --- Running mIOU:0.8337344972414114\n",
      "Train Epoch:131 --- Running Loss:0.23809395730495453 --- Running mIOU:0.853812664576255\n",
      "Train Epoch:131 --- Running Loss:0.20830613374710083 --- Running mIOU:0.8396505606062701\n",
      "Train Epoch:131 --- Running Loss:0.2363329976797104 --- Running mIOU:0.8678542645870457\n",
      "Train Epoch:131 --- Running Loss:0.2687240242958069 --- Running mIOU:0.8229295634151222\n",
      "Train Epoch:131 --- Running Loss:0.3086186647415161 --- Running mIOU:0.8183803967623831\n",
      "Train Epoch:131 --- Running Loss:0.2903374135494232 --- Running mIOU:0.8611555388825403\n",
      "Train Epoch:131 --- Running Loss:0.2524963617324829 --- Running mIOU:0.8824126539328985\n",
      "Train Epoch:131 --- Running Loss:0.2492551952600479 --- Running mIOU:0.8646025004990485\n",
      "Train Epoch:132 --- Running Loss:0.2878543734550476 --- Running mIOU:0.8634500938416171\n",
      "Train Epoch:132 --- Running Loss:0.26049327850341797 --- Running mIOU:0.8040520986672449\n",
      "Train Epoch:132 --- Running Loss:0.3062335252761841 --- Running mIOU:0.8158439732264156\n",
      "Train Epoch:132 --- Running Loss:0.27361148595809937 --- Running mIOU:0.8955210695159888\n",
      "Train Epoch:132 --- Running Loss:0.25674861669540405 --- Running mIOU:0.7979418102872013\n",
      "Train Epoch:132 --- Running Loss:0.15968692302703857 --- Running mIOU:0.8742587146070104\n",
      "Train Epoch:132 --- Running Loss:0.20888353884220123 --- Running mIOU:0.8277671861697886\n",
      "Train Epoch:132 --- Running Loss:0.3002913296222687 --- Running mIOU:0.7991486740653364\n",
      "Train Epoch:132 --- Running Loss:0.3192979693412781 --- Running mIOU:0.8057556754993154\n",
      "Train Epoch:132 --- Running Loss:0.27849462628364563 --- Running mIOU:0.8383000421719419\n",
      "Train Epoch:133 --- Running Loss:0.2526457905769348 --- Running mIOU:0.8494997912546989\n",
      "Train Epoch:133 --- Running Loss:0.240687295794487 --- Running mIOU:0.8344130005213934\n",
      "Train Epoch:133 --- Running Loss:0.31746307015419006 --- Running mIOU:0.84946206254606\n",
      "Train Epoch:133 --- Running Loss:0.29157739877700806 --- Running mIOU:0.868733160335299\n",
      "Train Epoch:133 --- Running Loss:0.2747642695903778 --- Running mIOU:0.859530067200394\n",
      "Train Epoch:133 --- Running Loss:0.18651743233203888 --- Running mIOU:0.8593157929733193\n",
      "Train Epoch:133 --- Running Loss:0.3084518313407898 --- Running mIOU:0.8250043111022203\n",
      "Train Epoch:133 --- Running Loss:0.24306368827819824 --- Running mIOU:0.8045799746665089\n",
      "Train Epoch:133 --- Running Loss:0.2396565079689026 --- Running mIOU:0.8669736528196417\n",
      "Train Epoch:133 --- Running Loss:0.33628255128860474 --- Running mIOU:0.7783435558525755\n",
      "Train Epoch:134 --- Running Loss:0.3174140453338623 --- Running mIOU:0.7885440134541264\n",
      "Train Epoch:134 --- Running Loss:0.22036825120449066 --- Running mIOU:0.8178911631784697\n",
      "Train Epoch:134 --- Running Loss:0.2773601710796356 --- Running mIOU:0.8566389088646769\n",
      "Train Epoch:134 --- Running Loss:0.3521922528743744 --- Running mIOU:0.8155301530258083\n",
      "Train Epoch:134 --- Running Loss:0.287131130695343 --- Running mIOU:0.8285900486698381\n",
      "Train Epoch:134 --- Running Loss:0.30737045407295227 --- Running mIOU:0.8162043016743039\n",
      "Train Epoch:134 --- Running Loss:0.27941685914993286 --- Running mIOU:0.8628712014841988\n",
      "Train Epoch:134 --- Running Loss:0.3012687861919403 --- Running mIOU:0.7617362599513684\n",
      "Train Epoch:134 --- Running Loss:0.2580452263355255 --- Running mIOU:0.8674382385709997\n",
      "Train Epoch:134 --- Running Loss:0.34029898047447205 --- Running mIOU:0.7971363762156602\n",
      "Train Epoch:135 --- Running Loss:0.25424474477767944 --- Running mIOU:0.838450933029903\n",
      "Train Epoch:135 --- Running Loss:0.23645365238189697 --- Running mIOU:0.8381497796939311\n",
      "Train Epoch:135 --- Running Loss:0.2823689877986908 --- Running mIOU:0.8177528626672675\n",
      "Train Epoch:135 --- Running Loss:0.26642701029777527 --- Running mIOU:0.8151638582613121\n",
      "Train Epoch:135 --- Running Loss:0.2997896075248718 --- Running mIOU:0.8341580886601058\n",
      "Train Epoch:135 --- Running Loss:0.27402830123901367 --- Running mIOU:0.8147682108262411\n",
      "Train Epoch:135 --- Running Loss:0.2871043086051941 --- Running mIOU:0.8208718800124419\n",
      "Train Epoch:135 --- Running Loss:0.24935011565685272 --- Running mIOU:0.8524725444360477\n",
      "Train Epoch:135 --- Running Loss:0.25398629903793335 --- Running mIOU:0.8671942200870131\n",
      "Train Epoch:135 --- Running Loss:0.313433974981308 --- Running mIOU:0.8891617953363005\n",
      "Train Epoch:136 --- Running Loss:0.30928027629852295 --- Running mIOU:0.757228954177009\n",
      "Train Epoch:136 --- Running Loss:0.2975257933139801 --- Running mIOU:0.7851233416528336\n",
      "Train Epoch:136 --- Running Loss:0.356798380613327 --- Running mIOU:0.8722781354106219\n",
      "Train Epoch:136 --- Running Loss:0.21213816106319427 --- Running mIOU:0.8609381457564165\n",
      "Train Epoch:136 --- Running Loss:0.2764377295970917 --- Running mIOU:0.8508321470310556\n",
      "Train Epoch:136 --- Running Loss:0.2249075025320053 --- Running mIOU:0.8453884761305861\n",
      "Train Epoch:136 --- Running Loss:0.21820995211601257 --- Running mIOU:0.8362327768991085\n",
      "Train Epoch:136 --- Running Loss:0.1991020292043686 --- Running mIOU:0.8542844471803464\n",
      "Train Epoch:136 --- Running Loss:0.37175697088241577 --- Running mIOU:0.7280850362349531\n",
      "Train Epoch:136 --- Running Loss:0.32269901037216187 --- Running mIOU:0.8578666982555176\n",
      "Train Epoch:137 --- Running Loss:0.26505303382873535 --- Running mIOU:0.8396214436383148\n",
      "Train Epoch:137 --- Running Loss:0.1807435303926468 --- Running mIOU:0.8699064952386668\n",
      "Train Epoch:137 --- Running Loss:0.28656017780303955 --- Running mIOU:0.7612630077358649\n",
      "Train Epoch:137 --- Running Loss:0.3026466369628906 --- Running mIOU:0.8422182286104792\n",
      "Train Epoch:137 --- Running Loss:0.31366944313049316 --- Running mIOU:0.8483675035790974\n",
      "Train Epoch:137 --- Running Loss:0.3230209946632385 --- Running mIOU:0.7913549354326916\n",
      "Train Epoch:137 --- Running Loss:0.21952246129512787 --- Running mIOU:0.8208021655231839\n",
      "Train Epoch:137 --- Running Loss:0.3349037766456604 --- Running mIOU:0.7434146948860438\n",
      "Train Epoch:137 --- Running Loss:0.21130481362342834 --- Running mIOU:0.8471134416821688\n",
      "Train Epoch:137 --- Running Loss:0.3409435749053955 --- Running mIOU:0.7888357430765498\n",
      "Train Epoch:138 --- Running Loss:0.2455577552318573 --- Running mIOU:0.8024531507848134\n",
      "Train Epoch:138 --- Running Loss:0.25850710272789 --- Running mIOU:0.8443400107402801\n",
      "Train Epoch:138 --- Running Loss:0.33035916090011597 --- Running mIOU:0.8053440385579473\n",
      "Train Epoch:138 --- Running Loss:0.2856505513191223 --- Running mIOU:0.8195663672553412\n",
      "Train Epoch:138 --- Running Loss:0.2626803517341614 --- Running mIOU:0.8576834621970021\n",
      "Train Epoch:138 --- Running Loss:0.2383163422346115 --- Running mIOU:0.8082403917915693\n",
      "Train Epoch:138 --- Running Loss:0.2420794665813446 --- Running mIOU:0.8249275387175928\n",
      "Train Epoch:138 --- Running Loss:0.2655506134033203 --- Running mIOU:0.8122470820563319\n",
      "Train Epoch:138 --- Running Loss:0.27303722500801086 --- Running mIOU:0.8439468128297754\n",
      "Train Epoch:138 --- Running Loss:0.28898540139198303 --- Running mIOU:0.7723430037420752\n",
      "Train Epoch:139 --- Running Loss:0.27339059114456177 --- Running mIOU:0.8472221262392248\n",
      "Train Epoch:139 --- Running Loss:0.3192894160747528 --- Running mIOU:0.8088230455232389\n",
      "Train Epoch:139 --- Running Loss:0.19081667065620422 --- Running mIOU:0.845004409370127\n",
      "Train Epoch:139 --- Running Loss:0.32176467776298523 --- Running mIOU:0.780914407687152\n",
      "Train Epoch:139 --- Running Loss:0.32517704367637634 --- Running mIOU:0.8508580953647078\n",
      "Train Epoch:139 --- Running Loss:0.21393753588199615 --- Running mIOU:0.8470437256997262\n",
      "Train Epoch:139 --- Running Loss:0.20131470263004303 --- Running mIOU:0.8459973781202325\n",
      "Train Epoch:139 --- Running Loss:0.2089887410402298 --- Running mIOU:0.8391752801835659\n",
      "Train Epoch:139 --- Running Loss:0.2883744239807129 --- Running mIOU:0.8605053105974294\n",
      "Train Epoch:139 --- Running Loss:0.23879656195640564 --- Running mIOU:0.8457583576299\n",
      "Train Epoch:140 --- Running Loss:0.2774059772491455 --- Running mIOU:0.8532035454404991\n",
      "Train Epoch:140 --- Running Loss:0.2662287950515747 --- Running mIOU:0.8091948612479409\n",
      "Train Epoch:140 --- Running Loss:0.29980364441871643 --- Running mIOU:0.8553147138498864\n",
      "Train Epoch:140 --- Running Loss:0.2795664072036743 --- Running mIOU:0.8113901681761422\n",
      "Train Epoch:140 --- Running Loss:0.31023871898651123 --- Running mIOU:0.7867278383284801\n",
      "Train Epoch:140 --- Running Loss:0.16683056950569153 --- Running mIOU:0.8618531980088545\n",
      "Train Epoch:140 --- Running Loss:0.27255332469940186 --- Running mIOU:0.8522500586115481\n",
      "Train Epoch:140 --- Running Loss:0.24849183857440948 --- Running mIOU:0.8769554717190609\n",
      "Train Epoch:140 --- Running Loss:0.22931639850139618 --- Running mIOU:0.8442381101910001\n",
      "Train Epoch:140 --- Running Loss:0.2413814216852188 --- Running mIOU:0.8420176825110397\n",
      "Running Loss:0.3370187282562256 --- Running mIOU:0.7781562579134673\n",
      "Running Loss:0.4897853434085846 --- Running mIOU:0.6016541484619862\n",
      "Running Loss:0.47763803601264954 --- Running mIOU:0.6312544166099525\n",
      "Running Loss:0.36059749126434326 --- Running mIOU:0.688180456384946\n",
      "Running Loss:0.5004909634590149 --- Running mIOU:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:141 --- Running Loss:0.23935192823410034 --- Running mIOU:0.8520642347621932\n",
      "Train Epoch:141 --- Running Loss:0.2755114734172821 --- Running mIOU:0.8444256771692802\n",
      "Train Epoch:141 --- Running Loss:0.2453598976135254 --- Running mIOU:0.8467429150823642\n",
      "Train Epoch:141 --- Running Loss:0.231313556432724 --- Running mIOU:0.8562139781109204\n",
      "Train Epoch:141 --- Running Loss:0.22949467599391937 --- Running mIOU:0.8169423909603252\n",
      "Train Epoch:141 --- Running Loss:0.2483333796262741 --- Running mIOU:0.8411076215446694\n",
      "Train Epoch:141 --- Running Loss:0.20462048053741455 --- Running mIOU:0.8367348692349212\n",
      "Train Epoch:141 --- Running Loss:0.27110156416893005 --- Running mIOU:0.8604608673063976\n",
      "Train Epoch:141 --- Running Loss:0.2446337193250656 --- Running mIOU:0.8688765719527702\n",
      "Train Epoch:141 --- Running Loss:0.3511269986629486 --- Running mIOU:0.7945485317318801\n",
      "Train Epoch:142 --- Running Loss:0.23583245277404785 --- Running mIOU:0.8283366981289177\n",
      "Train Epoch:142 --- Running Loss:0.26056575775146484 --- Running mIOU:0.8289805532249567\n",
      "Train Epoch:142 --- Running Loss:0.24827954173088074 --- Running mIOU:0.8175974436529965\n",
      "Train Epoch:142 --- Running Loss:0.34056153893470764 --- Running mIOU:0.8032361632951356\n",
      "Train Epoch:142 --- Running Loss:0.3074745237827301 --- Running mIOU:0.7988794142313752\n",
      "Train Epoch:142 --- Running Loss:0.29530274868011475 --- Running mIOU:0.8712468261438047\n",
      "Train Epoch:142 --- Running Loss:0.23289692401885986 --- Running mIOU:0.8130676787694493\n",
      "Train Epoch:142 --- Running Loss:0.32148995995521545 --- Running mIOU:0.7815983720342642\n",
      "Train Epoch:142 --- Running Loss:0.21239762008190155 --- Running mIOU:0.8603137988822778\n",
      "Train Epoch:142 --- Running Loss:0.23491992056369781 --- Running mIOU:0.8154540190216073\n",
      "Train Epoch:143 --- Running Loss:0.3292793929576874 --- Running mIOU:0.7610499970213798\n",
      "Train Epoch:143 --- Running Loss:0.2695625126361847 --- Running mIOU:0.7888832836741355\n",
      "Train Epoch:143 --- Running Loss:0.2843707501888275 --- Running mIOU:0.7600078933728693\n",
      "Train Epoch:143 --- Running Loss:0.28836509585380554 --- Running mIOU:0.8443814949460651\n",
      "Train Epoch:143 --- Running Loss:0.21453240513801575 --- Running mIOU:0.8205361171889981\n",
      "Train Epoch:143 --- Running Loss:0.3466464579105377 --- Running mIOU:0.7962461886755605\n",
      "Train Epoch:143 --- Running Loss:0.2482316792011261 --- Running mIOU:0.7836490191869679\n",
      "Train Epoch:143 --- Running Loss:0.3111133277416229 --- Running mIOU:0.7957849844744209\n",
      "Train Epoch:143 --- Running Loss:0.2033100575208664 --- Running mIOU:0.8412090417212286\n",
      "Train Epoch:143 --- Running Loss:0.22290368378162384 --- Running mIOU:0.8401419685855899\n",
      "Train Epoch:144 --- Running Loss:0.2758793234825134 --- Running mIOU:0.8490206630767991\n",
      "Train Epoch:144 --- Running Loss:0.28153175115585327 --- Running mIOU:0.8355573093575701\n",
      "Train Epoch:144 --- Running Loss:0.26832443475723267 --- Running mIOU:0.8463896458515441\n",
      "Train Epoch:144 --- Running Loss:0.31734806299209595 --- Running mIOU:0.806118078336246\n",
      "Train Epoch:144 --- Running Loss:0.3566267788410187 --- Running mIOU:0.8147310367736336\n",
      "Train Epoch:144 --- Running Loss:0.40415728092193604 --- Running mIOU:0.769834570173217\n",
      "Train Epoch:144 --- Running Loss:0.2753707468509674 --- Running mIOU:0.8315225181638206\n",
      "Train Epoch:144 --- Running Loss:0.21655960381031036 --- Running mIOU:0.8210251543681224\n",
      "Train Epoch:144 --- Running Loss:0.27577921748161316 --- Running mIOU:0.828529279082975\n",
      "Train Epoch:144 --- Running Loss:0.21432535350322723 --- Running mIOU:0.8267173097897476\n",
      "Train Epoch:145 --- Running Loss:0.26643624901771545 --- Running mIOU:0.8208431147136149\n",
      "Train Epoch:145 --- Running Loss:0.3268580138683319 --- Running mIOU:0.8377043607856431\n",
      "Train Epoch:145 --- Running Loss:0.274906188249588 --- Running mIOU:0.8475881183420575\n",
      "Train Epoch:145 --- Running Loss:0.2651017904281616 --- Running mIOU:0.7892327185775896\n",
      "Train Epoch:145 --- Running Loss:0.2736271321773529 --- Running mIOU:0.8256375324589849\n",
      "Train Epoch:145 --- Running Loss:0.1715436577796936 --- Running mIOU:0.8531944601059624\n",
      "Train Epoch:145 --- Running Loss:0.31310755014419556 --- Running mIOU:0.8429181086742856\n",
      "Train Epoch:145 --- Running Loss:0.25797122716903687 --- Running mIOU:0.8323092186482364\n",
      "Train Epoch:145 --- Running Loss:0.3059598505496979 --- Running mIOU:0.8278954805077752\n",
      "Train Epoch:145 --- Running Loss:0.2579754889011383 --- Running mIOU:0.808458270754228\n",
      "Train Epoch:146 --- Running Loss:0.3013392686843872 --- Running mIOU:0.8059618482489528\n",
      "Train Epoch:146 --- Running Loss:0.3079361319541931 --- Running mIOU:0.787900102005761\n",
      "Train Epoch:146 --- Running Loss:0.20135164260864258 --- Running mIOU:0.8149660636192821\n",
      "Train Epoch:146 --- Running Loss:0.344879686832428 --- Running mIOU:0.8490647627918481\n",
      "Train Epoch:146 --- Running Loss:0.2903887927532196 --- Running mIOU:0.8551474279878006\n",
      "Train Epoch:146 --- Running Loss:0.3103622794151306 --- Running mIOU:0.8525545802854535\n",
      "Train Epoch:146 --- Running Loss:0.2735080122947693 --- Running mIOU:0.8062431036052449\n",
      "Train Epoch:146 --- Running Loss:0.39157623052597046 --- Running mIOU:0.826177686196834\n",
      "Train Epoch:146 --- Running Loss:0.22054344415664673 --- Running mIOU:0.8489795797300228\n",
      "Train Epoch:146 --- Running Loss:0.28504183888435364 --- Running mIOU:0.8042515912696164\n",
      "Train Epoch:147 --- Running Loss:0.3444686830043793 --- Running mIOU:0.8019253578311027\n",
      "Train Epoch:147 --- Running Loss:0.38194677233695984 --- Running mIOU:0.8069317182788338\n",
      "Train Epoch:147 --- Running Loss:0.17392414808273315 --- Running mIOU:0.8518666441325458\n",
      "Train Epoch:147 --- Running Loss:0.3334648013114929 --- Running mIOU:0.8215193362446744\n",
      "Train Epoch:147 --- Running Loss:0.3252183198928833 --- Running mIOU:0.7921852683140573\n",
      "Train Epoch:147 --- Running Loss:0.24665334820747375 --- Running mIOU:0.8157160818728213\n",
      "Train Epoch:147 --- Running Loss:0.2714301347732544 --- Running mIOU:0.8028691752952057\n",
      "Train Epoch:147 --- Running Loss:0.257064551115036 --- Running mIOU:0.8700831261370934\n",
      "Train Epoch:147 --- Running Loss:0.28108373284339905 --- Running mIOU:0.823463911460137\n",
      "Train Epoch:147 --- Running Loss:0.2443476915359497 --- Running mIOU:0.7835661548709119\n",
      "Train Epoch:148 --- Running Loss:0.24967831373214722 --- Running mIOU:0.8063057086637255\n",
      "Train Epoch:148 --- Running Loss:0.3288251459598541 --- Running mIOU:0.8532273452972722\n",
      "Train Epoch:148 --- Running Loss:0.2220419943332672 --- Running mIOU:0.8269114181033331\n",
      "Train Epoch:148 --- Running Loss:0.2764796316623688 --- Running mIOU:0.8067992192741469\n",
      "Train Epoch:148 --- Running Loss:0.23114937543869019 --- Running mIOU:0.8716940268837488\n",
      "Train Epoch:148 --- Running Loss:0.2460392564535141 --- Running mIOU:0.8125401921935267\n",
      "Train Epoch:148 --- Running Loss:0.21724176406860352 --- Running mIOU:0.847205741780159\n",
      "Train Epoch:148 --- Running Loss:0.3618106245994568 --- Running mIOU:0.8403462814551825\n",
      "Train Epoch:148 --- Running Loss:0.2931823432445526 --- Running mIOU:0.835846373353393\n",
      "Train Epoch:148 --- Running Loss:0.2276802361011505 --- Running mIOU:0.8604817430067484\n",
      "Train Epoch:149 --- Running Loss:0.24582773447036743 --- Running mIOU:0.8310287864800927\n",
      "Train Epoch:149 --- Running Loss:0.2582879066467285 --- Running mIOU:0.8353493733279441\n",
      "Train Epoch:149 --- Running Loss:0.26841849088668823 --- Running mIOU:0.8294533107758895\n",
      "Train Epoch:149 --- Running Loss:0.25201404094696045 --- Running mIOU:0.8867007300791506\n",
      "Train Epoch:149 --- Running Loss:0.33934441208839417 --- Running mIOU:0.766267593404216\n",
      "Train Epoch:149 --- Running Loss:0.3147944509983063 --- Running mIOU:0.8361755989973244\n",
      "Train Epoch:149 --- Running Loss:0.3234280049800873 --- Running mIOU:0.8236010910974697\n",
      "Train Epoch:149 --- Running Loss:0.24103496968746185 --- Running mIOU:0.7962992404456315\n",
      "Train Epoch:149 --- Running Loss:0.3016095757484436 --- Running mIOU:0.8461385755432715\n",
      "Train Epoch:149 --- Running Loss:0.30970391631126404 --- Running mIOU:0.7897259200413302\n"
     ]
    }
   ],
   "source": [
    "test_freq = config['test_freq']\n",
    "\n",
    "while epochs < total_epochs:\n",
    "    train(epochs)\n",
    "    \n",
    "    if epochs%test_freq == 0:\n",
    "        val_loss = val()\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            save_checkpoint(loss = best_loss, \n",
    "                            model = model, \n",
    "                            optimizer = optimizer, \n",
    "                            experiment_dir = experiment_dir)\n",
    "    epochs = epochs + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b9020ccbb7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(val_loader):\n",
    "    _input, gt = sample\n",
    "    _output = model(_input.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (torch.sigmoid(_output['out'].cpu()) > 0.5).numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-104c2f1199a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_input' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(_input[idxx][:3].cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d4b56b012b95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_input' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(_input[idxx][3:4].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97ade7bf10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN/klEQVR4nO3dXYxcd33G8e+T9WYTEhAxecG13cZVLVEHlUBdg5SqogQaFxDOTSQjUVlVJF80lUCthOwitaKSJcoF4qLKhQWolnixrAKKGyFa15CivgjHkARiOyZLksYru3F5SQlUOLH968Uc1MH/tXfindmZjb8faXXO+c//zDyrXT8+c2bObKoKSep31bgDSJo8FoOkhsUgqWExSGpYDJIaFoOkxsiKIcnmJMeTzCbZMarHkTR8GcX7GJJMAd8D3gXMAQ8D76+qo0N/MElDN6ojhk3AbFU9VVUvAnuBLSN6LElDtmJE97saONG3PQe89WKTr85MXcN1I4pyZcr0NL/yhue5LrnkvCP/dRPTp3+2RKk0Ti/w4x9U1U2DzB1VMcz32/hLz1mSbAe2A1zDq3hr7hxRlCvTitev5q//4cv89szVl5z3po//Ca//5L8vUSqN0z/X3//noHNH9VRiDljbt70GONk/oap2V9XGqto4zcyIYki6HKMqhoeB9UnWJbka2ArsH9FjSRqykTyVqKqzSf4U+EdgCvhMVR0ZxWNJGr5RnWOgqr4CfGVU9y9pdHzno6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxXCl8+8NaR4WwxXs335+ntVfPT3uGJpAFsMV7IXz18IPfzzuGJpAFoOkhsUgqWExSGpYDJIaFoOkhsUgqWExSGpYDJIaFoOkhsUgqWExSGpYDJIaFoOkhsUgqWExSGpYDJIaFoOkhsUgqWExSGpYDJIaFoOkhsXwCvW/t63ipqkXxx1Dy9SCxZDkM0lOJ3m8b2xlkgNJnuyWN/TdtjPJbJLjSe4aVXBd2nO/czW/uuL6ccfQMjXIEcPfAZsvGNsBHKyq9cDBbpskG4CtwG3dPvcnmRpaWklLYsFiqKpvAD+6YHgLsKdb3wPc3Te+t6rOVNXTwCywaThRJS2Vyz3HcEtVnQLoljd346uBE33z5rqxRpLtSQ4nOfwSZy4zhqRRGPbJx8wzNu+fTa2q3VW1sao2TjMz5BiSFuNyi+G5JKsAuuUv/jLqHLC2b94a4OTlx5M0DpdbDPuBbd36NuCBvvGtSWaSrAPWA4cWF1HSUlux0IQkXwDeDtyYZA74K+BjwL4k9wLPAvcAVNWRJPuAo8BZ4L6qOjei7JJGZMFiqKr3X+SmOy8yfxewazGhJI2X73yU1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1FiwGJKsTfL1JMeSHEnywW58ZZIDSZ7sljf07bMzyWyS40nuGuU3IGn4BjliOAv8eVX9JvA24L4kG4AdwMGqWg8c7LbpbtsK3AZsBu5PMjWK8JJGY8FiqKpTVfXtbv0F4BiwGtgC7Omm7QHu7ta3AHur6kxVPQ3MApuGnFvSCL2scwxJbgXeDHwTuKWqTkGvPICbu2mrgRN9u811Y5KWiYGLIcn1wBeBD1XVTy41dZ6xmuf+tic5nOTwS5wZNIaG6OjPV8PZs+OOoQk0UDEkmaZXCp+rqi91w88lWdXdvgo43Y3PAWv7dl8DnLzwPqtqd1VtrKqN08xcbn4twt/+y7s49/z/jDuGJtAgr0oE+DRwrKo+0XfTfmBbt74NeKBvfGuSmSTrgPXAoeFF1tCcH3cATaoVA8y5A/gj4LtJHu3G/gL4GLAvyb3As8A9AFV1JMk+4Ci9VzTuq6pzww4uaXQWLIaq+lfmP28AcOdF9tkF7FpELklj5DsfJTUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2KQ1LAYJDUsBkkNi0FSw2J4BcqKFfzGu54adwwtYxbDK1Gu4h03PjHuFFrGLAZJDYtBUsNikNSwGCQ1LAZJDYtBUsNikNSwGCQ1LAZJDYtBUsNikNSwGCQ1LAZJjQWLIck1SQ4leSzJkSQf7cZXJjmQ5MlueUPfPjuTzCY5nuSuUX4DkoZvkCOGM8A7qupNwO3A5iRvA3YAB6tqPXCw2ybJBmArcBuwGbg/ydQIsksakQWLoXp+2m1Od18FbAH2dON7gLu79S3A3qo6U1VPA7PApmGGljRaA51jSDKV5FHgNHCgqr4J3FJVpwC65c3d9NXAib7d57qxC+9ze5LDSQ6/xJlFfAuShm2gYqiqc1V1O7AG2JTkjZeYnvnuYp773F1VG6tq4zQzA4WVtDRe1qsSVfU88BC9cwfPJVkF0C1Pd9PmgLV9u60BTi42qKSlM8irEjcleW23fi3wTuAJYD+wrZu2DXigW98PbE0yk2QdsB44NOTckkZoxQBzVgF7ulcWrgL2VdWDSf4D2JfkXuBZ4B6AqjqSZB9wFDgL3FdV50YTX9IoLFgMVfUd4M3zjP8QuPMi++wCdi06naSx8J2PkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoDF0OSqSSPJHmw216Z5ECSJ7vlDX1zdyaZTXI8yV2jCC5pdF7OEcMHgWN92zuAg1W1HjjYbZNkA7AVuA3YDNyfZGo4cSUthYGKIcka4D3Ap/qGtwB7uvU9wN1943ur6kxVPQ3MApuGklbSkhj0iOGTwIeB831jt1TVKYBueXM3vho40Tdvrhv7JUm2Jzmc5PBLnHm5uSWN0ILFkOS9wOmq+taA95l5xqoZqNpdVRurauM0MwPetaSlsGKAOXcA70vybuAa4DVJPgs8l2RVVZ1Ksgo43c2fA9b27b8GODnM0JJGa8EjhqraWVVrqupWeicVv1ZVHwD2A9u6aduAB7r1/cDWJDNJ1gHrgUNDTy5pZAY5YriYjwH7ktwLPAvcA1BVR5LsA44CZ4H7qurcopNKWjIvqxiq6iHgoW79h8CdF5m3C9i1yGySxsR3PkpqWAySGhaDpIbFIKlhMbwCXXXdtbzqqhfHHUPLmMXwCvSTO9/AH7/mxMITpYuwGF6Bzq8I017QqkWwGCQ1LAZJDYtBUsNikNSwGCQ1LAZJDYtBUsNikNSwGCQ1LIYr1E/P/5wbD/vj1/z8zbhCvXD+LK975MfjjqEJZTFcoaYy36f8Sz0Wg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIalgMkhoWg6SGxSCpYTFIagxUDEmeSfLdJI8mOdyNrUxyIMmT3fKGvvk7k8wmOZ7krlGFlzQaL+eI4fer6vaq2tht7wAOVtV64GC3TZINwFbgNmAzcH/iX1iVlpPFPJXYAuzp1vcAd/eN762qM1X1NDALbFrE40haYoMWQwH/lORbSbZ3Y7dU1SmAbnlzN74aONG371w39kuSbE9yOMnhlzhzeekljcSKAefdUVUnk9wMHEjyxCXmzvdhgtUMVO0GdgO8Jiub2yWNz0BHDFV1slueBr5M76nBc0lWAXTL0930OWBt3+5rgJPDCixp9BYshiTXJXn1L9aBPwAeB/YD27pp24AHuvX9wNYkM0nWAeuBQ8MOLml0BnkqcQvw5fQ+bnwF8Pmq+mqSh4F9Se4FngXuAaiqI0n2AUeBs8B9VXVuJOkljUSqxv/0Psl/Az8DfjDuLAO4EXMO23LJulxywvxZf62qbhpk54koBoAkh/veIzGxzDl8yyXrcskJi8/qW6IlNSwGSY1JKobd4w4wIHMO33LJulxywiKzTsw5BkmTY5KOGCRNiLEXQ5LN3eXZs0l2TECezyQ5neTxvrGJu8Q8ydokX09yLMmRJB+cxKxJrklyKMljXc6PTmLOvseeSvJIkgcnPOdoPwqhqsb2BUwB3wd+HbgaeAzYMOZMvwe8BXi8b+zjwI5ufQfwN936hi7zDLCu+16mlijnKuAt3fqrge91eSYqK71rZ67v1qeBbwJvm7ScfXn/DPg88OCk/uy7x38GuPGCsaFlHfcRwyZgtqqeqqoXgb30Ltsem6r6BvCjC4Yn7hLzqjpVVd/u1l8AjtG7inWislbPT7vN6e6rJi0nQJI1wHuAT/UNT1zOSxha1nEXw0CXaE+ARV1iPmpJbgXeTO9/44nL2h2eP0rvQrsDVTWROYFPAh8GzveNTWJOGMFHIfQb9LLrURnoEu0JNvb8Sa4Hvgh8qKp+0l3TMu/UecaWJGv1rpW5Pclr6V1388ZLTB9LziTvBU5X1beSvH2QXeYZW8qf/dA/CqHfuI8Ylssl2hN5iXmSaXql8Lmq+tIkZwWoqueBh+h95N+k5bwDeF+SZ+g9pX1Hks9OYE5g9B+FMO5ieBhYn2RdkqvpfVbk/jFnms/EXWKe3qHBp4FjVfWJSc2a5KbuSIEk1wLvBJ6YtJxVtbOq1lTVrfR+D79WVR+YtJywRB+FsFRnUS9xdvXd9M6ofx/4yATk+QJwCniJXtPeC7yO3gfePtktV/bN/0iX/Tjwh0uY83fpHQ5+B3i0+3r3pGUFfgt4pMv5OPCX3fhE5bwg89v5/1clJi4nvVfxHuu+jvzi380ws/rOR0mNcT+VkDSBLAZJDYtBUsNikNSwGCQ1LAZJDYtBUsNikNT4P1Sluc4f9e/UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(_input[idxx][4:5].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97ade72510>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(gt[idxx].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97addd7d90>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[idxx].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValTestDrivewayDataset(Dataset):\n",
    "    def __init__(self, path_directory, mode):\n",
    "        self.path_directory = path_directory\n",
    "        \n",
    "        self.namefile = open(os.path.join(self.path_directory, (mode + '.txt')), 'r')\n",
    "        self.reader = csv.reader(self.namefile)\n",
    "        self.image_names = [row[0] for row in self.reader]\n",
    "        \n",
    "        self.crop_size = 768\n",
    "        self.reshape = True\n",
    "        self.reshape_size = 512\n",
    "        \n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "#         self.color_jit = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.05)\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.image_names))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # randomly choose an image\n",
    "        file_name = random.choice(self.image_names)\n",
    "        \n",
    "        # prepapre reading paths\n",
    "        path_img = os.path.join('/mnt/mount-point-directory/datasets/', city, 'VRT')\n",
    "        path_building = os.path.join(self.path_directory, 'data', 'building_polygon', 'tiles_jp2')\n",
    "        path_road = os.path.join(self.path_directory, 'data', 'road_fill', 'tiles_jp2')\n",
    "        path_driveway = os.path.join(self.path_directory, 'data', 'driveways_polygon', 'tiles_jp2')\n",
    "        \n",
    "        # read src datasets\n",
    "        src_img = rio.open(os.path.join(path_img, file_name), mode = 'r')\n",
    "        src_building = rio.open(os.path.join(path_building, file_name), mode ='r')\n",
    "        src_road = rio.open(os.path.join(path_road, file_name), mode = 'r')\n",
    "        src_driveway = rio.open(os.path.join(path_driveway, file_name), mode = 'r')\n",
    "        \n",
    "        meta = src_img.meta\n",
    "\n",
    "        _mask = src_driveway.read()\n",
    "        \n",
    "                \n",
    "        # read images, if you get nullpointer error in img read, there is a channel issue. Reformat the images.\n",
    "        _img = src_img.read((1,2,3), window = window)\n",
    "        _mask_building = src_building.read(1, window = window)\n",
    "        _mask_road = src_road.read(1, window = window)\n",
    "        _mask_driveway = src_driveway.read(1, window = window)\n",
    "        \n",
    "        _input_tensor, _mask = self.transform(_img, _mask_building, _mask_road, _mask_driveway)\n",
    "        \n",
    "        return _input_tensor, _mask\n",
    "        \n",
    "    def transform(self, img, mask_building, mask_road, mask_driveway):\n",
    "        \"\"\"\n",
    "        Input Tensor, Ouput Tensor\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # To Tensor\n",
    "        img = torch.tensor(img)\n",
    "        mask_building = torch.tensor(mask_building)\n",
    "        mask_road = torch.tensor(mask_road)\n",
    "        mask_driveway = torch.tensor(mask_driveway)\n",
    "        \n",
    "        # To PIL image\n",
    "        image = self.to_pil(img)\n",
    "        mask_building = self.to_pil(mask_building)\n",
    "        mask_road = self.to_pil(mask_road)\n",
    "        mask_driveway = self.to_pil(mask_driveway)\n",
    "        \n",
    "        # Resize\n",
    "        image = TF.resize(image, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_building = TF.resize(mask_building, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_road = TF.resize(mask_road, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_driveway = TF.resize(mask_driveway, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        \n",
    "        # Change to tensors\n",
    "        image = self.to_tensor(image)\n",
    "        mask_building = self.to_tensor(mask_building)\n",
    "        mask_road = self.to_tensor(mask_road)\n",
    "        mask_driveway = self.to_tensor(mask_driveway)\n",
    "        \n",
    "        # Merge input tensors to 5 channel, 3 image 1 building 1 road\n",
    "        _input_stacked = torch.cat((image, mask_building, mask_road))\n",
    "        \n",
    "        return _input_stacked, mask_driveway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
