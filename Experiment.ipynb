{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driveway Footprint Detection \n",
    "Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENCV_IO_ENABLE_JASPER']='True' # reading jp2000 images\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import rasterio as rio\n",
    "from rasterio.windows import Window\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'kw_3band'\n",
    "crop_size = 512\n",
    "EXPERIMENT_NAME = 'test1'\n",
    "TOTAL_EPOCHS = 100\n",
    "LR = 1e-4\n",
    "WD = 5e-4\n",
    "test_freq = 5\n",
    "\n",
    "PATH_DIRECTORY = '/mnt/mount-point-directory/building_footprint/'\n",
    "PATH_DATA = os.path.join(PATH_DIRECTORY, 'data')\n",
    "\n",
    "PATH_DATA_BUILDING_POLYGON = os.path.join(PATH_DIRECTORY, 'data', 'building_polygon', 'tiles_jp2')\n",
    "PATH_DATA_ROAD_FILL = os.path.join(PATH_DIRECTORY, 'data', 'road_fill', 'tiles_jp2')\n",
    "PATH_DATA_CITY = os.path.join('/mnt/mount-point-directory/datasets/', city, 'VRT')\n",
    "\n",
    "PATH_DATA_DRIVEWAY_POLYGON = os.path.join(PATH_DIRECTORY, 'data', 'driveways_polygon', 'tiles_jp2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbuilding_polygon\u001b[0m/  \u001b[01;34mdriveways_polygon\u001b[0m/  \u001b[01;34mroad_fill\u001b[0m/  \u001b[01;34mroad_polyline\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls '/mnt/mount-point-directory/building_footprint/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_building_polygon = os.listdir('/mnt/mount-point-directory/building_footprint/data/building_polygon/tiles_jp2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images = os.listdir(os.path.join(PATH_DATA_CITY))\n",
    "list_road = os.listdir(os.path.join(PATH_DATA_ROAD_FILL))\n",
    "list_building = os.listdir(os.path.join(PATH_DATA_BUILDING_POLYGON))\n",
    "\n",
    "list_driveway = os.listdir(os.path.join(PATH_DATA_DRIVEWAY_POLYGON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in list_images:\n",
    "#     print(name)\n",
    "#     new_name = name.split('_')[-1]\n",
    "#     os.rename(os.path.join(PATH_DATA_CITY, name), os.path.join(PATH_DATA_CITY, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_final = list((set.intersection(set(list_images),set(list_road))))\n",
    "file_name = names_final[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split\n",
    "Train 70%\n",
    "Validation 15%\n",
    "Test 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nos = int(len(names_final) * .7)\n",
    "val_nos = int(len(names_final) * .15)\n",
    "test_nos = len(names_final) - train_nos - val_nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_DIRECTORY, 'train.txt'), 'w') as f:\n",
    "    for item in names_final[:train_nos]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open(os.path.join(PATH_DIRECTORY, 'val.txt'), 'w') as f:\n",
    "    for item in names_final[train_nos : train_nos + val_nos]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open(os.path.join(PATH_DIRECTORY, 'test.txt'), 'w') as f:\n",
    "    for item in names_final[:test_nos]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIRECTORY = '/mnt/mount-point-directory/building_footprint/'\n",
    "PATH_DATA = os.path.join(PATH_DIRECTORY, 'data')\n",
    "\n",
    "PATH_DATA_BUILDING_POLYGON = os.path.join(PATH_DIRECTORY, 'data', 'building_polygon', 'tiles_jp2')\n",
    "PATH_DATA_ROAD_FILL = os.path.join(PATH_DIRECTORY, 'data', 'road_fill', 'tiles_jp2')\n",
    "PATH_DATA_CITY = os.path.join('/mnt/mount-point-directory/datasets/', city, 'VRT')\n",
    "\n",
    "PATH_DATA_DRIVEWAY_POLYGON = os.path.join(PATH_DIRECTORY, 'data', 'driveways_polygon', 'tiles_jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "import PIL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainDrivewayDataset(Dataset):\n",
    "    def __init__(self, path_directory, mode):\n",
    "        self.path_directory = path_directory\n",
    "        \n",
    "        self.namefile = open(os.path.join(self.path_directory, 'train.txt'), 'r')\n",
    "        self.reader = csv.reader(self.namefile)\n",
    "        self.image_names = [row[0] for row in self.reader]\n",
    "        \n",
    "        self.crop_size = 768\n",
    "        self.reshape = True\n",
    "        self.reshape_size = 512\n",
    "        \n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        self.color_jit = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.05)\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return(len(self.image_names))\n",
    "        return(2)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # randomly choose an image\n",
    "        file_name = random.choice(self.image_names)\n",
    "        \n",
    "        # prepapre reading paths\n",
    "        path_img = os.path.join('/mnt/mount-point-directory/datasets/', city, 'VRT')\n",
    "        path_building = os.path.join(self.path_directory, 'data', 'building_polygon', 'tiles_jp2')\n",
    "        path_road = os.path.join(self.path_directory, 'data', 'road_fill', 'tiles_jp2')\n",
    "        path_driveway = os.path.join(self.path_directory, 'data', 'driveways_polygon', 'tiles_jp2')\n",
    "        \n",
    "        # read src datasets\n",
    "        src_img = rio.open(os.path.join(path_img, file_name), mode = 'r')\n",
    "        src_building = rio.open(os.path.join(path_building, file_name), mode ='r')\n",
    "        src_road = rio.open(os.path.join(path_road, file_name), mode = 'r')\n",
    "        src_driveway = rio.open(os.path.join(path_driveway, file_name), mode = 'r')\n",
    "        \n",
    "        meta = src_img.meta\n",
    "        x_lim = meta['width'] - self.crop_size \n",
    "        y_lim = meta['height'] - self.crop_size\n",
    "        \n",
    "        # find a random path until there is some data in it\n",
    "#         while True: \n",
    "#             col_off = np.random.randint(0, x_lim)\n",
    "#             row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "#             window = Window(col_off=col_off,\n",
    "#                 row_off=row_off,\n",
    "#                 width=self.crop_size,\n",
    "#                 height=self.crop_size)\n",
    "\n",
    "#             _mask = src_driveway.read(window = window)\n",
    "#             print(window)\n",
    "#             if _mask.any():\n",
    "#                 break\n",
    "\n",
    "        col_off = np.random.randint(0, x_lim)\n",
    "        row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "        window = Window(col_off=col_off,\n",
    "            row_off=row_off,\n",
    "            width=self.crop_size,\n",
    "            height=self.crop_size)\n",
    "\n",
    "        _mask = src_driveway.read(window = window)\n",
    "        \n",
    "                \n",
    "        # read images, if you get nullpointer error in img read, there is a channel issue. Reformat the images.\n",
    "        _img = src_img.read((1,2,3), window = window)\n",
    "        _mask_building = src_building.read(1, window = window)\n",
    "        _mask_road = src_road.read(1, window = window)\n",
    "        _mask_driveway = src_driveway.read(1, window = window)\n",
    "        \n",
    "        _input_tensor, _mask = self.transform(_img, _mask_building, _mask_road, _mask_driveway)\n",
    "        \n",
    "        return _input_tensor, _mask\n",
    "        \n",
    "    def transform(self, img, mask_building, mask_road, mask_driveway):\n",
    "        \"\"\"\n",
    "        Input Tensor, Ouput Tensor\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # To Tensor\n",
    "        img = torch.tensor(img)\n",
    "        mask_building = torch.tensor(mask_building)\n",
    "        mask_road = torch.tensor(mask_road)\n",
    "        mask_driveway = torch.tensor(mask_driveway)\n",
    "        \n",
    "        # To PIL image\n",
    "        image = self.to_pil(img)\n",
    "        mask_building = self.to_pil(mask_building)\n",
    "        mask_road = self.to_pil(mask_road)\n",
    "        mask_driveway = self.to_pil(mask_driveway)\n",
    "        \n",
    "        # Resize\n",
    "        image = TF.resize(image, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_building = TF.resize(mask_building, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_road = TF.resize(mask_road, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_driveway = TF.resize(mask_driveway, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask_building= TF.hflip(mask_building)\n",
    "            mask_road= TF.hflip(mask_road)\n",
    "            mask_driveway= TF.hflip(mask_driveway)\n",
    "            \n",
    "        # Random Vertical flip\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask_building = TF.vflip(mask_building)\n",
    "            mask_road = TF.vflip(mask_road)\n",
    "            mask_driveway = TF.vflip(mask_driveway)\n",
    "        \n",
    "        # Color Jitter Image\n",
    "        image = self.color_jit(image)\n",
    "        \n",
    "        # Change to tensors\n",
    "        image = self.to_tensor(image)\n",
    "        mask_building = self.to_tensor(mask_building)\n",
    "        mask_road = self.to_tensor(mask_road)\n",
    "        mask_driveway = self.to_tensor(mask_driveway)\n",
    "        \n",
    "        # Merge input tensors to 5 channel, 3 image 1 building 1 road\n",
    "        _input_stacked = torch.cat((image, mask_building, mask_road))\n",
    "        \n",
    "        return _input_stacked, mask_driveway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValTestDrivewayDataset(Dataset):\n",
    "    def __init__(self, path_directory, mode):\n",
    "        self.path_directory = path_directory\n",
    "        \n",
    "        self.namefile = open(os.path.join(self.path_directory, (mode + '.txt')), 'r')\n",
    "        self.reader = csv.reader(self.namefile)\n",
    "        self.image_names = [row[0] for row in self.reader]\n",
    "        \n",
    "        self.crop_size = 768\n",
    "        self.reshape = True\n",
    "        self.reshape_size = 512\n",
    "        \n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "#         self.color_jit = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.05)\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return(len(self.image_names))\n",
    "        return(5)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # randomly choose an image\n",
    "        file_name = random.choice(self.image_names)\n",
    "        \n",
    "        # prepapre reading paths\n",
    "        path_img = os.path.join('/mnt/mount-point-directory/datasets/', city, 'VRT')\n",
    "        path_building = os.path.join(self.path_directory, 'data', 'building_polygon', 'tiles_jp2')\n",
    "        path_road = os.path.join(self.path_directory, 'data', 'road_fill', 'tiles_jp2')\n",
    "        path_driveway = os.path.join(self.path_directory, 'data', 'driveways_polygon', 'tiles_jp2')\n",
    "        \n",
    "        # read src datasets\n",
    "        src_img = rio.open(os.path.join(path_img, file_name), mode = 'r')\n",
    "        src_building = rio.open(os.path.join(path_building, file_name), mode ='r')\n",
    "        src_road = rio.open(os.path.join(path_road, file_name), mode = 'r')\n",
    "        src_driveway = rio.open(os.path.join(path_driveway, file_name), mode = 'r')\n",
    "        \n",
    "        meta = src_img.meta\n",
    "        x_lim = meta['width'] - self.crop_size \n",
    "        y_lim = meta['height'] - self.crop_size\n",
    "        \n",
    "        # find a random path until there is some data in it\n",
    "#         while True: \n",
    "#             col_off = np.random.randint(0, x_lim)\n",
    "#             row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "#             window = Window(col_off=col_off,\n",
    "#                 row_off=row_off,\n",
    "#                 width=self.crop_size,\n",
    "#                 height=self.crop_size)\n",
    "\n",
    "#             _mask = src_driveway.read(window = window)\n",
    "#             print(window)\n",
    "#             if _mask.any():\n",
    "#                 break\n",
    "\n",
    "        col_off = np.random.randint(0, x_lim)\n",
    "        row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "        window = Window(col_off=col_off,\n",
    "            row_off=row_off,\n",
    "            width=self.crop_size,\n",
    "            height=self.crop_size)\n",
    "\n",
    "        _mask = src_driveway.read(window = window)\n",
    "        \n",
    "                \n",
    "        # read images, if you get nullpointer error in img read, there is a channel issue. Reformat the images.\n",
    "        _img = src_img.read((1,2,3), window = window)\n",
    "        _mask_building = src_building.read(1, window = window)\n",
    "        _mask_road = src_road.read(1, window = window)\n",
    "        _mask_driveway = src_driveway.read(1, window = window)\n",
    "        \n",
    "        _input_tensor, _mask = self.transform(_img, _mask_building, _mask_road, _mask_driveway)\n",
    "        \n",
    "        return _input_tensor, _mask\n",
    "        \n",
    "    def transform(self, img, mask_building, mask_road, mask_driveway):\n",
    "        \"\"\"\n",
    "        Input Tensor, Ouput Tensor\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # To Tensor\n",
    "        img = torch.tensor(img)\n",
    "        mask_building = torch.tensor(mask_building)\n",
    "        mask_road = torch.tensor(mask_road)\n",
    "        mask_driveway = torch.tensor(mask_driveway)\n",
    "        \n",
    "        # To PIL image\n",
    "        image = self.to_pil(img)\n",
    "        mask_building = self.to_pil(mask_building)\n",
    "        mask_road = self.to_pil(mask_road)\n",
    "        mask_driveway = self.to_pil(mask_driveway)\n",
    "        \n",
    "        # Resize\n",
    "        image = TF.resize(image, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_building = TF.resize(mask_building, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_road = TF.resize(mask_road, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        mask_driveway = TF.resize(mask_driveway, size = self.reshape_size, interpolation=PIL.Image.NEAREST)\n",
    "        \n",
    "        # Change to tensors\n",
    "        image = self.to_tensor(image)\n",
    "        mask_building = self.to_tensor(mask_building)\n",
    "        mask_road = self.to_tensor(mask_road)\n",
    "        mask_driveway = self.to_tensor(mask_driveway)\n",
    "        \n",
    "        # Merge input tensors to 5 channel, 3 image 1 building 1 road\n",
    "        _input_stacked = torch.cat((image, mask_building, mask_road))\n",
    "        \n",
    "        return _input_stacked, mask_driveway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DeepLabV3 segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, num_classes=1, aux_loss=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.conv1 = nn.Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainDrivewayDataset(PATH_DIRECTORY, mode = 'train')\n",
    "train_loader = DataLoader(train_ds, batch_size = 2, shuffle = True, num_workers = 16)\n",
    "\n",
    "val_ds = ValTestDrivewayDataset(PATH_DIRECTORY, mode = 'val')\n",
    "val_loader = DataLoader(val_ds, batch_size = 4, shuffle = True, num_workers = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import loss, util\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth = 1e-6):\n",
    "    pred = y_pred.contiguous()\n",
    "    target = y_true.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "def calc_loss(pred, target, weight_bce):\n",
    "    pred = pred\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(y_true = target, y_pred = pred)\n",
    "\n",
    "    loss = bce * weight_bce + dice * (1-weight_bce)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def compute_miou(y_pred, y_true):\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    \n",
    "    current = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    intersection = np.diag(current)\n",
    "    ground_truth_set = current.sum(axis=1)\n",
    "    predicted_set = current.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "    IoU = intersection / union.astype(np.float32)\n",
    "    \n",
    "    return np.mean(IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = os.path.join('./save/', EXPERIMENT_NAME)\n",
    "util.ensure_dir(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logging Files\n",
    "train_file = \"{}/{}_train_loss.txt\".format(experiment_dir, city)\n",
    "test_file = \"{}/{}_test_loss.txt\".format(experiment_dir, city)\n",
    "\n",
    "train_loss_file = open(train_file, \"w\")\n",
    "val_loss_file = open(test_file, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU, GPU not available\n"
     ]
    }
   ],
   "source": [
    "if num_gpus > 1:\n",
    "    print(\"Training with multiple GPUs ({})\".format(num_gpus))\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif num_gpus == 1:\n",
    "    print(\"Single Cuda Node is avaiable\")\n",
    "    model.cuda()\n",
    "else:\n",
    "    print(\"Training on CPU, GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO CHECK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_miou = 0\n",
    "best_loss = 1e10\n",
    "epochs = 1\n",
    "total_epochs = TOTAL_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=LR, weight_decay=WD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        _input, gt = sample\n",
    "        _output = model(_input)\n",
    "        \n",
    "        loss = calc_loss(_output['out'], gt, weight_bce=0.5)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = (torch.sigmoid(_output['out']) > 0.5).numpy().astype(int)\n",
    "        \n",
    "        running_mIOU = compute_miou(y_pred=pred, y_true=gt)\n",
    "        \n",
    "        print('Train Epoch:{} --- Running Loss:{} --- Running mIOU:{}'.format(start_epoch, loss.item(), running_mIOU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(loss, model, optimizer, experiment_dir):\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        arch = type(model.module).__name__\n",
    "    else:\n",
    "        arch = type(model).__name__\n",
    "    state = {\n",
    "        \"arch\": arch,\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "    filename = os.path.join(\n",
    "        experiment_dir, \"checkpoint-loss-{:.4f}.pth.tar\".format(loss)\n",
    "    )\n",
    "    torch.save(state, filename)\n",
    "    os.rename(filename, os.path.join(experiment_dir, \"model_best.pth.tar\"))\n",
    "    print(\"Saving current best: {} ...\".format(\"model_best.pth.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val():\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        for i, data in enumerate(val_loader):\n",
    "            _input, gt = sample\n",
    "            _output = model(_input)\n",
    "\n",
    "            loss = calc_loss(_output['out'], gt, weight_bce=0.5)\n",
    "\n",
    "            pred = (torch.sigmoid(_output['out']) > 0.5).numpy().astype(int)\n",
    "\n",
    "            running_mIOU = compute_miou(y_pred=pred, y_true=gt)\n",
    "\n",
    "            print('Running Loss:{} --- Running mIOU:{}'.format(loss.item(), running_mIOU))\n",
    "            \n",
    "            val_loss = val_loss + loss\n",
    "        \n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0 --- Running Loss:0.8070863485336304 --- Running mIOU:0.36496350868975574\n",
      "Train Epoch:0 --- Running Loss:0.7916972637176514 --- Running mIOU:0.4571526663630442\n",
      "Train Epoch:0 --- Running Loss:0.7745586633682251 --- Running mIOU:0.5170357903506669\n",
      "Train Epoch:0 --- Running Loss:0.755042552947998 --- Running mIOU:0.5585140834896927\n",
      "Train Epoch:0 --- Running Loss:0.736782431602478 --- Running mIOU:0.5989812038939125\n",
      "Running Loss:0.8155452013015747 --- Running mIOU:0.5455327019887042\n",
      "Running Loss:0.8155452013015747 --- Running mIOU:0.5455327019887042\n",
      "Saving current best: model_best.pth.tar ...\n"
     ]
    }
   ],
   "source": [
    "while epochs < total_epochs:\n",
    "    train()\n",
    "    \n",
    "    if epochs%test_freq == 0:\n",
    "        val_loss = val()\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            save_checkpoint(loss = best_loss, \n",
    "                            model = model, \n",
    "                            optimizer = optimizer, \n",
    "                            experiment_dir = experiment_dir)\n",
    "    epochs = epochs + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_img = rio.open(os.path.join(PATH_DATA_CITY, file_name), mode = 'r')\n",
    "src_building = rio.open(os.path.join(PATH_DATA_BUILDING_POLYGON, file_name), mode ='r')\n",
    "src_road = rio.open(os.path.join(PATH_DATA_ROAD_FILL, file_name), mode = 'r')\n",
    "src_driveway = rio.open(os.path.join(PATH_DATA_DRIVEWAY_POLYGON, file_name), mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = src_img.meta\n",
    "x_lim = meta['width'] - crop_size \n",
    "y_lim = meta['height'] - crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: \n",
    "    col_off = np.random.randint(0, x_lim)\n",
    "    row_off = np.random.randint(0, y_lim)\n",
    "\n",
    "    window = Window(col_off=col_off,\n",
    "        row_off=row_off,\n",
    "        width=crop_size,\n",
    "        height=crop_size)\n",
    "\n",
    "    _mask = src_driveway.read(window = window)\n",
    "\n",
    "    if _mask.any():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_img = src_img.read((1,2,3), window = window)\n",
    "_mask_building = src_building.read(1, window = window)\n",
    "_mask_road = src_road.read(1, window = window)\n",
    "_mask_driveway = src_driveway.read(1, window = window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train':{\n",
    "        'hello':1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'hello': 1}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-19-f87fcebfa447>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-f87fcebfa447>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def __len__(self):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class TrainDrivewayDataset(Dataset):\n",
    "    def __init__(self, image_names):\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "    def __getitem__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make train validation test set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
